publication_type,title,doi,abstract,year,authors,Insights,Problem Statement,Methods Used,Research Gap,Dataset,Literature Survey,Results,Summarized Abstract,Limitations,Objectives,Future Research,Found Methods,llm_method
Proceedings Article,Management and Monitoring of Livestock in the Farm Using Deep Learning,10.1109/icabcd59051.2023.10220556,"Livestock management and monitoring system play a crucial role in farm operations. This paper proposes a system for the management and monitoring of livestock on a farm using deep learning techniques. Traditional methods of monitoring livestock involve manual observation, which can be time-consuming and unreliable. Various systems have been developed, however, there are still challenges existing in present livestock classification and counting, including occlusion, animal overlapping, shadow, etc. To improve all these challenges, this paper presents a monitoring system of livestock under different conditions by the end-to-end deep learning model of You Only Look Once version 5 (YOLOv5). The suggested model conducts feature extraction on the original image with the original YOLOv5 backbone network and detects livestock of different sizes for counting on each anchor frame. Additionally, this model identifies and tracks individual animals The Kaggle dataset collected in real-time containing different animals is used as YOLOv5 relies heavily on data augmentation to improve its detection and tracking performance and validate the proposed system. The scaling, resizing, and manipulation of the splitting dataset are done by the Roboflow application. Additionally, this paper seeks to demonstrate the latest research in utilizing Faster Regional convolutional neural networks (R-CNN) and compare its backbones with the original YOLOv5 backbone. The tensor board graphs from Colab show that this proposed system outperformed other R-CNN, achieving an accuracy of 93% on mAP@_0.5%, making it a promising option for intelligent farm monitoring and managing. ",2023.0,"Makhabane Molapo, Chunling Tu, Deao Du Plessis, Shengzhi Du","The paper presents a livestock detection, counting, and classification system using the YOLOv5 deep learning model. It addresses challenges such as occlusion and animal overlapping by employing an end-to-end approach for feature extraction and tracking individual animals. The system utilizes a real-time Kaggle dataset and enhances performance through data augmentation techniques. The proposed model achieved an impressive accuracy of 93% on mAP@_0.5%, demonstrating its effectiveness in intelligent farm monitoring and management."," - The paper addresses the challenges in traditional livestock monitoring methods, which rely on manual observation that can be time-consuming and unreliable. Issues such as occlusion, animal overlapping, and shadows complicate accurate livestock classification and counting.

- To tackle these challenges, the paper proposes a deep learning-based monitoring system using the YOLOv5 model, which enhances feature extraction and enables effective detection and tracking of livestock under various conditions, achieving a high accuracy of 93% on mAP@_0.5%."," - The paper proposes a livestock management and monitoring system that utilizes the end-to-end deep learning model You Only Look Once version 5 (YOLOv5) for feature extraction and detection of livestock of different sizes, enabling accurate counting and tracking of individual animals in various conditions.

- It also incorporates data augmentation techniques using a real-time Kaggle dataset and employs the Roboflow application for scaling, resizing, and manipulating the dataset, while comparing the performance of YOLOv5 with Faster Regional convolutional neural networks (R-CNN) to demonstrate improved accuracy in livestock monitoring."," - The paper acknowledges existing challenges in livestock classification and counting, such as occlusion, animal overlapping, and shadow effects, which indicate a gap in the effectiveness of current monitoring systems that rely on traditional methods of manual observation.

- While the proposed system using YOLOv5 shows improved performance, the paper suggests a need for further exploration and comparison with other advanced models like Faster R-CNN, highlighting a gap in understanding the relative advantages and limitations of different deep learning architectures in livestock monitoring."," - The study utilizes a Kaggle dataset that was collected in real-time, containing various animals, to train and validate the proposed deep learning model for livestock management and monitoring.
- The dataset is enhanced through data augmentation techniques, which include scaling, resizing, and manipulation, facilitated by the Roboflow application to improve the detection and tracking performance of the YOLOv5 model."," - The paper discusses the limitations of traditional livestock monitoring methods, which rely on manual observation that can be time-consuming and unreliable. It highlights existing challenges in livestock classification and counting, such as occlusion, animal overlapping, and shadow effects, which necessitate the development of more advanced monitoring systems.

- The proposed system utilizes an end-to-end deep learning model, specifically You Only Look Once version 5 (YOLOv5), for effective livestock management. It emphasizes the model's capability for feature extraction, detection of livestock of various sizes, individual animal tracking, and its superior performance compared to Faster Regional convolutional neural networks (R-CNN), achieving an accuracy of 93% on mAP@_0.5%."," - The proposed monitoring system using the YOLOv5 deep learning model achieved an accuracy of 93% on mAP@_0.5%, demonstrating its effectiveness in livestock classification and counting under various conditions, including challenges like occlusion and animal overlapping.

- The system outperformed other Faster Regional convolutional neural networks (R-CNN) models, indicating that the YOLOv5 backbone network is a promising option for intelligent farm monitoring and management."," - The paper proposes a deep learning-based system for the management and monitoring of livestock on farms, addressing challenges such as occlusion, animal overlapping, and shadows that affect traditional manual observation methods. The system utilizes the YOLOv5 model for effective livestock classification and counting under various conditions.

- The proposed model achieves a high accuracy of 93% on mAP@_0.5% by employing data augmentation techniques and comparing its performance with Faster R-CNN models, demonstrating its potential as an intelligent solution for farm monitoring and management."," - The paper highlights challenges in current livestock classification and counting methods, including issues such as occlusion, animal overlapping, and shadow effects, which can hinder accurate monitoring and management of livestock.

- Despite the advancements presented in the proposed system using YOLOv5, the paper does not explicitly mention any limitations of the model itself, focusing instead on the improvements it offers over traditional methods and other existing systems."," - The paper aims to develop a livestock management and monitoring system that utilizes deep learning techniques, specifically the YOLOv5 model, to address challenges in traditional livestock monitoring methods, such as manual observation, which can be time-consuming and unreliable.

- Another objective is to improve livestock classification and counting under various conditions by implementing an end-to-end deep learning model that can detect and track individual animals, achieving high accuracy in performance metrics, as demonstrated by the proposed system's 93% accuracy on mAP@_0.5%."," - Future research could focus on enhancing the robustness of livestock detection and tracking systems to address challenges such as occlusion, animal overlapping, and shadow effects, which currently hinder accurate classification and counting of livestock in various environmental conditions.

- Another area for future exploration could involve the development and integration of more advanced deep learning models beyond YOLOv5, such as experimenting with different architectures of Faster Regional convolutional neural networks (R-CNN), to further improve detection accuracy and performance metrics in livestock management systems.","deep learning, yolo, cnn","Method Used: YOLOv5, data augmentation, Roboflow, Faster R-CNN."
Proceedings Article,Methods for Automated Remote Sensing and Counting of Animals,10.1109/eeae53789.2022.9831239,"Remote sensing and counting of animals is important for both livestock farming and wildlife population management. Traditional surveying methods for manual onsite counting are hard to accomplish, time-consuming, expensive and could be even dangerous. In contrast, remote detection and counting is safe, cost-effective and could be easily and frequently repeated, providing prompt information about animals’ population size and location. This paper reviews some of the most promising potential methods for automated remote detection and counting of animals, ranging from simple computer vision operations like spatial filtering, edge detection, binarization and image subtraction, to more complex machine learning and AI approaches for object detection and recognition. Many scientists worldwide are working on automation of farming and livestock management, and their experimental results really prove the great potential of computer vision and artificial intelligence for achieving that.",2022.0,"Yordan Kalmukov, Boris Evstatiev","The paper discusses various methods for automated remote sensing and counting of livestock, emphasizing the advantages of remote detection over traditional manual counting. It reviews techniques ranging from basic computer vision operations, such as spatial filtering and edge detection, to advanced machine learning and AI approaches for object detection and recognition. These methods enhance the efficiency and accuracy of livestock classification and counting, proving their potential in improving livestock farming and management practices."," - Traditional surveying methods for manual onsite counting of animals are challenging to execute, often being time-consuming, expensive, and potentially dangerous, which limits their effectiveness in livestock farming and wildlife population management.
- The paper emphasizes the advantages of remote detection and counting methods, highlighting their safety, cost-effectiveness, and ability to provide timely information about animal population size and location, thus addressing the limitations of conventional methods."," - The paper discusses traditional surveying methods for manual onsite counting of animals, highlighting their drawbacks such as being hard to accomplish, time-consuming, expensive, and potentially dangerous.
- The paper reviews potential methods for automated remote detection and counting of animals, including simple computer vision operations like spatial filtering, edge detection, binarization, and image subtraction, as well as more complex machine learning and AI approaches for object detection and recognition."," - The paper does not explicitly identify specific research gaps, but it implies that there is a need for further development and refinement of automated remote sensing methods, particularly in the application of complex machine learning and AI approaches for object detection and recognition in various environments.

- There may be a lack of comprehensive studies comparing the effectiveness and accuracy of different remote sensing techniques, such as traditional methods versus advanced computer vision operations, which could provide insights into the most efficient approaches for different types of animal populations and habitats.",," - The paper reviews various methods for automated remote sensing and counting of animals, highlighting the advantages of these methods over traditional manual onsite counting, which is often difficult, time-consuming, and potentially dangerous.
- It discusses a range of techniques from simple computer vision operations, such as spatial filtering and edge detection, to more advanced machine learning and AI approaches for object detection and recognition, showcasing the significant potential of these technologies in the field of livestock farming and wildlife population management."," - The paper reviews potential methods for automated remote detection and counting of animals, including computer vision operations like spatial filtering, edge detection, binarization, and image subtraction.
- Scientists worldwide are experimenting with computer vision and artificial intelligence approaches for automating farming and livestock management, demonstrating the significant potential of these technologies in achieving efficient animal population monitoring."," - The paper discusses the importance of remote sensing and counting of animals for livestock farming and wildlife population management, highlighting the limitations of traditional manual counting methods which are often time-consuming, expensive, and potentially dangerous. 

- It reviews various automated methods for remote detection and counting, including simple computer vision techniques and advanced machine learning approaches, emphasizing the significant potential of these technologies in enhancing the efficiency and safety of animal population monitoring."," - The paper highlights that traditional surveying methods for manual onsite counting are hard to accomplish, time-consuming, expensive, and could even be dangerous, indicating significant limitations in efficiency and safety for wildlife population management and livestock farming.

- While the paper discusses promising methods for automated remote detection and counting of animals, it does not provide specific limitations or challenges associated with these methods, suggesting a gap in addressing potential drawbacks or obstacles in their implementation."," - The paper aims to review and evaluate various methods for automated remote sensing and counting of animals, highlighting the advantages of these methods over traditional manual onsite counting, which is often difficult and resource-intensive.
- It focuses on the potential of computer vision and artificial intelligence techniques, including simple operations like spatial filtering and edge detection, as well as more advanced machine learning approaches for effective object detection and recognition in the context of livestock farming and wildlife population management."," - Future research could focus on enhancing the accuracy and efficiency of automated remote detection and counting methods by integrating more advanced machine learning and AI techniques, which could improve object detection and recognition capabilities in various environments.

- Another area for future exploration is the development of more sophisticated computer vision operations, such as improved spatial filtering and edge detection algorithms, to better handle diverse conditions and challenges in livestock farming and wildlife population management.",machine learning,"- Traditional surveying methods
- Automated remote detection and counting
- Computer vision operations (spatial filtering, edge detection, binarization, image subtraction)
- Machine learning and AI approaches for object detection and recognition"
Journal Article,Smart Animal Detection and Counting Framework for Monitoring Livestock in an Autonomous Unmanned Ground Vehicle Using Restricted Supervised Learning and Image Fusion,10.1007/S11063-021-10439-4,"Automated livestock monitoring is a promising solution for vast and isolated farmlands or cattle stations. The advancement in sensor technology and the rise of unmanned systems have paved the way for the automated systems. In this work, we propose an Unmanned Ground Vehicle (UGV) based livestock detection-counting system for fusion images using restricted supervised learning technique. For image fusion, we propose Dual-scale image Decomposition based Fusion technique (DDF) that fuses visible and thermal images. To reduce the difficulty of ground truth annotation, we introduce Seed Labels focused Object Detector (SLOD) that carefully propagates the annotation to all the object instances in the training images. Further, we propose a novel Restricted Supervised Learning (RSL) technique that produces competitive results with minimal training data. Experimental results show that the proposed RSL is more efficient and accurate when compared to other learning techniques (fully and weakly supervised). On the test data, with only five training images and five seed labels, the restricted supervised learning has improved the average precision from 4.05% (using fully supervised learning) to 80.58% (using restricted supervised learning). With 50 seed labels, the average precision is further boosted to 91.56%. The proposed model is extensively tested on benchmark animal datasets and has achieved an average accuracy of 98.3%.",2021.0,"S. Divya Meena, L. Agilandeeswari","The paper presents a livestock detection and counting system using an Unmanned Ground Vehicle (UGV) that employs a Dual-scale image Decomposition based Fusion technique (DDF) for fusing visible and thermal images. It introduces the Seed Labels focused Object Detector (SLOD) for efficient annotation propagation and a novel Restricted Supervised Learning (RSL) technique, achieving significant improvements in average precision from 4.05% to 80.58% with minimal training data. The model demonstrates an impressive average accuracy of 98.3% on benchmark datasets."," - The paper addresses the challenge of automated livestock monitoring in vast and isolated farmlands or cattle stations, highlighting the need for efficient systems that can operate in such environments using advanced sensor technology and unmanned systems.

- It focuses on the difficulty of ground truth annotation in training data for livestock detection and counting, proposing a novel Seed Labels focused Object Detector (SLOD) to facilitate the annotation process and a Restricted Supervised Learning (RSL) technique to achieve high accuracy with minimal training data."," - The paper proposes a Dual-scale image Decomposition based Fusion technique (DDF) for fusing visible and thermal images, which enhances the detection and counting of livestock in the automated monitoring system.

- A novel Restricted Supervised Learning (RSL) technique is introduced, which allows for efficient and accurate results with minimal training data, significantly improving average precision from 4.05% with fully supervised learning to 80.58% with restricted supervised learning using only five training images and five seed labels."," - The paper does not address the scalability of the proposed Restricted Supervised Learning (RSL) technique when applied to larger datasets or more complex environments, which could impact its effectiveness in real-world applications beyond the benchmark animal datasets tested.

- There is a lack of discussion on the potential limitations or challenges associated with the Dual-scale image Decomposition based Fusion technique (DDF) in varying environmental conditions, such as different lighting or weather scenarios, which may affect the accuracy of livestock detection and counting."," - The proposed model is extensively tested on benchmark animal datasets, which are not specified in detail within the provided information.
- The study demonstrates the effectiveness of the Restricted Supervised Learning (RSL) technique on these datasets, achieving an average accuracy of 98.3%."," - The paper discusses the advancements in sensor technology and unmanned systems that have enabled automated livestock monitoring, particularly in vast and isolated farmlands or cattle stations. It highlights the need for efficient detection and counting systems to facilitate this monitoring process.

- It introduces a novel approach combining Dual-scale image Decomposition based Fusion technique (DDF) for fusing visible and thermal images, along with a Seed Labels focused Object Detector (SLOD) to simplify ground truth annotation, thereby enhancing the training process for the proposed Restricted Supervised Learning (RSL) technique."," - The proposed Restricted Supervised Learning (RSL) technique significantly improved the average precision on test data, achieving 80.58% with only five training images and five seed labels, compared to 4.05% using fully supervised learning. With 50 seed labels, the average precision further increased to 91.56%.

- The model demonstrated high accuracy, achieving an average accuracy of 98.3% when extensively tested on benchmark animal datasets."," - The paper presents an automated livestock monitoring system utilizing an Unmanned Ground Vehicle (UGV) that employs a Dual-scale image Decomposition based Fusion technique (DDF) to combine visible and thermal images for improved detection and counting of livestock. It introduces a Seed Labels focused Object Detector (SLOD) to facilitate easier ground truth annotation by propagating labels across object instances in training images.

- A novel Restricted Supervised Learning (RSL) technique is proposed, which demonstrates significant improvements in accuracy with minimal training data, achieving an average precision increase from 4.05% to 80.58% with just five training images and seed labels, and further to 91.56% with 50 seed labels. The model has been extensively tested on benchmark animal datasets, achieving an impressive average accuracy of 98.3%."," - The paper does not explicitly mention any limitations; however, it implies that the reliance on minimal training data (only five training images and five seed labels) may pose challenges in achieving robustness and generalization in diverse real-world scenarios.
- The focus on restricted supervised learning and the specific techniques used for image fusion may limit the applicability of the proposed system to only certain types of environments or conditions, potentially affecting its performance in varied livestock monitoring situations."," - The research aims to develop an Unmanned Ground Vehicle (UGV) based livestock detection and counting system that utilizes a Dual-scale image Decomposition based Fusion technique (DDF) to effectively fuse visible and thermal images for improved monitoring of livestock in vast and isolated farmlands.

- The study introduces a novel Restricted Supervised Learning (RSL) technique that enhances the efficiency and accuracy of livestock detection with minimal training data, demonstrating significant improvements in average precision compared to fully and weakly supervised learning methods, thereby addressing the challenges of ground truth annotation in training datasets.",,ddf,"- Dual-scale image Decomposition based Fusion technique (DDF)
- Restricted Supervised Learning (RSL)"
Journal Article,YOLOv5-MHSA-DS: an efficient pig detection and counting method,10.1080/21642583.2024.2394428,"Accurate and efficient livestock detection and counting are crucial for agricultural intelligence. To address the obstacles created by traditional manual methods and limitations of current vision technology, we introduce YOLOv5-MHSA-DS, a novel model that integrates YOLOv5 framework with Multi-Head Self-Attention and DySample modules. Multi-Head Self-Attention excels at capturing diverse features, enhancing pig detection and counting accuracy. On the other hand, DySample dynamically adjusts sampling strategies based on input data, allowing it to focus on the most critical parts of the image and thereby significantly improving pig detection and counting performance. To validate the generalization and robustness of our proposed model, we conducted ablation experiments. The results demonstrate that YOLOv5-MHSA-DS achieves an impressive mAP of 93.8% and counting accuracy of 95.0%, surpassing other models by significant margins of 12.2% and 19.0%, respectively. ",2024.0,"Wangli Hao, Li Zhang, S H Xu, Meng Han, Fuzhong Li, Hua Yang","The paper introduces YOLOv5-MHSA-DS, a model designed for efficient livestock detection and counting, specifically focusing on pigs. It integrates Multi-Head Self-Attention to enhance feature capture and DySample for dynamic sampling strategies, improving detection accuracy. The model achieves a mean Average Precision (mAP) of 93.8% and a counting accuracy of 95.0%, outperforming other models by significant margins. This approach addresses the limitations of traditional methods and current vision technology in livestock detection and counting."," - The paper addresses the challenges posed by traditional manual methods of livestock detection and counting, which are often inefficient and time-consuming, hindering agricultural intelligence.
- It also highlights the limitations of current vision technology in accurately detecting and counting pigs, necessitating the development of a more effective solution that can enhance performance in these tasks."," - The paper introduces a novel model called YOLOv5-MHSA-DS, which integrates the YOLOv5 framework with Multi-Head Self-Attention (MHSA) and DySample modules. The Multi-Head Self-Attention component enhances the model's ability to capture diverse features, thereby improving the accuracy of pig detection and counting.

- The DySample module dynamically adjusts sampling strategies based on the input data, allowing the model to focus on the most critical parts of the image. This adaptability significantly enhances the performance of pig detection and counting compared to traditional methods."," - The paper identifies the limitations of traditional manual methods and current vision technology in livestock detection and counting, highlighting the need for more accurate and efficient solutions in agricultural intelligence.
- The proposed YOLOv5-MHSA-DS model addresses these research gaps by integrating Multi-Head Self-Attention and DySample modules to enhance pig detection and counting accuracy, showcasing significant improvements in performance compared to existing models.",,," - The YOLOv5-MHSA-DS model achieved a mean Average Precision (mAP) of 93.8%, indicating a high level of accuracy in detecting pigs compared to other models.
- The model demonstrated a counting accuracy of 95.0%, which surpasses the performance of other models by significant margins of 12.2% and 19.0%, respectively."," - The paper introduces YOLOv5-MHSA-DS, a novel model that combines the YOLOv5 framework with Multi-Head Self-Attention and DySample modules to enhance the accuracy and efficiency of pig detection and counting in agricultural settings. The Multi-Head Self-Attention mechanism improves feature capture, while DySample optimizes sampling strategies to focus on critical image areas.

- Experimental results show that YOLOv5-MHSA-DS achieves a mean Average Precision (mAP) of 93.8% and a counting accuracy of 95.0%, outperforming other models by significant margins of 12.2% and 19.0%, respectively, demonstrating its robustness and generalization capabilities.",," - The primary objective of the research is to develop an efficient and accurate method for livestock detection and counting, specifically targeting pig detection, by integrating the YOLOv5 framework with Multi-Head Self-Attention and DySample modules to overcome the limitations of traditional manual methods and existing vision technology.

- The study aims to validate the generalization and robustness of the proposed YOLOv5-MHSA-DS model through ablation experiments, demonstrating its superior performance with a mean Average Precision (mAP) of 93.8% and a counting accuracy of 95.0%, significantly outperforming other models in the field.",,yolo,"- Method: YOLOv5-MHSA-DS
- Techniques Used: YOLOv5, Multi-Head Self-Attention (MHSA), DySample modules"
Journal Article,Pig Counting Algorithm Based on Improved YOLOv5n Model with Multiscene and Fewer Number of Parameters,10.3390/ani13213411,"Pig counting is an important work in the breeding process of large-scale pig farms. In order to achieve high-precision pig identification in the conditions of pigs occluding each other, illumination difference, multiscenes, and differences in the number of pigs and the imaging size, and to also reduce the number of parameters of the model, a pig counting algorithm of improved YOLOv5n was proposed. Firstly, a multiscene dataset is created by selecting images from several different pig farms to enhance the generalization performance of the model; secondly, the Backbone of YOLOv5n was replaced by the FasterNet model to reduce the number of parameters and calculations to lay the foundation for the model to be applied to Android system; thirdly, the Neck of YOLOv5n was optimized by using the E-GFPN structure to enhance the feature fusion capability of the model; Finally, Focal EIoU loss function was used to replace the CIoU loss function of YOLOv5n to improve the model’s identification accuracy. The results showed that the AP of the improved model was 97.72%, the number of parameters, the amount of calculation, and the size of the model were reduced by 50.57%, 32.20%, and 47.21% compared with YOLOv5n, and the detection speed reached 75.87 f/s. The improved algorithm has better accuracy and robustness in multiscene and complex pig house environments, which not only ensured the accuracy of the model but also reduced the number of parameters as much as possible. Meanwhile, a pig counting application for the Android system was developed based on the optimized model, which truly realized the practical application of the technology. The improved algorithm and application could be easily extended and applied to the field of livestock and poultry counting, such as cattle, sheep, geese, etc., which has a widely practical value.",2023.0,"Yongsheng Wang, Duanli Yang, Hui Chen, Lianzeng Wang, Yuan Gao","The paper presents an improved YOLOv5n model for pig counting, which enhances detection accuracy and robustness in complex environments. It utilizes a multiscene dataset, replaces the Backbone with FasterNet to reduce parameters, and optimizes the Neck with E-GFPN for better feature fusion. The Focal EIoU loss function further improves identification accuracy. This algorithm can be extended to other livestock counting and classification tasks, such as cattle, sheep, and geese, demonstrating its practical value in the field."," - The paper addresses the challenge of achieving high-precision pig identification in large-scale pig farms, particularly under conditions where pigs may occlude each other, there are differences in illumination, and variations in the number of pigs and imaging sizes across multiple scenes.

- It also aims to reduce the number of parameters in the pig counting model to enhance its applicability on Android systems while maintaining accuracy and robustness in complex pig house environments."," - A multiscene dataset was created by selecting images from various pig farms to enhance the generalization performance of the improved YOLOv5n model, allowing it to better handle different conditions such as occlusion, illumination differences, and varying numbers of pigs.

- The Backbone of YOLOv5n was replaced with the FasterNet model to reduce the number of parameters and calculations, while the Neck was optimized using the E-GFPN structure to improve feature fusion capability, and the Focal EIoU loss function was implemented to enhance identification accuracy compared to the original CIoU loss function."," - The paper does not address the potential limitations of the improved YOLOv5n model in extremely crowded environments where pigs may be heavily occluded, which could affect the accuracy of counting and identification.
- There is no discussion on the scalability of the proposed algorithm when applied to different species of livestock beyond pigs, such as the specific challenges that may arise when counting cattle, sheep, or geese in various farming conditions."," - A multiscene dataset was created by selecting images from several different pig farms to enhance the generalization performance of the model, addressing challenges such as pigs occluding each other and varying illumination conditions.
- The dataset was specifically designed to improve the model's accuracy in complex environments, ensuring effective pig identification across different scenes and conditions."," - The paper presents an improved pig counting algorithm based on the YOLOv5n model, addressing challenges such as occlusion, illumination differences, and varying pig numbers and sizes in multiscene environments. It emphasizes the importance of high-precision identification in large-scale pig farming.

- The proposed algorithm enhances the YOLOv5n model by replacing its Backbone with the FasterNet model to reduce parameters and calculations, optimizing the Neck with the E-GFPN structure for better feature fusion, and utilizing the Focal EIoU loss function to improve identification accuracy, resulting in significant performance improvements."," - The improved YOLOv5n model achieved an Average Precision (AP) of 97.72%, demonstrating high identification accuracy for pig counting in complex environments, while also reducing the number of parameters by 50.57%, the amount of calculation by 32.20%, and the model size by 47.21% compared to the original YOLOv5n model.

- The detection speed of the improved algorithm reached 75.87 frames per second (f/s), indicating that the model not only maintained accuracy and robustness in multiscene conditions but also provided efficient performance suitable for practical applications, such as a pig counting application developed for the Android system."," - The paper presents an improved pig counting algorithm based on the YOLOv5n model, designed to enhance pig identification accuracy in challenging conditions such as occlusion, varying illumination, and different pig farm environments. The model incorporates a multiscene dataset, replaces the Backbone with the FasterNet model to reduce parameters, and optimizes the Neck using the E-GFPN structure for better feature fusion.

- The results demonstrate that the improved model achieves an average precision (AP) of 97.72%, while significantly reducing the number of parameters, calculations, and model size by over 50%, 32%, and 47% respectively compared to the original YOLOv5n. Additionally, the detection speed reaches 75.87 frames per second, and a practical application for Android systems has been developed, showcasing the model's applicability in livestock counting beyond pigs."," - The paper does not explicitly mention any limitations of the improved YOLOv5n model; however, it implies challenges such as the need for high-precision pig identification in conditions where pigs occlude each other, face illumination differences, and vary in number and imaging size, which could affect the model's performance in real-world applications.

- While the model shows improved accuracy and reduced parameters, the abstract does not discuss potential trade-offs or limitations related to the model's generalization across different environments or its performance in scenarios not covered by the multiscene dataset."," - The research aims to achieve high-precision pig identification in challenging conditions such as occlusion, varying illumination, and different scenes, while also addressing the variability in the number of pigs and imaging sizes. This is accomplished through the development of an improved YOLOv5n model tailored for pig counting.

- Another objective is to reduce the number of parameters and calculations of the model to facilitate its application on Android systems. This includes optimizing the model's architecture by replacing the Backbone with the FasterNet model and enhancing feature fusion capabilities through the E-GFPN structure, ultimately improving detection speed and accuracy."," - Future research could focus on further enhancing the generalization performance of the pig counting algorithm by creating even more diverse multiscene datasets that include various lighting conditions, pig breeds, and farm environments to improve accuracy in real-world applications.

- Another area for future exploration could involve optimizing the model for deployment on other mobile platforms beyond Android, as well as adapting the algorithm for counting different types of livestock and poultry, such as cattle, sheep, and geese, to broaden its applicability in the agricultural sector.",yolo,"Method: YOLOv5n, FasterNet, E-GFPN, Focal EIoU loss function"
Journal Article,Detection and Counting Method of Pigs Based on YOLOV5_Plus: A Combination of YOLOV5 and Attention Mechanism,10.1155/2022/7078670,"Information-based pig detection and counting is the trend in smart animal husbandry development. Cameras can efficiently collect farm information and combine it with artificial intelligence technology to assist breeders in real-time monitoring and analysis of farming. In order to improve the speed and accuracy of pig detection and counting, an advanced improved YOLO_v5 method for pig detection and counting based on the attention mechanism is proposed. The model is named as YOLOV5_Plus. This article utilizes a series of data augmentation methods, including translation, color augmentation, rescaling, and mosaic. The proposed model performs feature extraction on the original image with a backbone network, detects pigs of different sizes with three detection heads, and counts the detected anchor frames. Different versions of YOLOV5 are compared, and YOLOV5x is selected as the baseline model for the best performance. Attention modules are smartly combined with the model so that the model can better handle overlapping and misidentification. YOLOV5_Plus can achieve an accuracy of 0.989, a recall of 0.996, mAP@.50 of 0.994, and mAP@.50:.95 of 0.796, which outperforms all competing models. The inference time per image during detection is only 24.1 ms. YOLOV5_Plus model achieves real-time pig number and location detection, which is meaningful for promoting smart animal husbandry and saving labor costs in farming enterprises.",2022.0,Zishun Zhou,"The paper presents YOLOV5_Plus, an advanced method for livestock detection, counting, and classification, specifically for pigs. It utilizes an attention mechanism to enhance detection accuracy, achieving 0.989 accuracy and 0.996 recall. The model employs data augmentation techniques and features three detection heads to identify pigs of various sizes. YOLOV5_Plus processes images in real-time with an inference time of 24.1 ms, making it effective for smart animal husbandry and reducing labor costs in farming enterprises."," - The paper addresses the need for efficient and accurate pig detection and counting in smart animal husbandry, highlighting the importance of real-time monitoring and analysis for breeders using advanced technology.
- It identifies the challenges of overlapping and misidentification in pig detection, proposing an improved YOLO_v5 method that incorporates an attention mechanism to enhance the model's performance in these areas."," - The paper proposes an advanced improved YOLO_v5 method for pig detection and counting, named YOLOV5_Plus, which incorporates an attention mechanism to enhance the model's ability to handle overlapping and misidentification of pigs during detection.

- A series of data augmentation methods are utilized, including translation, color augmentation, rescaling, and mosaic, to improve the speed and accuracy of pig detection and counting in the YOLOV5_Plus model.",,,," - The YOLOV5_Plus model achieves an accuracy of 0.989, a recall of 0.996, mAP@.50 of 0.994, and mAP@.50:.95 of 0.796, demonstrating superior performance compared to competing models in pig detection and counting.

- The model processes images with an inference time of only 24.1 ms per image, enabling real-time detection of pig numbers and locations, which is beneficial for enhancing smart animal husbandry and reducing labor costs in farming enterprises."," - The paper presents YOLOV5_Plus, an advanced pig detection and counting method that combines YOLOV5 with an attention mechanism to enhance speed and accuracy in smart animal husbandry. The model employs various data augmentation techniques and features a backbone network for effective feature extraction and detection of pigs of different sizes.

- YOLOV5_Plus achieves impressive performance metrics, including an accuracy of 0.989, recall of 0.996, and mAP scores of 0.994 and 0.796, while maintaining a fast inference time of 24.1 ms per image, making it suitable for real-time monitoring and analysis in farming enterprises.",," - The primary objective of the research is to develop an advanced pig detection and counting method, named YOLOV5_Plus, which combines the YOLOV5 model with an attention mechanism to enhance the speed and accuracy of detecting and counting pigs in real-time monitoring systems for smart animal husbandry.

- The study aims to utilize various data augmentation techniques, such as translation, color augmentation, rescaling, and mosaic, to improve the model's performance, enabling it to effectively handle overlapping and misidentification of pigs, ultimately achieving high accuracy and efficiency in pig detection and counting.",,yolo,"- Method Used: YOLO_v5 (improved with attention mechanism)  
- Data Augmentation Techniques: Translation, color augmentation, rescaling, mosaic"
Proceedings Article,Counting Broiler from Poultry House Video Using Faster Region-based Convolutional Neural Networks,10.1109/isitia56226.2022.9855276,"In a poultry house, livestock object detection is essential for farmers to prepare the amount of food. Counting broiler can be done through video monitoring placed at the top. If video processing is done automatically, it will collide with memory, especially with many frames. Image approach can be taken considering the broiler is in a poultry house or closed room, so that one frame per second processing is quite representative. In addition, the observed broilers are considered to have a similar shape, and their identity is ignored. Therefore, this study proposed using the Faster Region-based Convolutional Neural Network (Faster R-CNN) method for broiler livestock. Faster R-CNN is one of the models of object detection that can be used to count the number of objects. In Faster RCNN, choosing the proper architecture and configuration must be considered to find good performance. The experiment showed that using ResNet-101, Faster R-CNN achieves the best accuracy than other famous CNN architecture, such as ResNet-50 and ResNeXt-101, with an average precision of 50% achieving 92.8% and average precision of 75%, achieving 78.1%. The ResNet-101 architecture has more convolution depth. The depth causes ResNet-101 to do better feature extraction even though ResNeXt-101 has more depth convolution, but it made ResNeXt-101 too heavy to do feature extraction, making ResNeXt-101 have the largest size model. However, the Faster R-CNN model using ResNet-101 is better implemented for real-time detection. ",2022.0,,"The paper focuses on livestock detection and counting specifically for broilers using the Faster Region-based Convolutional Neural Network (Faster R-CNN) method. It emphasizes counting broilers through video monitoring, where identity is ignored, and similar shapes are considered. The study demonstrates that using ResNet-101 architecture yields the best accuracy for counting, achieving an average precision of 92.8% and 78.1% for different metrics, making it suitable for real-time detection in poultry houses."," - The problem of counting broilers in a poultry house is crucial for farmers to manage food preparation, and it can be effectively addressed through video monitoring. However, automatic video processing can lead to memory issues, especially when dealing with a large number of frames.

- The study proposes using the Faster Region-based Convolutional Neural Network (Faster R-CNN) for broiler counting, as it allows for effective object detection in a closed environment where broilers have similar shapes and identities can be ignored, thus enabling efficient processing at a rate of one frame per second."," - The study proposed using the Faster Region-based Convolutional Neural Network (Faster R-CNN) method for counting broiler livestock in a poultry house, which is an object detection model suitable for counting the number of objects in video monitoring.
  
- The experiment utilized different architectures within the Faster R-CNN framework, specifically comparing ResNet-101, ResNet-50, and ResNeXt-101, with ResNet-101 achieving the best accuracy due to its deeper convolution layers, which enhance feature extraction capabilities."," - The study focuses on counting broilers in a poultry house using the Faster R-CNN method, but it does not address the potential challenges of varying lighting conditions and occlusions that may affect the accuracy of object detection in real-world scenarios. This gap suggests a need for further research on improving detection robustness under different environmental conditions.

- While the paper demonstrates that ResNet-101 outperforms other architectures in terms of accuracy, it does not explore the trade-offs between model complexity and computational efficiency. Future research could investigate optimizing the model for faster processing times without significantly compromising accuracy, especially for real-time applications in poultry monitoring.",," - The study focuses on the use of Faster Region-based Convolutional Neural Networks (Faster R-CNN) for counting broilers in a poultry house, emphasizing the importance of livestock object detection for farmers to manage food preparation effectively. It highlights the challenges of video processing, particularly memory issues when dealing with numerous frames, and suggests processing one frame per second as a representative approach due to the similar shape of the broilers and the disregard for individual identities.

- The research compares different CNN architectures, specifically ResNet-101, ResNet-50, and ResNeXt-101, to determine the best performance for broiler counting. The findings indicate that ResNet-101 outperforms the other architectures in terms of accuracy, achieving an average precision of 92.8% at 50% and 78.1% at 75%, due to its deeper convolution layers that enhance feature extraction, while also noting that ResNeXt-101, despite its greater depth, is less effective due to its larger model size."," - The experiment demonstrated that the Faster R-CNN model using ResNet-101 achieved the best accuracy compared to other CNN architectures, with an average precision of 92.8% at 50% and 78.1% at 75%. This indicates that ResNet-101 is effective for counting broilers in a poultry house setting.

- The study highlighted that the depth of the ResNet-101 architecture allows for better feature extraction, making it more suitable for real-time detection, despite ResNeXt-101 having a greater convolution depth but being too heavy for efficient feature extraction."," - The study focuses on using Faster Region-based Convolutional Neural Networks (Faster R-CNN) for counting broilers in a poultry house through video monitoring, emphasizing the importance of livestock object detection for food preparation by farmers. The approach involves processing one frame per second to manage memory effectively while ignoring individual identities of the broilers due to their similar shapes.

- The experiments demonstrated that the ResNet-101 architecture within the Faster R-CNN model outperformed other architectures like ResNet-50 and ResNeXt-101, achieving an average precision of 92.8% at 50% and 78.1% at 75%. The depth of ResNet-101 allows for better feature extraction, making it more suitable for real-time detection compared to the heavier ResNeXt-101 model."," - The study acknowledges that automatic video processing for counting broilers can lead to memory issues, particularly when dealing with a large number of frames, which may hinder efficient processing.
- The identity of individual broilers is ignored in the counting process, which may limit the ability to track specific animals or assess their individual health and growth, focusing solely on the overall count instead."," - The research aims to develop an automated system for counting broiler livestock in a poultry house using video monitoring, which helps farmers prepare the appropriate amount of food for the animals.
- The study proposes the use of the Faster Region-based Convolutional Neural Network (Faster R-CNN) method to enhance object detection accuracy, specifically focusing on optimizing the architecture and configuration to achieve better performance in counting broilers.",,cnn,"Method: Faster R-CNN (with ResNet-101, ResNet-50, and ResNeXt-101 architectures)"
Journal Article,"Multi-attribute, graph-based approach for duplicate cattle removal and counting in large pasture areas from multiple aerial images",10.1016/j.compag.2024.108828,"In this study, we address the challenges of counting cattle in large pasture areas using Unmanned Aerial Vehicles (UAVs) equipped with high-resolution cameras. Traditional manual counting methods are laborious and error-prone, while existing automated approaches struggle with duplicate animal detection. To overcome these limitations, we propose a novel graph-based method that incorporates multiple-attributes, including velocity, direction, state (lying down or standing), color, and distance, to improve duplicate removal and counting accuracy. We conducted extensive experiments involving automated hyper-parameter learning to effectively integrate these attributes into our method. By employing a Ford–Fulkerson graph algorithm, we detect and remove duplicated cattle based on their multiple attributes. An ablation study validates the contribution of each attribute. Additionally, we provide new datasets of drone images captured in large pastures to support research in this field. Our results demonstrate that our proposed method outperforms state-of-the-art techniques, achieving an average percentage error of 2.34%. Comparisons with mosaic-based and other graph-based methods validate the effectiveness of our approach, which contributes to more efficient cattle counting practices and enhances livestock management in agriculture. ",2024.0,"V.H.A. Soares, M.A. Ponti, R.J.G.B. Campello","The study presents a novel graph-based method for livestock detection, counting, and classification using UAV-captured images. It incorporates multiple attributes such as velocity, direction, state (lying down or standing), color, and distance to enhance duplicate removal and counting accuracy. The method employs the Ford–Fulkerson graph algorithm for effective duplicate detection. Extensive experiments demonstrate that this approach significantly outperforms existing techniques, achieving an average percentage error of only 2.34%, thus improving livestock management practices in agriculture."," - The study addresses the challenges of counting cattle in large pasture areas using Unmanned Aerial Vehicles (UAVs) with high-resolution cameras, highlighting that traditional manual counting methods are laborious and prone to errors, while existing automated approaches struggle with accurately detecting duplicate animals.

- To improve counting accuracy and duplicate removal, the paper proposes a novel graph-based method that utilizes multiple attributes such as velocity, direction, state (lying down or standing), color, and distance, which are integrated through automated hyper-parameter learning and a Ford–Fulkerson graph algorithm."," - The study proposes a novel graph-based method that utilizes multiple attributes such as velocity, direction, state (lying down or standing), color, and distance to improve the accuracy of duplicate cattle removal and counting in large pasture areas. This method integrates these attributes through automated hyper-parameter learning.

- The Ford–Fulkerson graph algorithm is employed to detect and remove duplicated cattle based on the identified multiple attributes, enhancing the overall counting accuracy and efficiency compared to traditional and existing automated approaches."," - The paper addresses the challenge of duplicate animal detection in automated cattle counting but does not explore the potential limitations or challenges of the proposed graph-based method in varying environmental conditions or different types of pasture landscapes, which could affect the accuracy and reliability of the results.

- While the study provides new datasets of drone images for research, it does not discuss the availability or diversity of these datasets in terms of different cattle breeds, sizes, or behaviors, which could limit the generalizability of the proposed method across various agricultural settings."," - The study provides new datasets of drone images that were captured in large pastures, specifically designed to support research in the field of cattle counting and management.
- These datasets are utilized to validate the proposed graph-based method for duplicate cattle removal and counting, enhancing the accuracy and efficiency of automated cattle counting practices."," - The study highlights the limitations of traditional manual counting methods for cattle, which are labor-intensive and prone to errors, as well as the challenges faced by existing automated approaches in accurately detecting duplicate animals in large pasture areas.

- The proposed method utilizes a novel graph-based approach that integrates multiple attributes such as velocity, direction, state (lying down or standing), color, and distance to enhance the accuracy of duplicate removal and cattle counting, demonstrating superior performance compared to state-of-the-art techniques."," - The proposed graph-based method for duplicate cattle removal and counting achieved an average percentage error of 2.34%, demonstrating significant accuracy improvements over traditional and existing automated approaches.
- Extensive experiments, including an ablation study, validated the contribution of multiple attributes (velocity, direction, state, color, and distance) in enhancing the effectiveness of duplicate detection and counting in large pasture areas."," - The study presents a novel graph-based method for counting cattle in large pasture areas using UAVs with high-resolution cameras, addressing the limitations of traditional manual counting and existing automated approaches that struggle with duplicate detection. The method incorporates multiple attributes such as velocity, direction, state, color, and distance to enhance counting accuracy and remove duplicates.

- Extensive experiments, including automated hyper-parameter learning and an ablation study, validate the effectiveness of the proposed method, which employs the Ford–Fulkerson graph algorithm. The results show a significant improvement over state-of-the-art techniques, achieving an average percentage error of 2.34%, thereby contributing to more efficient cattle counting and better livestock management practices."," - Traditional manual counting methods for cattle are laborious and prone to errors, making them inefficient for large pasture areas. This highlights the need for automated solutions to improve accuracy and reduce labor intensity in cattle counting.

- Existing automated approaches struggle with duplicate animal detection, which can lead to inaccuracies in counting and livestock management. The proposed method aims to address this limitation by utilizing a multi-attribute, graph-based approach to effectively remove duplicates and enhance counting accuracy."," - The primary objective of the research is to develop a novel graph-based method that improves the accuracy of cattle counting in large pasture areas by effectively detecting and removing duplicate animals using multiple attributes such as velocity, direction, state (lying down or standing), color, and distance.

- The study aims to validate the proposed method's effectiveness through extensive experiments, including automated hyper-parameter learning and an ablation study, ultimately demonstrating superior performance compared to existing state-of-the-art techniques with an average percentage error of 2.34%."," - Future research could focus on enhancing the graph-based method by integrating additional attributes or advanced machine learning techniques to further improve the accuracy of duplicate cattle detection and counting in various environmental conditions and pasture types.

- Another area for future exploration could involve the development of real-time processing capabilities for the proposed method, allowing for immediate analysis of aerial images captured by UAVs, which would significantly benefit livestock management practices in dynamic agricultural settings.",,Graph-based method with Ford–Fulkerson algorithm.
Journal Article,SCS-YOLOv5s: A cattle detection and counting method for complex breeding environment,10.3233/jifs-237231,"Cattle detection and counting is one of the most important topics in the development of modern agriculture and animal husbandry. The traditional manual monitoring methods are inefficient and constrained by factors such as site. To solve the above problems, a SCS-YOLOv5 cattle detection and counting model for complex breeding scenarios is proposed. The original SPPF module is replaced in the YOLOv5 backbone network with a CSP structured SPPFCSPC. A CA (Coordinate Attention) mechanism is added to the neck network, as well as the SC (Standard Convolution) of the Neck network is replaced with a light convolution GSConv and Slim Neck is introduced, and training strategies such as multi-scale training are also employed. The experimental results show that the proposed method enhances the feature extraction ability and feature fusion ability, balances the localization accuracy and detection speed, and improves the use effect in real farming scenarios. The Precision of the improved network model is improved from 93.2% to 95.5%, mAP@0.5 is improved from 94.5% to 95.2%, the RMSE is reduced by about 0.03, and the FPS reaches 88. Compared with other mainstream algorithms, the comprehensive performance of SCS-YOLOv5 s is in a leading position, with fewer missed and false detections, and the strong robustness and generalization ability of this model are proved on multi-category public datasets. Applying the improvement ideas in this paper to YOLOv8 s also yields an increase in accuracy. The improved method in this study can greatly improve the accuracy of cattle detection and counting in complex environments, and has good real-time performance, so as to provide technical support for large-scale cattle breeding.",2024.0,"Zhi Weng, Rongfei Bai, Zhiqiang Zhang","The paper presents the SCS-YOLOv5s model, which enhances cattle detection and counting in complex breeding environments. It incorporates a CSP structured SPPFCSPC in the YOLOv5 backbone, a CA mechanism in the neck network, and employs light convolution GSConv. The model achieves improved precision (from 93.2% to 95.5%) and mAP@0.5 (from 94.5% to 95.2%), demonstrating strong robustness and generalization for livestock detection and counting, making it suitable for large-scale cattle breeding applications."," - The paper addresses the inefficiency of traditional manual monitoring methods for cattle detection and counting, which are constrained by various site factors, making them unsuitable for modern agricultural practices.
- To overcome these challenges, the authors propose a SCS-YOLOv5 model specifically designed for complex breeding environments, enhancing feature extraction and fusion capabilities while improving localization accuracy and detection speed."," - The SCS-YOLOv5 model incorporates a CSP structured SPPFCSPC in place of the original SPPF module in the YOLOv5 backbone network, enhancing feature extraction and fusion capabilities for improved cattle detection in complex breeding environments.

- The model integrates a Coordinate Attention (CA) mechanism in the neck network, replaces the Standard Convolution (SC) with a light convolution GSConv, and introduces a Slim Neck, along with employing multi-scale training strategies to balance localization accuracy and detection speed.",," - The study demonstrates the strong robustness and generalization ability of the SCS-YOLOv5s model on multi-category public datasets, indicating that various datasets were utilized for testing the model's performance.
- Specific details about the datasets used in the study are not provided in the abstract."," - The paper addresses the inefficiencies of traditional manual monitoring methods in cattle detection and counting, which are constrained by various site factors, highlighting the need for an improved automated solution in modern agriculture and animal husbandry.
- It presents the SCS-YOLOv5 model, which incorporates several enhancements such as the replacement of the original SPPF module with a CSP structured SPPFCSPC, the addition of a Coordinate Attention mechanism, and the introduction of light convolution techniques, resulting in improved precision and detection capabilities in complex breeding environments."," - The proposed SCS-YOLOv5 model improved the Precision from 93.2% to 95.5%, and the mean Average Precision (mAP@0.5) increased from 94.5% to 95.2%, demonstrating enhanced accuracy in cattle detection and counting.
- The model achieved a reduction in Root Mean Square Error (RMSE) by approximately 0.03 and reached a Frames Per Second (FPS) rate of 88, indicating improved real-time performance and efficiency in complex breeding environments."," - The paper presents the SCS-YOLOv5 cattle detection and counting model, which addresses inefficiencies in traditional manual monitoring methods in complex breeding environments by enhancing feature extraction and fusion capabilities, leading to improved precision from 93.2% to 95.5% and mAP@0.5 from 94.5% to 95.2%.

- The model incorporates several innovations, including a CSP structured SPPFCSPC in the backbone network, a CA mechanism in the neck network, and the introduction of light convolution GSConv, resulting in a robust performance with a reduced RMSE and a frame rate of 88 FPS, demonstrating strong robustness and generalization on multi-category public datasets.",," - The research aims to develop a SCS-YOLOv5 cattle detection and counting model specifically designed for complex breeding environments, addressing the inefficiencies and constraints of traditional manual monitoring methods in agriculture and animal husbandry.

- The study focuses on enhancing the feature extraction and fusion capabilities of the YOLOv5 model by implementing structural modifications, such as replacing the original SPPF module with a CSP structured SPPFCSPC, adding a Coordinate Attention mechanism, and employing advanced training strategies to improve detection accuracy and speed in real farming scenarios."," - Future research could explore the application of the SCS-YOLOv5 model in various agricultural settings beyond cattle detection, such as detecting and counting other livestock or wildlife, to assess its versatility and effectiveness in different environments and conditions.

- Investigating the integration of advanced machine learning techniques or additional sensor data (e.g., thermal imaging, drones) with the SCS-YOLOv5 model could enhance its robustness and accuracy in complex breeding scenarios, potentially leading to improved monitoring and management of livestock.",yolo,"- Method: YOLOv5 
- Techniques: CSP structured SPPFCSPC, Coordinate Attention (CA) mechanism, GSConv (light convolution), Slim Neck, multi-scale training strategies."
Journal Article,Animal Detection and Counting from UAV Images Using Convolutional Neural Networks,10.3390/drones7030179,"In the last decade, small unmanned aerial vehicles (UAVs/drones) have become increasingly popular in the airborne observation of large areas for many purposes, such as the monitoring of agricultural areas, the tracking of wild animals in their natural habitats, and the counting of livestock. Coupled with deep learning, they allow for automatic image processing and recognition. The aim of this work was to detect and count the deer population in northwestern Serbia from such images using deep neural networks, a tedious process that otherwise requires a lot of time and effort. In this paper, we present and compare the performance of several state-of-the-art network architectures, trained on a manually annotated set of images, and use it to predict the presence of objects in the rest of the dataset. We implemented three versions of the You Only Look Once (YOLO) architecture and a Single Shot Multibox Detector (SSD) to detect deer in a dense forest environment and measured their performance based on mean average precision (mAP), precision, recall, and F1 score. Moreover, we also evaluated the models based on their real-time performance. The results showed that the selected models were able to detect deer with a mean average precision of up to 70.45% and a confidence score of up to a 99%. The highest precision was achieved by the fourth version of YOLO with 86%, as well as the highest recall value of 75%. Its compressed version achieved slightly lower results, with 83% mAP in its best case, but it demonstrated four times better real-time performance. The counting function was applied on the best-performing models, providing us with the exact distribution of deer over all images. Yolov4 obtained an error of 8.3% in counting, while Yolov4-tiny mistook 12 deer, which accounted for an error of 7.1%.",2023.0,"Nemanja Rancic, Bosko Blagojevic, Atila Bezdan, Bojana Ivošević, Bojan Tubić, Milica Vranešević, Branislav Pejak, Vladimir Crnojevic, Oskar Marko","The paper focuses on detecting and counting deer populations using UAV images and deep learning, specifically through convolutional neural networks like YOLO and SSD. While it primarily addresses wildlife monitoring, the methodologies can be adapted for livestock detection and counting. The automation of livestock counting enhances farm production monitoring, similar to the deer detection process. The study highlights the effectiveness of one-stage detectors for real-time applications, which can be beneficial for livestock management as well."," - The paper addresses the challenge of detecting and counting the deer population in northwestern Serbia using images captured by small unmanned aerial vehicles (UAVs). This task is typically labor-intensive and time-consuming, necessitating an automated solution through the application of deep learning techniques.

- The authors compare the performance of various state-of-the-art deep learning architectures, specifically three versions of the You Only Look Once (YOLO) and a Single Shot Multibox Detector (SSD), to evaluate their effectiveness in accurately detecting deer in dense forest environments, measuring their performance through metrics such as mean average precision (mAP), precision, recall, and F1 score."," - The paper utilized the tiling function as part of the preprocessing methodology, which involved dividing large images into smaller, non-overlapping tiles to improve the detection of small objects against a large background. This approach allowed the models to focus on specific regions of the image, enhancing the accuracy and efficiency of the analysis.

- Several state-of-the-art network architectures were implemented for object detection, including three versions of the You Only Look Once (YOLO) architecture and a Single Shot Multibox Detector (SSD). These models were trained on a manually annotated set of images, and their performance was evaluated based on metrics such as mean average precision (mAP), precision, recall, and F1 score, as well as their real-time performance capabilities."," - The detection of small target objects posed significant challenges due to the diversity of input images, which included variations in resolution and size, as well as the overlap of small objects by other objects. This often resulted in false negative predictions, where the model failed to detect a deer that was actually present, indicating a need for improved algorithms or techniques to enhance detection accuracy in cluttered environments.

- The study highlighted issues with distinguishing animals from stationary objects like tree trunks and rocks when viewed from above, which complicated the detection process. This suggests a gap in the current methodologies that could be addressed by developing more sophisticated image processing techniques or incorporating additional data sources to improve object recognition in complex backgrounds."," - The dataset consisted of 30 UAV images collected from the northwestern region of Serbia, specifically from the hunting ground of Plavna, which covers a total area of 2619 ha, with 630 ha being enclosed. The images were captured using three different UAVs: DJI Phantom 4 Pro V2.0 (4608 x 3456 pixels), Parrot Company SenseFly eBee (4864 x 3648 pixels), and DJI Inspire 1 (4000 x 3000 pixels).

- To enhance the dataset for model training and evaluation, the original 30 images were divided into smaller pieces using a tiling function, resulting in 2340 new smaller images, each sized 416 x 416 x 3 pixels. Out of these, 120 images contained ground truth data, which included manually annotated bounding boxes for the deer present in the images."," - The paper discusses the increasing popularity of small unmanned aerial vehicles (UAVs) in various applications, particularly in monitoring agricultural areas, tracking wild animals, and counting livestock, highlighting their effectiveness when combined with deep learning for automatic image processing and recognition.

- It presents a comparative analysis of several state-of-the-art deep learning architectures, specifically focusing on the performance of different versions of the You Only Look Once (YOLO) and Single Shot Multibox Detector (SSD) models in detecting and counting deer populations in a dense forest environment, emphasizing the trade-offs between precision, recall, and real-time performance."," - The best-performing model, YOLOv4, achieved a mean average precision (mAP) of 86% and a recall value of 75%, with an error of 8.3% in counting the deer population. The compressed version, YOLOv4-tiny, had a slightly lower mAP of 83% but demonstrated four times better real-time performance, resulting in a counting error of 7.1% by mistaking 12 deer.

- The study compared several state-of-the-art network architectures, including three versions of YOLO and a Single Shot Multibox Detector (SSD), with the results indicating that the models could detect deer with a mean average precision of up to 70.45% and a confidence score of up to 99%. The performance evaluation metrics used included precision, recall, and F1 score, highlighting the effectiveness of the models in detecting deer in a dense forest environment."," - The paper discusses the use of small unmanned aerial vehicles (UAVs) combined with deep learning techniques to automatically detect and count deer populations in northwestern Serbia, a process that traditionally requires significant time and effort. The authors implemented and compared various state-of-the-art neural network architectures, including multiple versions of the You Only Look Once (YOLO) and Single Shot Multibox Detector (SSD), to evaluate their performance in detecting deer in dense forest environments.

- Results indicated that the best-performing models achieved a mean average precision (mAP) of up to 70.45% and a confidence score of 99%. Specifically, the fourth version of YOLO demonstrated the highest precision at 86% and a recall of 75%, while the counting function applied to these models revealed an error rate of 8.3% for YOLOv4 and 7.1% for its compressed version, YOLOv4-tiny, which miscounted 12 deer."," - The detection of small target objects posed significant challenges due to the diversity of input images, which varied in resolution and size. This variability often led to overlapping objects, resulting in false negative predictions where the model failed to detect a deer that was actually present.

- The complexity of distinguishing animals from stationary objects, such as tree trunks and rocks, further complicated detection efforts. In large images, it was often difficult for the naked eye to identify objects of interest, necessitating pixel-level analysis. However, low contrast and cluttered backgrounds made it challenging to determine whether a specific region or pixel represented an animal or merely the background."," - The primary objective of the research was to detect and count the deer population in northwestern Serbia using images captured by small unmanned aerial vehicles (UAVs) and deep neural networks, aiming to automate a process that is typically time-consuming and labor-intensive.

- The study involved comparing the performance of several state-of-the-art network architectures, specifically three versions of the You Only Look Once (YOLO) architecture and a Single Shot Multibox Detector (SSD), to evaluate their effectiveness in detecting deer in dense forest environments based on metrics such as mean average precision (mAP), precision, recall, and F1 score."," - Future research will focus on extending the current models, which are trained to recognize only deer, to detect and track other types of animals. This will require sufficient training data and will involve experiments using different animal databases to enhance the versatility of the detection system.

- Another area for future work includes increasing the resolution of input images to 512 x 512 or 608 x 608, as recommended by the authors of the YOLO network. This approach aims to improve the mean average precision (mAP) of the models, particularly for the YOLOv4 architecture, which has already shown promising results in terms of detection accuracy.",yolo,"- Preprocessing Method: Tiling function
- Object Detection Methods: YOLO (You Only Look Once), SSD (Single Shot Multibox Detector)"
Proceedings Article,An Improved Sheep Counting Detection Method Based on Fusion Allocation Strategy and Multi-Objective Loss Function,10.1109/ispds58840.2023.10235543,"Chinais a big country in animal husbandry, and sheep breeding is an important part of animal husbandry. With the scale and modernization of the sheep farm, good management of the sheep shed is an essential factor to ensure the health of the sheep, including counting the sheep number in real time. This paper proposes an object detection method based on fusion allocation strategy and multi-objective loss function for sheep number counting. The fusion allocation strategy selects the pre-selection box based on the cross-grid strategy, and then calculates the minimum allocation loss function to distinguish the positive and negative samples, and the multi-objective loss function changes the confidence loss to VarifocalLoss, which strengthens the detection performance of the model for multi-objective situation. The experimental training was carried out on a single 1080Ti GPU, and the comparative analysis was based on the attention depthwise YOLO detection model. The result shows that the mAP value of the model reached 87.81%, which is superior to the previous model, and proves the feasibility of the model in actual application scenario.",2023.0,"Xingyu Chen, Xiaodong Ye, Miao Li, Zhixian Song, Hualong Li, Xuan Jiang Yang, Xianwang Liu, Panpan Guo","The paper presents an improved method for sheep counting detection, focusing on livestock detection and classification. It utilizes a fusion allocation strategy to select pre-selection boxes and a multi-objective loss function, specifically VarifocalLoss, to enhance detection performance in multi-objective scenarios. The model achieved a mean Average Precision (mAP) of 87.81%, demonstrating its effectiveness in accurately counting and classifying sheep in real-time, which is crucial for effective management in modern sheep farming."," - The paper addresses the challenge of real-time sheep counting in modern sheep farms, which is crucial for effective management and ensuring the health of the sheep as the scale of sheep breeding increases.
- It proposes an improved object detection method that utilizes a fusion allocation strategy and a multi-objective loss function to enhance the accuracy and performance of sheep counting, thereby overcoming limitations of previous models."," - The paper proposes an object detection method that utilizes a fusion allocation strategy, which selects the pre-selection box based on a cross-grid strategy and calculates the minimum allocation loss function to effectively distinguish between positive and negative samples.

- It also employs a multi-objective loss function that modifies the confidence loss to VarifocalLoss, enhancing the model's detection performance in multi-objective situations.",,,," - The proposed object detection method achieved a mean Average Precision (mAP) value of 87.81%, indicating a significant improvement in sheep counting accuracy compared to previous models.
- The experimental training was conducted on a single 1080Ti GPU, and the results demonstrate the model's feasibility for real-world applications in sheep farm management."," - The paper presents an improved object detection method for counting sheep in real-time, utilizing a fusion allocation strategy and a multi-objective loss function to enhance detection performance in sheep farming management.
- Experimental results demonstrate that the proposed model achieved a mean Average Precision (mAP) value of 87.81%, outperforming previous models and confirming its practical applicability in actual sheep counting scenarios.",," - The research aims to develop an improved object detection method specifically for counting sheep in real-time, which is crucial for effective management in modern sheep farming.
- The study introduces a fusion allocation strategy and a multi-objective loss function to enhance the detection performance of the model, achieving a mean Average Precision (mAP) value of 87.81%, demonstrating its superiority over previous models.",,,Method Used: Object Detection with Fusion Allocation Strategy and VarifocalLoss.
Proceedings Article,A Sheep Detection and Counting System based on Light Attention YOLO Model,10.1109/cac57257.2022.10055935,"With the construction of modern sheep farms, it is of great significance to achieve accurate and real-time detection as well as counting on sheep. In order to solve the problem of overlapping occlusion among sheep group and chase the need for real-time performance, this paper proposes a Light Attention YOLO model, which fuses the attention depth separable module with CSPDarknet and PAFPN respectively, adds CBAM attention module to the 4th and 5th layers of the backbone. The model is trained and tested using 1225 monitor frame images. Through completely testing in the hardware environment of a single GTX1080T¡ graphics card, the mean accuracy precision of this model in different environments reaches 92%, and the detection speed is 28.5 frames per second, which perfectly meets the accuracy and real-time requirements. In different complex environments, the comprehensive performance on sheep detection is better than the current mainstream detection model. The model can be deployed on the web system to achieve real-time sheep detection and counting.",2022.0,"Xingyu Chen, Xiaodong Ye, Miao Li, Hualong Li, Xianwang Liu, Zhi Run Ma","The paper presents a Light Attention YOLO model specifically designed for sheep detection and counting, addressing challenges like overlapping occlusion. It integrates attention mechanisms with CSPDarknet and PAFPN, achieving a mean accuracy of 92% and a detection speed of 28.5 frames per second. This model outperforms mainstream detection systems in complex environments and can be deployed for real-time sheep detection and counting, making it a significant advancement in livestock detection and classification."," - The paper addresses the challenge of accurately detecting and counting sheep in modern sheep farms, particularly in scenarios where there is overlapping occlusion among sheep groups, which complicates the detection process.
- It emphasizes the need for real-time performance in sheep detection and counting, which is crucial for effective management and monitoring of sheep in various complex environments."," - The paper proposes a Light Attention YOLO model that integrates an attention depth separable module with CSPDarknet and PAFPN, enhancing the model's ability to detect sheep in overlapping and occluded scenarios.
- The model incorporates a CBAM attention module added to the 4th and 5th layers of the backbone, which improves the detection performance in various complex environments.",," - The model was trained and tested using 1225 monitor frame images.
- The performance of the model was evaluated in different complex environments to assess its sheep detection capabilities.",," - The Light Attention YOLO model achieved a mean accuracy precision of 92% in detecting sheep across different environments, demonstrating its effectiveness in handling overlapping occlusion among sheep groups.
- The model operates at a detection speed of 28.5 frames per second on a single GTX1080Ti graphics card, fulfilling the requirements for both accuracy and real-time performance in sheep detection and counting."," - The paper presents a Light Attention YOLO model designed for accurate and real-time detection and counting of sheep, addressing challenges such as overlapping occlusion in sheep groups and the need for quick performance. The model integrates attention mechanisms with CSPDarknet and PAFPN, enhancing its detection capabilities.

- The model was trained and tested on 1225 monitor frame images, achieving a mean accuracy precision of 92% and a detection speed of 28.5 frames per second on a single GTX1080Ti graphics card, outperforming current mainstream detection models in various complex environments. It is suitable for deployment in web systems for real-time sheep detection and counting.",," - The primary objective of the research is to achieve accurate and real-time detection and counting of sheep, addressing the challenges posed by overlapping occlusion among sheep groups and the need for real-time performance in modern sheep farms.

- The paper proposes a Light Attention YOLO model that integrates various advanced techniques, such as the attention depth separable module and CBAM attention module, to enhance the model's performance in detecting sheep in complex environments, achieving a mean accuracy precision of 92% and a detection speed of 28.5 frames per second.",,yolo,"Light Attention YOLO model, Attention Depth Separable Module, CSPDarknet, PAFPN, CBAM Attention Module."
Journal Article,Intelligent Classifier for Identifying and Managing Sheep and Goat Faces Using Deep Learning,10.3390/agriengineering6040204,"Computer vision, particularly in artificial intelligence (AI), is increasingly being applied in various industries, including livestock farming. Identifying and managing livestock through machine learning is essential to improve efficiency and animal welfare. The aim of this work is to automatically identify individual sheep or goats based on their physical characteristics including muzzle pattern, coat pattern, or ear pattern. The proposed intelligent classifier was built on the Roboflow platform using the YOLOv8 model, trained with 35,204 images. Initially, a Convolutional Neural Network (CNN) model was developed, but its performance was not optimal. The pre-trained VGG16 model was then adapted, and additional fine-tuning was performed using data augmentation techniques. The dataset was split into training (88%), validation (8%), and test (4%) sets. The performance of the classifier was evaluated using precision, recall, and F1-Score metrics, with comparisons against other pre-trained models such as EfficientNet. The YOLOv8 classifier achieved 95.8% accuracy in distinguishing between goat and sheep images. Compared to the CNN and VGG16 models, the YOLOv8-based classifier showed superior performance in terms of both accuracy and computational efficiency. The results confirm that deep learning models, particularly YOLOv8, significantly enhance the accuracy and efficiency of livestock identification and management. Future research could extend this technology to other livestock species and explore real-time monitoring through IoT integration. ",2024.0,"Chandra Shekhar Yadav, Antonio Augusto Teixeira Peixoto, Luís Alberto Linhares Rufino, Aedo Braga Silveira, Auzuir Ripardo de Alexandria","The research paper focuses on identifying and managing sheep and goat faces using deep learning, specifically through the YOLOv8 model. This intelligent classifier effectively distinguishes between individual animals based on physical characteristics, achieving 95.8% accuracy. While the study primarily addresses identification, the underlying technology can be adapted for livestock detection, counting, and classification in broader applications. Future research may explore real-time monitoring and extend the technology to other livestock species, enhancing overall management efficiency."," - The paper addresses the challenge of identifying and managing individual sheep and goats based on their unique physical characteristics, such as muzzle pattern, coat pattern, and ear pattern, which is essential for improving efficiency and animal welfare in livestock farming.

- It highlights the limitations of initial models, specifically a Convolutional Neural Network (CNN) that did not perform optimally, leading to the development of a more effective intelligent classifier using the YOLOv8 model, which significantly enhances the accuracy and efficiency of livestock identification."," - The intelligent classifier was built on the Roboflow platform using the YOLOv8 model, which was trained with a dataset of 35,204 images. Initially, a Convolutional Neural Network (CNN) model was developed, but it did not perform optimally, leading to the adaptation of a pre-trained VGG16 model with additional fine-tuning through data augmentation techniques.

- The dataset was divided into training (88%), validation (8%), and test (4%) sets, and the performance of the classifier was evaluated using precision, recall, and F1-Score metrics. The YOLOv8 classifier achieved 95.8% accuracy in distinguishing between goat and sheep images, demonstrating superior performance compared to the CNN and VGG16 models in terms of accuracy and computational efficiency."," - The paper indicates that future research could extend the technology developed for sheep and goat identification to other livestock species, suggesting a gap in the application of the intelligent classifier beyond the current focus on sheep and goats.
  
- There is an opportunity to explore real-time monitoring through IoT integration, highlighting a gap in the current implementation of the classifier that could enhance its practical utility in livestock management."," - The dataset used in the study consisted of 35,204 images of sheep and goats, which were utilized to train the intelligent classifier for identifying individual animals based on their physical characteristics such as muzzle pattern, coat pattern, and ear pattern.

- The dataset was divided into three subsets for training and evaluation purposes: 88% of the images were allocated for training, 8% for validation, and 4% for testing the performance of the classifier."," - The paper discusses the application of computer vision and artificial intelligence in livestock farming, emphasizing the importance of machine learning for improving efficiency and animal welfare through the identification and management of individual sheep and goats based on their physical characteristics such as muzzle, coat, and ear patterns.

- It highlights the development of an intelligent classifier using the YOLOv8 model, which was trained on a substantial dataset of 35,204 images, and compares its performance against other models like CNN and VGG16, demonstrating that YOLOv8 achieved a notable accuracy of 95.8% in distinguishing between goat and sheep images, thus confirming the effectiveness of deep learning in livestock identification."," - The YOLOv8 classifier achieved an impressive accuracy of 95.8% in distinguishing between goat and sheep images, demonstrating its effectiveness in identifying individual livestock based on physical characteristics such as muzzle, coat, and ear patterns.

- The performance of the YOLOv8-based classifier was superior to that of the initially developed Convolutional Neural Network (CNN) and the adapted VGG16 model, both in terms of accuracy and computational efficiency, confirming the advantages of using deep learning models for livestock identification and management."," - The paper presents an intelligent classifier developed using the YOLOv8 model on the Roboflow platform, aimed at automatically identifying individual sheep and goats based on their physical characteristics such as muzzle, coat, and ear patterns. The classifier was trained with a dataset of 35,204 images, achieving a high accuracy of 95.8% in distinguishing between goat and sheep images.

- The study highlights the superior performance of the YOLOv8 classifier over previously developed models, including a Convolutional Neural Network (CNN) and a pre-trained VGG16 model, in terms of accuracy and computational efficiency. The results indicate that deep learning models can significantly improve livestock identification and management, with potential for future applications in other livestock species and real-time monitoring through IoT integration."," - The initial Convolutional Neural Network (CNN) model developed for identifying sheep and goats did not perform optimally, indicating limitations in its architecture or training approach that necessitated the transition to a more advanced model.
  
- While the YOLOv8 classifier achieved a high accuracy of 95.8% in distinguishing between goat and sheep images, the paper suggests that future research could explore extending this technology to other livestock species and integrating real-time monitoring through IoT, implying that the current model may not yet be applicable to a broader range of livestock or real-time scenarios."," - The primary objective of the research is to automatically identify individual sheep or goats based on their physical characteristics, such as muzzle pattern, coat pattern, or ear pattern, to improve efficiency and animal welfare in livestock farming.

- The study aims to develop an intelligent classifier using deep learning techniques, specifically the YOLOv8 model, to enhance the accuracy and efficiency of livestock identification and management, achieving a high accuracy rate of 95.8% in distinguishing between goat and sheep images."," - Future research could extend the intelligent classifier technology to other livestock species, enhancing the identification and management capabilities across a broader range of animals in the farming industry.
- There is potential to explore real-time monitoring of livestock through the integration of Internet of Things (IoT) technologies, which could further improve efficiency and animal welfare in livestock management.","yolo, cnn","Method Used: YOLOv8, Convolutional Neural Network (CNN), VGG16, Data Augmentation, Performance Evaluation (Precision, Recall, F1-Score)"
Journal Article,An algorithm for cattle counting in rangeland based on multi‐scale perception and image association,10.1049/ipr2.13240,"Abstract To effectively address common issues such as cattle being obscured by fences and images prone to colour shifts and high brightness in a ranch setting, this paper proposes an algorithm for counting cows based on multi‐scale perception and image correlation. The algorithm first adjusts the model output scale to enhance cattle detection under current conditions. It incor‐porates efficient Partial Convolution (PConv) to replace 3 × 3 convolutions in the Neck segment of the YOLOv7 network, boost‐ing computational speed and reducing complexity. To streamline feature fusion, Dynamic Head (DyHead) unifies multiple at‐tentional operations in the Neck segment, enhancing efficiency. Additionally, it introduces a novel bounding box similarity metric Minimum Point DioU (MPDIoU) based on minimum point distance, encompassing factors from existing loss functions, while simplifying computations. Experimental results demonstrate the algorithm significantly improves detection, achieving 98.8% accuracy, 99.0% recall, and a 92.1% mAP value. Compared with mainstream SOTA models, Precision increases by 0.4%, Recall by 2.0%, and mAP value by 2.2%. Model size decreases by 23.9%, parameter count by 23.0%, and computational load by 6.1%. the algorithm shows improvements across all indices, meeting the challenge of real‐time cattle counting in ranches under complex conditions. ",2024.0,"Bingxuan Li, Jiandong Fang, Yudong Zhao","The paper presents an algorithm for cattle counting that enhances livestock detection and classification through multi-scale perception and image correlation. It utilizes Partial Convolution (PConv) to improve computational speed and reduce complexity, while Dynamic Head (DyHead) streamlines feature fusion. The novel Minimum Point DioU (MPDIoU) metric simplifies bounding box similarity calculations. Experimental results indicate the algorithm achieves 98.8% accuracy, 99.0% recall, and a 92.1% mAP, demonstrating significant improvements in real-time cattle counting under complex ranch conditions."," - The paper addresses common challenges in cattle counting, such as cattle being obscured by fences and the presence of images that are prone to colour shifts and high brightness in ranch settings, which complicate accurate detection.
- It proposes an algorithm that utilizes multi-scale perception and image correlation to enhance cattle detection, aiming to improve the efficiency and accuracy of counting cattle in complex environmental conditions."," - The algorithm utilizes Partial Convolution (PConv) to replace traditional 3 × 3 convolutions in the Neck segment of the YOLOv7 network, which enhances computational speed and reduces complexity, thereby improving cattle detection in challenging conditions such as being obscured by fences and varying image brightness.

- It introduces a novel bounding box similarity metric called Minimum Point DioU (MPDIoU), which is based on minimum point distance and incorporates factors from existing loss functions while simplifying computations, contributing to the overall efficiency and accuracy of the cattle counting process.",,,," - The proposed algorithm for cattle counting achieved significant improvements in detection performance, with an accuracy of 98.8%, recall of 99.0%, and a mean Average Precision (mAP) value of 92.1%. Compared to mainstream state-of-the-art models, it showed increases in Precision by 0.4%, Recall by 2.0%, and mAP value by 2.2%.

- The algorithm also demonstrated efficiency gains, with a reduction in model size by 23.9%, a decrease in parameter count by 23.0%, and a lowered computational load by 6.1%, making it suitable for real-time cattle counting in complex ranch environments."," - The paper presents an algorithm for counting cattle in rangeland environments, addressing challenges such as cattle being obscured by fences and variations in image quality due to color shifts and brightness. The algorithm enhances cattle detection by adjusting the model output scale and incorporates Partial Convolution (PConv) to improve computational speed and reduce complexity within the YOLOv7 network.

- Experimental results indicate that the proposed algorithm achieves high performance metrics, including 98.8% accuracy, 99.0% recall, and a 92.1% mean Average Precision (mAP). It also demonstrates improvements over existing models, with increases in Precision, Recall, and mAP values, while significantly reducing model size, parameter count, and computational load, making it suitable for real-time cattle counting in complex ranch conditions."," - The algorithm addresses common issues such as cattle being obscured by fences and images being prone to colour shifts and high brightness, indicating that these environmental factors can complicate cattle detection and counting in ranch settings.

- While the algorithm shows significant improvements in detection accuracy and efficiency, the paper does not explicitly mention any limitations or challenges that remain unaddressed, suggesting that further research may be needed to explore potential shortcomings in various conditions."," - The research aims to develop an algorithm for counting cattle in rangeland settings, specifically addressing challenges such as cattle being obscured by fences and variations in image quality due to color shifts and high brightness. 

- The algorithm enhances cattle detection by adjusting the model output scale, utilizing Partial Convolution (PConv) for improved computational speed, and introducing a novel bounding box similarity metric called Minimum Point DioU (MPDIoU) to simplify computations while maintaining high accuracy in detection.",,yolo,- Method: YOLOv7 with Partial Convolution (PConv) and Minimum Point DioU (MPDIoU) metric
Journal Article,A real-time sheep counting detection system based on machine learning,10.35633/inmateh-67-08,"With the development of modern breeding industry, it is very important to count sheep accurately. In the past, herdsmen used manual statistics to count and manage sheep, which was time-consuming, laborious and often had large errors. In recent years, machine learning methods are widely used in automatic target recognition, which can replace manual labor. This system is based on YOLOv5 algorithm for sheep counting management. The counting of sheep was controlled by two - way counting. This improves the accuracy of counting, saves a lot of manpower and material resources for herdsmen, and greatly promotes the management of animal husbandry.",2022.0,"Xue Feng Deng, Song Zhang, Yi Shao, Xiaoli Yan","The paper presents a sheep counting detection system utilizing the YOLOv5 algorithm for livestock detection and classification. It employs a two-way counting method to enhance accuracy and efficiency in sheep management. The system is designed to detect sheep in real-time as they pass through a constructed channel, minimizing the challenges of sheep clustering. This method not only improves counting accuracy but also serves as a core module for broader sheep management systems, promoting effective livestock management."," - The paper addresses the challenges faced by herdsmen in accurately counting and managing sheep, which traditionally relied on manual statistics that were time-consuming, labor-intensive, and prone to significant errors. This inefficiency in sheep counting becomes increasingly problematic as herdsmen manage larger flocks.

- The introduction of a machine learning-based sheep counting detection system aims to automate the counting process, thereby reducing the workload for herders, improving counting accuracy, and enhancing the overall management of animal husbandry, particularly in the context of modern breeding practices."," - The paper utilizes the YOLOv5 algorithm as the core method for sheep counting, which is optimized for real-time detection and management of sheep in pasture environments. This method allows for accurate recording of sheep numbers and operates stably and reliably.

- A bidirectional collision counting method is implemented, where two lines are set to control the counting of sheep exiting and returning through a constructed channel. This method ensures that sheep are accurately tracked and counted without duplication, enhancing the overall accuracy of the counting process."," - The paper does not address the potential limitations of the YOLOv5 algorithm in varying environmental conditions, such as different lighting or weather scenarios, which could affect the accuracy of sheep counting in real-time applications.

- There is no discussion on the scalability of the proposed system for larger flocks or different species of livestock, which may require further adaptation of the counting method and algorithm to ensure reliable performance across diverse farming situations."," - The study utilized a dataset collected from the Inner Mongolia Autonomous Region, which included 29 videos of 28 small-tailed han sheep. Among these, 28 videos corresponded to the data results of each sheep, while the last video served as a verification set.

- The dataset was processed by clipping the videos to remove clips without sheep or with unclear sheep, and then saving the remaining clips by extracting frames every 15 frames to ensure a balance between data quantity and quality for accurate sheep counting."," - The paper discusses the limitations of traditional manual counting methods used by herdsmen, highlighting that these methods are time-consuming, labor-intensive, and prone to significant errors. It emphasizes the need for an accurate and efficient counting system in modern sheep management, especially as many herdsmen manage large flocks.

- It reviews the application of machine learning techniques, specifically the YOLOv5 algorithm, in automatic target recognition for sheep counting. The paper outlines how this technology can enhance the accuracy of sheep counting, reduce the workload for herdsmen, and improve overall management efficiency in animal husbandry."," - The proposed sheep counting detection system based on the YOLOv5 algorithm demonstrated accurate real-time counting of sheep, effectively recording the number of sheep passing through designated counting lines in both north-south and east-west directions, thus improving the accuracy of sheep management.

- The system was tested and proved to be stable, reliable, and expandable, significantly reducing the workload of herders and enhancing the efficiency of sheep breeding management by automating the counting process."," - The paper presents a real-time sheep counting detection system utilizing the YOLOv5 machine learning algorithm, which significantly enhances the accuracy and efficiency of sheep counting compared to traditional manual methods. This system is designed to reduce the workload of herders and improve the management of animal husbandry by implementing a two-way counting mechanism.

- The proposed method involves constructing a channel for sheep to pass through individually, allowing for effective target detection and accurate counting. The system has been tested in real pasture conditions, demonstrating stability, reliability, and the potential for integration into broader sheep management systems."," - The paper mentions that sheep tend to gather closely together due to their timid nature, which complicates target detection and accurate counting. To address this issue, a channel was constructed to ensure that sheep pass through in a single file, reducing the difficulty of detecting and counting them accurately.

- The system requires a well-defined passage for sheep to queue through, which may not always be feasible in all pasture environments. This limitation necessitates additional infrastructure to facilitate effective counting, potentially increasing the complexity and cost of implementing the system in various settings."," - The primary objective of the research is to develop a real-time sheep counting detection system using the YOLOv5 algorithm, which aims to automate the counting process and replace the traditional manual counting methods used by herdsmen.
- The system is designed to improve the accuracy of sheep counting through a two-way counting mechanism, thereby reducing the workload for herders and enhancing the overall management of animal husbandry."," - Future research could focus on improving the accuracy and detection speed of the sheep counting system by further optimizing the YOLOv5 algorithm and exploring the integration of additional machine learning techniques, such as Faster R-CNN, to enhance the detection of sheep in various postures and crowded scenarios.

- Another area for future research could involve the development of more advanced data collection methods and experimental setups that minimize occlusion among sheep, potentially by designing more sophisticated passageways or utilizing multiple camera angles to ensure clearer visibility and separation of individual sheep during counting.",yolo,"- YOLOv5 algorithm
- Bidirectional collision counting method"
Journal Article,An Intelligent Deep learning Based Animal Detection System,10.55041/ijsrem14600,"Efficient and reliable monitoring of wild animals in their natural habitat is essential. We develop a system to detect animals with automatic alerts as part of the project. Since there is a large number of different animals, manually identifying them can be a difficult task. Our algorithm classifies animals based on a DarkNet deep learning model, which allows us to monitor them more efficiently. Animal detection and classification can help to prevent animal- vehicle accidents and animals from destroying agricultural lands. This can be achieved by applying effective deep learning algorithms. Furthermore, GSM and GPS devices are used to detect and alert the presence of animals using Arduino embedded systems. Keywords: Wild animals, DarkNet, Deep Learning, Animal Detection, Animal vehicle accidents, Arduino, GSM, GPS.",2022.0,Ijsrem Journal,"The paper focuses on detecting and classifying wild animals using a DarkNet deep learning model, which may not directly address livestock detection. However, the principles of animal detection and classification can be adapted for livestock monitoring. The system utilizes GSM and GPS devices for alerts, which could be beneficial in managing livestock to prevent accidents and protect agricultural lands. Thus, while not explicitly covered, the methodology could be relevant for livestock detection and counting."," - The paper addresses the challenge of efficiently and reliably monitoring wild animals in their natural habitat, highlighting the difficulty of manually identifying a large number of different animal species.
- It emphasizes the need for an automated system that can detect and classify animals to prevent potential issues such as animal-vehicle accidents and damage to agricultural lands, utilizing deep learning algorithms and embedded systems for effective monitoring."," - The system utilizes a DarkNet deep learning model to classify and detect various wild animals, enabling efficient monitoring in their natural habitats. This approach helps in automating the identification process, which can be challenging due to the diversity of animal species.

- To enhance the detection and alerting process, the system incorporates GSM and GPS devices integrated with Arduino embedded systems. This technology allows for real-time alerts regarding the presence of animals, which can help mitigate risks such as animal-vehicle accidents and agricultural damage.",,,," - The developed system utilizes a DarkNet deep learning model to efficiently classify and detect a variety of wild animals, facilitating better monitoring in their natural habitats and reducing the challenges associated with manual identification.
- The integration of GSM and GPS devices with Arduino embedded systems enables automatic alerts regarding the presence of animals, which can help prevent animal-vehicle accidents and protect agricultural lands from potential damage caused by wildlife."," - The paper presents an intelligent system for the efficient monitoring and detection of wild animals in their natural habitats, utilizing a DarkNet deep learning model for automatic classification and alerts, which enhances the ability to manage and observe diverse animal populations.
- The system incorporates GSM and GPS technology through Arduino embedded systems to provide real-time detection and alerts, aiming to reduce animal-vehicle accidents and mitigate the impact of wildlife on agricultural lands.",," - The primary objective of the research is to develop an efficient and reliable system for monitoring wild animals in their natural habitat, utilizing a DarkNet deep learning model for automatic detection and classification of various animal species. This aims to enhance the monitoring process and reduce the challenges associated with manual identification.

- Another key objective is to implement a system that can prevent animal-vehicle accidents and mitigate the impact of animals on agricultural lands by providing timely alerts through the integration of GSM and GPS devices with Arduino embedded systems, thereby ensuring better management of wildlife interactions."," - Future research could focus on enhancing the accuracy and efficiency of the animal detection algorithm by exploring advanced deep learning models beyond DarkNet, potentially incorporating techniques such as transfer learning or ensemble methods to improve classification performance across a wider variety of species.

- Another area for future research could involve the integration of real-time data analytics and machine learning to predict animal movement patterns, which could further aid in preventing animal-vehicle accidents and optimizing agricultural land management strategies.",deep learning,"Method Used: DarkNet deep learning model, GSM and GPS integration with Arduino embedded systems."
Journal Article,An Integrated Goat Head Detection and Automatic Counting Method Based on Deep Learning,10.3390/ani12141810,"Simple Summary To achieve precision and intelligence in farming, automatic recognition and counting of goats are important and fundamental parts of the process of large-scale goat farming. Currently, many farms with low modernization use manual counting, which has the obvious shortcomings of low efficiency and difficulty in avoiding duplication and omissions due to the large population base and frequent counting needs of goats. In order to solve this problem in the farming process, an efficient and accurate goat counting method is urgently needed. In this study, we address the above problem by constructing an integrated deep learning model for automatic detection and counting of goats based on computer vision technology with the Chengdu Ma goat as the research object. It is worth noting that we have improved the model using a series of advanced and effective strategies to enhance the performance of the model. Experiments show that our method can achieve accurate automatic counting of goats in a practical breeding environment. The method is beneficial to the regionalized management of goat barns and can be applied to different goat species with high practicality. Abstract Goat farming is one of the pillar industries for sustainable development of national economies in some countries and plays an active role in social and economic development. In order to realize the precision and intelligence of goat breeding, this paper describes an integrated goat detection and counting method based on deep learning. First, we constructed a new dataset of video images of goats for the object tracking task. Then, we took YOLOv5 as the baseline of the object detector and improved it using a series of advanced methods, including: using RandAugment to explore suitable data augmentation strategies in a real goat barn environment, using AF-FPN to improve the network’s ability to represent multi-scale objects, and using the Dynamic Head framework to unify the attention mechanism with the detector’s heads to improve its performance. The improved detector achieved 92.19% mAP, a significant improvement compared to the 84.26% mAP of the original YOLOv5. In addition, we also input the information obtained by the detector into DeepSORT for goat tracking and counting. The average overlap rate of our proposed method is 89.69%, which is significantly higher than the 82.78% of the original combination of YOLOv5 and DeepSORT. In order to avoid double counting as much as possible, goats were counted using the single-line counting based on the results of goat head tracking, which can support practical applications.",2022.0,"Yu Zhang, Chengjun Yu, Hui Liu, Xiaoyan Chen, Yujie Lei, T. Pang, Jie Zhang","The paper presents an integrated method for livestock detection, counting, and classification specifically for goats using deep learning. It employs an improved YOLOv5 model for accurate detection, achieving a mean Average Precision (mAP) of 92.19%. The method incorporates DeepSORT for tracking and counting, resulting in an average overlap rate of 89.69%. This approach enhances efficiency in goat farming by automating the counting process, reducing errors associated with manual counting, and supporting practical applications in various goat species."," - The paper addresses the inefficiencies and inaccuracies associated with manual counting of goats in large-scale farming, which can lead to duplication and omissions due to the large population and frequent counting needs.
- It emphasizes the urgent need for an efficient and accurate automatic counting method to enhance precision and intelligence in goat farming, thereby improving the management of goat barns and supporting the regionalized management of different goat species."," - The study constructed a new dataset of video images of goats for the object tracking task and utilized YOLOv5 as the baseline object detector. The model was improved through various advanced methods, including RandAugment for data augmentation, AF-FPN to enhance multi-scale object representation, and the Dynamic Head framework to unify the attention mechanism with the detector’s heads, resulting in a significant increase in mean Average Precision (mAP) from 84.26% to 92.19%.

- For goat tracking and counting, the information obtained from the improved detector was input into DeepSORT. The proposed method achieved an average overlap rate of 89.69%, which is higher than the original combination of YOLOv5 and DeepSORT at 82.78%. Additionally, a single-line counting method was employed based on goat head tracking results to minimize the risk of double counting."," - The paper primarily focuses on the detection and counting of Chengdu Ma goats, which may limit the generalizability of the method to other goat species or breeds. Future research could explore the adaptability of the integrated deep learning model across a wider variety of goat types to enhance its applicability in diverse farming environments.

- While the study demonstrates significant improvements in detection accuracy and counting efficiency, it does not address potential challenges related to varying environmental conditions, such as different lighting or weather scenarios that could affect the performance of the model in real-world settings. Further investigation into the robustness of the model under these varying conditions could be beneficial."," - The study constructed a new dataset of video images of goats specifically for the object tracking task, which is essential for the automatic detection and counting of goats in a farming environment.
- The dataset was utilized to improve the performance of the YOLOv5 object detector, which was enhanced through various advanced methods to achieve better accuracy in goat detection and counting."," - The paper addresses the challenges faced in large-scale goat farming, particularly the inefficiencies of manual counting methods that lead to duplication and omissions due to the large population of goats and frequent counting needs. It emphasizes the urgent need for an efficient and accurate automatic counting method to enhance the precision and intelligence of goat breeding.

- The study constructs an integrated deep learning model for automatic detection and counting of goats, utilizing computer vision technology. It improves upon the YOLOv5 object detection framework by implementing advanced strategies such as RandAugment for data augmentation, AF-FPN for better multi-scale object representation, and the Dynamic Head framework to enhance performance, achieving a significant increase in mean Average Precision (mAP) from 84.26% to 92.19%."," - The improved deep learning model for goat detection and counting achieved a mean Average Precision (mAP) of 92.19%, which is a significant improvement over the original YOLOv5 model's mAP of 84.26%. This enhancement was achieved through various advanced strategies, including data augmentation and improved network representation for multi-scale objects.

- The proposed method demonstrated an average overlap rate of 89.69% for goat tracking and counting, which is notably higher than the 82.78% overlap rate of the original combination of YOLOv5 and DeepSORT. This improvement supports practical applications by minimizing the chances of double counting through a single-line counting approach based on goat head tracking results."," - The paper presents an integrated deep learning model for the automatic detection and counting of goats, addressing the inefficiencies of manual counting in large-scale goat farming. The model utilizes computer vision technology, specifically focusing on the Chengdu Ma goat, and incorporates advanced strategies to enhance its performance, achieving a mean Average Precision (mAP) of 92.19%, significantly improving upon the original YOLOv5's 84.26% mAP.

- The method combines the improved YOLOv5 detector with DeepSORT for effective goat tracking and counting, resulting in an average overlap rate of 89.69%, which surpasses the original combination's 82.78%. The approach also implements single-line counting based on goat head tracking to minimize double counting, making it practical for real-world applications in goat barn management."," - The paper highlights that many farms currently rely on manual counting methods, which are inefficient and prone to errors such as duplication and omissions, particularly due to the large population of goats and the frequent need for counting. This indicates a limitation in the existing practices of goat counting in less modernized farms.

- While the proposed method shows significant improvements in detection and counting accuracy, the paper does not explicitly mention any limitations regarding the scalability of the model to different environments or the potential challenges in varying lighting conditions or goat behaviors that could affect the performance of the deep learning model in practical applications."," - The primary objective of the research is to develop an integrated deep learning model for the automatic detection and counting of goats, specifically focusing on improving efficiency and accuracy in large-scale goat farming, which currently relies on manual counting methods that are prone to errors and inefficiencies.

- The study aims to enhance the performance of the object detection model (YOLOv5) through various advanced strategies, such as data augmentation, improved network representation for multi-scale objects, and a unified attention mechanism, ultimately achieving a significant increase in mean Average Precision (mAP) and a higher overlap rate in goat tracking and counting."," - Future research could focus on expanding the integrated goat detection and counting method to include a wider variety of goat species beyond the Chengdu Ma goat, ensuring the model's adaptability and effectiveness in diverse farming environments and conditions.

- Another area for future exploration could involve enhancing the model's performance in challenging environments, such as varying lighting conditions or crowded settings, to further improve the accuracy of goat detection and counting while minimizing the risk of double counting.",yolo,"- Object Detection: YOLOv5
- Data Augmentation: RandAugment
- Multi-Scale Object Representation: AF-FPN
- Attention Mechanism: Dynamic Head framework
- Tracking: DeepSORT
- Counting Method: Single-line counting based on head tracking"
Journal Article,Livestock Recognition and Identification with Deep Convolutional Neural Networks: A Case Study of Pigs,10.1145/3594315.3594642,"Animal recognition with Object Detection (OD) method by using deep learning techniques has gained popularities in biodiversity preservation and“smart farm” program in recent years. Current research mainly focuses on model training and parameter optimization of different forms of livestock in a single scene. To meet the developmental needs of farms in modern agriculture, this paper proposes an image recognition method which preprocesses the morphological characteristics of livestock in different captivity scenarios, by combining Kennard Stone algorithm, K-means II algorithm and deep learning models for different scenes and live pigs of different behavior characteristics. Our results show that the F1-socre, mAP0.5, and mAP0.5-0.95 of the model were 98.48, 99.27 and 73.03, respectively. Our research shows significant improvements for promoting smart animal husbandry and saving labor costs for breeding enterprises, which can also speed up research of high accuracy livestock auto-weighing systems and subsequent applied in animal husbandry. ",2023.0,"Feiyang Zhao, Maohong Tian, Sheng Hu, Jian Liang, Longfu Zhou, Hualin Li","The paper presents an image recognition method for livestock detection, counting, and classification using deep learning techniques. It preprocesses morphological characteristics of pigs in various captivity scenarios, employing the Kennard Stone algorithm and K-means II algorithm. The model achieved impressive performance metrics, with an F1-score of 98.48, mAP0.5 of 99.27, and mAP0.5-0.95 of 73.03. This approach significantly enhances smart animal husbandry, aiding in labor cost reduction and improving livestock management efficiency."," - The paper addresses the challenge of animal recognition in various captivity scenarios, focusing on the need for effective identification methods for livestock, particularly pigs, to enhance biodiversity preservation and support smart farming initiatives.
- It highlights the limitations of current research, which primarily concentrates on model training and parameter optimization for different livestock forms in a single scene, indicating a gap in methodologies that can preprocess morphological characteristics across diverse environments and behaviors of live pigs."," - The paper proposes an image recognition method that preprocesses the morphological characteristics of livestock using a combination of the Kennard Stone algorithm and the K-means II algorithm, along with deep learning models tailored for different scenes and behaviors of live pigs.

- The research focuses on optimizing model training and parameters for livestock recognition in various captivity scenarios, which contributes to advancements in smart animal husbandry and the development of high accuracy livestock auto-weighing systems."," - The paper primarily focuses on model training and parameter optimization for different forms of livestock in a single scene, indicating a potential gap in exploring the effectiveness of the proposed methods across multiple scenes or environments, which could enhance the robustness of the recognition system in varied agricultural settings.

- While the study demonstrates significant improvements in livestock recognition metrics, it does not address the scalability of the proposed methods for larger farms or diverse livestock species, suggesting a need for further research on how these techniques can be adapted and applied in broader agricultural contexts.",," - The paper discusses the growing popularity of animal recognition using Object Detection methods and deep learning techniques, particularly in the context of biodiversity preservation and smart farming initiatives. It highlights the focus of current research on model training and parameter optimization for various forms of livestock within single scenes.

- It proposes a novel image recognition method that preprocesses the morphological characteristics of livestock across different captivity scenarios. This method integrates the Kennard Stone algorithm, K-means II algorithm, and deep learning models to effectively analyze live pigs exhibiting different behavioral characteristics, demonstrating significant improvements in smart animal husbandry practices."," - The model achieved an F1-score of 98.48, indicating a high level of accuracy in recognizing and identifying livestock, specifically pigs, in various captivity scenarios.
- The mean Average Precision (mAP) values were reported as 99.27 for mAP0.5 and 73.03 for mAP0.5-0.95, demonstrating the model's effectiveness in detecting pigs across different behaviors and conditions."," - The paper presents an image recognition method for livestock, specifically pigs, utilizing deep learning techniques and object detection methods. It preprocesses morphological characteristics of pigs in various captivity scenarios by integrating the Kennard Stone algorithm, K-means II algorithm, and deep learning models tailored for different behaviors and environments.

- The results demonstrate high performance metrics with an F1-score of 98.48, mAP0.5 of 99.27, and mAP0.5-0.95 of 73.03, indicating significant advancements in smart animal husbandry, labor cost reduction for breeding enterprises, and potential applications in high-accuracy livestock auto-weighing systems.",," - The research aims to develop an image recognition method that preprocesses the morphological characteristics of livestock in various captivity scenarios, utilizing a combination of the Kennard Stone algorithm, K-means II algorithm, and deep learning models tailored for different scenes and behaviors of live pigs.

- The study seeks to enhance smart animal husbandry practices by achieving significant improvements in livestock recognition accuracy, as evidenced by high performance metrics such as an F1-score of 98.48, mAP0.5 of 99.27, and mAP0.5-0.95 of 73.03, ultimately aiming to reduce labor costs for breeding enterprises and facilitate the development of high accuracy livestock auto-weighing systems."," - Future research could focus on enhancing the image recognition method to accommodate a wider variety of livestock species and behaviors, beyond just pigs, to further support biodiversity preservation and smart farming initiatives.
- Investigating the integration of the developed recognition system with high accuracy livestock auto-weighing systems could lead to advancements in automated monitoring and management of animal husbandry practices, ultimately improving efficiency and reducing labor costs.",deep learning,"- Image recognition method
- Kennard Stone algorithm
- K-means II algorithm
- Deep learning models"
Journal Article,YOLOv5-SA-FC: A Novel Pig Detection and Counting Method Based on Shuffle Attention and Focal Complete Intersection over Union,10.3390/ani13203201,"The efficient detection and counting of pig populations is critical for the promotion of intelligent breeding. Traditional methods for pig detection and counting mainly rely on manual labor, which is either time-consuming and inefficient or lacks sufficient detection accuracy. To address these issues, a novel model for pig detection and counting based on YOLOv5 enhanced with shuffle attention (SA) and Focal-CIoU (FC) is proposed in this paper, which we call YOLOv5-SA-FC. The SA attention module in this model enables multi-channel information fusion with almost no additional parameters, enhancing the richness and robustness of feature extraction. Furthermore, the Focal-CIoU localization loss helps to reduce the impact of sample imbalance on the detection results, improving the overall performance of the model. From the experimental results, the proposed YOLOv5-SA-FC model achieved a mean average precision (mAP) and count accuracy of 93.8% and 95.6%, outperforming other methods in terms of pig detection and counting by 10.2% and 15.8%, respectively. These findings verify the effectiveness of the proposed YOLOv5-SA-FC model for pig population detection and counting in the context of intelligent pig breeding.",2023.0,"Wangli Hao, Li Zhang, Meng Han, Kai Zhang, Fuzhong Li, Guoqiang Yang, Zhenyu Liu","The paper presents a novel method for livestock detection and counting, specifically focusing on pigs, using the YOLOv5-SA-FC model. This model incorporates a shuffle attention (SA) module for enhanced feature extraction and a Focal-CIoU loss to address sample imbalance. The results demonstrate a mean average precision (mAP) of 93.8% and a count accuracy of 95.6%, significantly outperforming traditional methods. This approach promotes efficient and accurate pig population detection and counting, essential for intelligent breeding practices."," - The paper addresses the inefficiencies and inaccuracies of traditional methods for pig detection and counting, which primarily rely on manual labor, making the process time-consuming and less effective.
- It proposes a novel model, YOLOv5-SA-FC, that enhances pig detection and counting through advanced techniques like shuffle attention and Focal-CIoU, aiming to improve detection accuracy and overall performance in intelligent breeding practices."," - The paper proposes a novel model called YOLOv5-SA-FC, which enhances the traditional YOLOv5 model by incorporating a shuffle attention (SA) module. This SA module facilitates multi-channel information fusion with minimal additional parameters, thereby improving the richness and robustness of feature extraction for pig detection and counting.

- Additionally, the model utilizes Focal-CIoU (FC) as a localization loss function, which helps mitigate the effects of sample imbalance on detection results. This approach contributes to the overall performance improvement of the model, leading to higher accuracy in pig detection and counting."," - The paper does not address the potential limitations or challenges of implementing the YOLOv5-SA-FC model in real-world pig breeding environments, such as variations in lighting, occlusions, or different pig breeds that may affect detection accuracy.

- There is no discussion on the scalability of the YOLOv5-SA-FC model for larger pig populations or its performance in diverse agricultural settings, which could impact its generalizability and practical application in intelligent breeding systems.",," - The paper addresses the limitations of traditional methods for pig detection and counting, which are often time-consuming, inefficient, and lack sufficient accuracy due to reliance on manual labor. 
- It introduces a novel model, YOLOv5-SA-FC, which incorporates a shuffle attention (SA) module for enhanced feature extraction and a Focal-CIoU (FC) localization loss to mitigate sample imbalance, resulting in significant improvements in detection and counting performance."," - The proposed YOLOv5-SA-FC model achieved a mean average precision (mAP) of 93.8% and a count accuracy of 95.6%, demonstrating high effectiveness in pig detection and counting.
- The model outperformed other methods by 10.2% in pig detection and 15.8% in counting accuracy, highlighting its superior performance in the context of intelligent pig breeding."," - The paper presents a novel model called YOLOv5-SA-FC for efficient pig detection and counting, which integrates a shuffle attention (SA) module and Focal-CIoU (FC) localization loss to enhance feature extraction and address sample imbalance issues, respectively. This model aims to improve the accuracy and efficiency of pig population monitoring compared to traditional manual methods.

- Experimental results demonstrate that the YOLOv5-SA-FC model achieved a mean average precision (mAP) of 93.8% and a count accuracy of 95.6%, surpassing other detection methods by 10.2% and 15.8%, thereby confirming its effectiveness for intelligent pig breeding applications.",," - The primary objective of the research is to develop a novel model for efficient pig detection and counting, addressing the limitations of traditional methods that rely on manual labor, which are often time-consuming, inefficient, and lack sufficient detection accuracy.

- The research aims to enhance the YOLOv5 model by integrating a shuffle attention (SA) module for improved feature extraction and a Focal-CIoU (FC) localization loss to mitigate the effects of sample imbalance, ultimately improving the model's mean average precision (mAP) and count accuracy in pig population detection.",,yolo,- **Method Used:** YOLOv5 with Shuffle Attention (SA) module and Focal-CIoU (FC) as localization loss function.
Journal Article,A Deep Learning-Based Model for the Detection and Tracking of Animals for Safety and Management of Financial Loss,10.52783/jes.1074,"The paper presents a deep learning-based model for detecting and tracking animals to protect agricultural fields. It addresses the challenge of crop destruction by stray animals, a significant issue for farmers, by proposing an intelligent camera-based solution. This solution utilizes IoT for real-time information transfer and employs advanced image and video processing methods, including YoloV5, for efficient animal detection and classification. The study evaluates various existing solutions and highlights the advantages of the proposed model in terms of accuracy and cost-effectiveness, offering a promising approach to mitigate animal raids on crops.",2024.0,,"The paper presents a deep learning-based model that utilizes YoloV5 for efficient detection and classification of animals, addressing the issue of livestock detection and counting. By employing advanced image and video processing methods, the model enables accurate identification of stray animals that threaten agricultural fields. This intelligent camera-based solution, integrated with IoT for real-time data transfer, offers a promising approach to manage livestock effectively, thereby reducing crop destruction and financial losses for farmers."," - The paper addresses the challenge of crop destruction caused by stray animals, which is a significant issue for farmers and can lead to substantial financial losses.
- It proposes an intelligent camera-based solution that utilizes IoT for real-time information transfer and advanced image and video processing methods, specifically YoloV5, to efficiently detect and classify animals threatening agricultural fields."," - The paper employs advanced image and video processing methods, specifically utilizing YoloV5, which is an efficient algorithm for animal detection and classification in agricultural fields.
- It incorporates IoT technology for real-time information transfer, enabling timely responses to prevent crop destruction by stray animals.",,," - The study evaluates various existing solutions for detecting and tracking animals that threaten agricultural fields, highlighting their limitations in terms of accuracy and cost-effectiveness.
- It emphasizes the advantages of the proposed deep learning-based model, particularly its use of advanced image and video processing methods like YoloV5, which enhances the efficiency of animal detection and classification compared to previous approaches."," - The proposed deep learning-based model demonstrates improved accuracy in detecting and tracking animals, effectively addressing the challenge of crop destruction caused by stray animals, which is a significant issue for farmers.
- The model is evaluated against various existing solutions and is highlighted for its cost-effectiveness, offering a promising approach to mitigate animal raids on crops through the use of intelligent camera systems and real-time information transfer via IoT."," - The paper introduces a deep learning-based model designed to detect and track animals, aiming to protect agricultural fields from crop destruction caused by stray animals. It proposes an intelligent camera-based solution that leverages IoT for real-time information transfer.

- The model employs advanced image and video processing techniques, specifically YoloV5, to enhance the efficiency of animal detection and classification. The study also compares existing solutions, demonstrating the proposed model's superior accuracy and cost-effectiveness in addressing the issue of animal raids on crops.",," - The primary objective of the research is to develop a deep learning-based model that effectively detects and tracks animals to protect agricultural fields from crop destruction caused by stray animals, thereby addressing a significant issue faced by farmers.

- The study aims to propose an intelligent camera-based solution that utilizes IoT for real-time information transfer and incorporates advanced image and video processing methods, such as YoloV5, to enhance the accuracy and cost-effectiveness of animal detection and classification.",,yolo,"- YoloV5 (object detection algorithm)
- IoT technology (real-time information transfer)"
Proceedings Article,Automatic Pig Counting Based on Video Detection and Tracking Algorithm,10.1109/ICFTIC57696.2022.10075234,"In the corridor, pigs are more likely to be covered or crowded, the existing methods of automatic pig counting based on video have large errors. In order to tackle these problems, this paper proposes a method of pig counting based on YOLOv5s detector and improved DeepSORT algorithm of behavior tracking. Firstly, DIOU_NMS replaces the ordinary NMS to optimize the output of YOLOv5s detector, which can improve the stability of detection boxes and reduce the missed detection of multiple pigs in parallel. Secondly, using CA model to replace the CV model in the original DeepSORT algorithm to improve the prediction results of kalman filter for trajectories. Finally, setting up the virtual detection area by taking the cross product of the vectors, counting the number of frames and capturing a key frame to accumulate the downside probability for pigs. And the probability as the condition to achieve pig counting in the corridor. The results show that the accuracy of this paper method is high, which can be applied to the pig counting in the breeding farms and provide technical reference for the realization of smart pig breeding.",2022.0,"Xuezhen Cheng, Meng Zhao","The paper focuses on automatic pig counting using a YOLOv5s detector and an improved DeepSORT algorithm for behavior tracking. It addresses challenges like crowding and occlusion in pig detection. By implementing DIOU_NMS for better detection stability and using a CA model to enhance Kalman filter predictions, the method effectively counts pigs in breeding farms. The approach provides a reliable technical reference for livestock detection and counting, specifically tailored for smart pig breeding applications."," - The paper addresses the issue of large errors in existing methods of automatic pig counting based on video, particularly in scenarios where pigs are covered or crowded in corridors, leading to missed detections.
- It proposes a solution that combines an optimized YOLOv5s detector with an improved DeepSORT algorithm to enhance the accuracy of pig counting by reducing missed detections and improving trajectory predictions."," - The paper proposes a pig counting method that utilizes the YOLOv5s detector, enhanced by replacing the ordinary Non-Maximum Suppression (NMS) with DIOU_NMS, which optimizes the output and improves the stability of detection boxes, thereby reducing missed detections of multiple pigs in parallel.

- An improved DeepSORT algorithm is employed, where the CA model is used instead of the CV model to enhance the prediction results of the Kalman filter for tracking trajectories, along with the establishment of a virtual detection area to count pigs based on the accumulated downside probability from captured key frames."," - The paper addresses the issue of large errors in existing automatic pig counting methods due to pigs being covered or crowded, but it does not explore the potential impact of varying lighting conditions or camera angles on detection accuracy, which could be significant in real-world applications.

- While the proposed method improves detection stability and reduces missed detections, it does not discuss the scalability of the algorithm for larger herds or different environments, which may present additional challenges not covered in the current research.",," - The paper addresses the challenges of automatic pig counting in crowded environments, highlighting that existing methods have significant errors due to pigs being covered or crowded in corridors.
- It proposes an innovative approach that combines the YOLOv5s detector with an improved DeepSORT algorithm, utilizing DIOU_NMS for better detection stability and a CA model for enhanced trajectory prediction, ultimately leading to more accurate pig counting in breeding farms."," - The proposed method for automatic pig counting demonstrates high accuracy, effectively addressing the challenges of counting pigs in crowded or covered conditions within corridors.
- The approach utilizes an optimized YOLOv5s detector and an improved DeepSORT algorithm, which enhances detection stability and reduces missed detections, making it suitable for application in breeding farms and contributing to smart pig breeding technologies."," - The paper presents a novel method for automatic pig counting using a combination of the YOLOv5s detector and an improved DeepSORT algorithm, addressing challenges such as crowding and occlusion in pig detection. The method enhances detection accuracy by implementing DIOU_NMS to optimize detection box outputs and reduce missed detections of multiple pigs.

- Additionally, the study replaces the CV model in the original DeepSORT algorithm with a CA model to improve Kalman filter predictions for tracking trajectories. A virtual detection area is established to count pigs based on frame accumulation and probability assessment, demonstrating high accuracy suitable for application in breeding farms and contributing to smart pig breeding technologies."," - The existing methods of automatic pig counting based on video have large errors, particularly in scenarios where pigs are covered or crowded in the corridor, which complicates accurate counting.
- The paper addresses the limitations of traditional detection methods by proposing an improved approach that utilizes DIOU_NMS and a CA model in the DeepSORT algorithm to enhance detection stability and reduce missed detections, indicating that previous methods were insufficient in these areas."," - The paper aims to improve the accuracy of automatic pig counting in crowded or covered environments by proposing a method that utilizes the YOLOv5s detector and an improved DeepSORT algorithm for behavior tracking, addressing the large errors present in existing methods.
- It seeks to enhance the detection and tracking process by implementing DIOU_NMS to optimize YOLOv5s output, and by replacing the CV model with a CA model in the DeepSORT algorithm to improve the prediction results of the Kalman filter for trajectories, ultimately facilitating effective pig counting in breeding farms.",,yolo,"- YOLOv5s detector
- DIOU_NMS
- DeepSORT algorithm
- CA model
- Kalman filter
- Virtual detection area"
Proceedings Article,Automatic Pig Counting Based on Video Detection and Tracking Algorithm,10.1109/icftic57696.2022.10075234,"In the corridor, pigs are more likely to be covered or crowded, the existing methods of automatic pig counting based on video have large errors. In order to tackle these problems, this paper proposes a method of pig counting based on YOLOv5s detector and improved DeepSORT algorithm of behavior tracking. Firstly, DIOU_NMS replaces the ordinary NMS to optimize the output of YOLOv5s detector, which can improve the stability of detection boxes and reduce the missed detection of multiple pigs in parallel. Secondly, using CA model to replace the CV model in the original DeepSORT algorithm to improve the prediction results of kalman filter for trajectories. Finally, setting up the virtual detection area by taking the cross product of the vectors, counting the number of frames and capturing a key frame to accumulate the downside probability for pigs. And the probability as the condition to achieve pig counting in the corridor. The results show that the accuracy of this paper method is high, which can be applied to the pig counting in the breeding farms and provide technical reference for the realization of smart pig breeding. ",2022.0,,"The paper focuses on automatic pig counting using a YOLOv5s detector and an improved DeepSORT algorithm for behavior tracking. It addresses challenges like crowding and occlusion in pig detection. By implementing DIOU_NMS for better detection stability and using a CA model to enhance Kalman filter predictions, the method effectively counts pigs in breeding farms. The approach provides a reliable technical reference for smart pig breeding, emphasizing accurate counting and classification in livestock management."," - The paper addresses the issue of large errors in existing methods of automatic pig counting based on video, particularly in scenarios where pigs are covered or crowded in corridors, leading to missed detections.
- It proposes a solution that combines an optimized YOLOv5s detector with an improved DeepSORT algorithm to enhance the accuracy of pig counting by reducing missed detections and improving trajectory predictions."," - The paper proposes a pig counting method that utilizes the YOLOv5s detector, enhanced by replacing the ordinary Non-Maximum Suppression (NMS) with DIOU_NMS, which optimizes the output and improves the stability of detection boxes, thereby reducing missed detections of multiple pigs in parallel.

- An improved DeepSORT algorithm is employed, where the CA model is used instead of the CV model to enhance the prediction results of the Kalman filter for tracking trajectories, along with the establishment of a virtual detection area to count pigs based on frame accumulation and downside probability."," - The paper addresses the issue of large errors in existing automatic pig counting methods due to pigs being covered or crowded, but it does not explore the potential impact of varying lighting conditions or camera angles on detection accuracy, which could be significant in real-world applications.

- While the proposed method improves detection stability and reduces missed detections, it does not discuss the scalability of the algorithm for larger herds or different environments, which may present additional challenges not covered in the current research.",," - The paper addresses the challenges of automatic pig counting in crowded environments, highlighting that existing methods have significant errors due to pigs being covered or crowded in corridors.
- It proposes an improved method that utilizes the YOLOv5s detector with DIOU_NMS for better detection stability and an enhanced DeepSORT algorithm with a CA model for improved trajectory prediction, ultimately leading to more accurate pig counting in breeding farms."," - The proposed method for automatic pig counting based on YOLOv5s detector and improved DeepSORT algorithm demonstrates high accuracy in counting pigs, effectively addressing the challenges of crowding and coverage in corridors.
- The implementation of DIOU_NMS and the CA model in the tracking algorithm significantly enhances the stability of detection boxes and improves the prediction results of trajectories, leading to a reduction in missed detections of multiple pigs."," - The paper presents a novel method for automatic pig counting using a combination of the YOLOv5s detector and an improved DeepSORT algorithm, addressing challenges such as crowding and occlusion in pig detection. The method incorporates DIOU_NMS to enhance detection stability and reduce missed detections of multiple pigs.

- Additionally, the study replaces the CV model in the original DeepSORT algorithm with a CA model to improve trajectory prediction, and establishes a virtual detection area to count pigs based on frame accumulation and probability assessment, demonstrating high accuracy suitable for application in breeding farms."," - The existing methods of automatic pig counting based on video have large errors, particularly in scenarios where pigs are covered or crowded in the corridor, which complicates accurate counting.
- The paper addresses the limitations of traditional detection methods by proposing an improved approach that utilizes DIOU_NMS to enhance the stability of detection boxes and reduce missed detections of multiple pigs in parallel."," - The paper aims to improve the accuracy of automatic pig counting in crowded or covered environments by proposing a method that utilizes the YOLOv5s detector and an improved DeepSORT algorithm for behavior tracking, addressing the large errors present in existing methods.
- It seeks to enhance the detection and tracking process by implementing DIOU_NMS to optimize YOLOv5s output and replacing the CV model with a CA model in the DeepSORT algorithm, ultimately establishing a virtual detection area to accurately count pigs in breeding farms.",,yolo,"- YOLOv5s detector
- DIOU_NMS
- Improved DeepSORT algorithm
- CA model for Kalman filter
- Virtual detection area for counting
"
Journal Article,Research on Dynamic Pig Counting Method Based on Improved YOLOv7 Combined with DeepSORT,10.3390/ani14081227,"A pig inventory is a crucial component of achieving precise and large-scale farming. In complex pigsty environments, due to pigs’ stress reactions and frequent obstructions, it is challenging to count them accurately and automatically. This difficulty contrasts with most current deep learning studies, which rely on overhead views or static images for counting. This research proposes a video-based dynamic counting method, combining YOLOv7 with DeepSORT. By utilizing the YOLOv7 network structure and optimizing the second and third 3 × 3 convolution operations in the head network ELAN-W with PConv, the model reduces the computational demand and improves the inference speed without sacrificing accuracy. To ensure that the network acquires accurate position perception information at oblique angles and extracts rich semantic information, we introduce the coordinate attention (CA) mechanism before the three re-referentialization paths (REPConv) in the head network, enhancing robustness in complex scenarios. Experimental results show that, compared to the original model, the improved model increases the mAP by 3.24, 0.05, and 1.00 percentage points for oblique, overhead, and all pig counting datasets, respectively, while reducing the computational cost by 3.6 GFLOPS. The enhanced YOLOv7 outperforms YOLOv5, YOLOv4, YOLOv3, Faster RCNN, and SSD in target detection with mAP improvements of 2.07, 5.20, 2.16, 7.05, and 19.73 percentage points, respectively. In dynamic counting experiments, the improved YOLOv7 combined with DeepSORT was tested on videos with total pig counts of 144, 201, 285, and 295, yielding errors of -3, -3, -4, and -26, respectively, with an average accuracy of 96.58% and an FPS of 22. This demonstrates the model’s capability of performing the real-time counting of pigs in various scenes, providing valuable data and references for automated pig counting research.",2024.0,"Xiaobao Shao, Zhixuan Zhou, Wenjing Xue, Guoye Zhang, Jianyu Liu, Hongwen Yan","The research focuses on a dynamic pig counting method using an improved YOLOv7 combined with DeepSORT for accurate livestock detection and counting. It addresses challenges in complex pigsty environments, enhancing counting accuracy through optimized convolution operations and the introduction of a coordinate attention mechanism. The model achieved an average accuracy of 96.58% in dynamic counting experiments, demonstrating its effectiveness in real-time detection and classification of pigs across various scenes, outperforming previous models in both accuracy and computational efficiency."," - The paper addresses the challenge of accurately and automatically counting pigs in complex pigsty environments, where pigs exhibit stress reactions and frequently obstruct each other, making it difficult to achieve precise inventory counts. This issue is compounded by the limitations of current deep learning studies that typically rely on overhead views or static images for counting.

- The proposed solution involves a video-based dynamic counting method that combines the YOLOv7 network structure with DeepSORT, aiming to enhance counting accuracy and speed while reducing computational demands, thereby overcoming the difficulties associated with traditional counting methods in dynamic and obstructed environments."," - The research proposes a video-based dynamic counting method that combines the YOLOv7 network structure with DeepSORT, optimizing the second and third 3 × 3 convolution operations in the head network ELAN-W with PConv to reduce computational demand and improve inference speed without sacrificing accuracy.

- To enhance the model's robustness in complex scenarios, the study introduces the coordinate attention (CA) mechanism before the three re-referentialization paths (REPConv) in the head network, ensuring accurate position perception at oblique angles and rich semantic information extraction."," - The research primarily focuses on improving the accuracy and speed of pig counting in complex environments using a video-based dynamic counting method. However, it does not address the potential impact of varying lighting conditions or environmental factors on the model's performance, which could affect the robustness of the counting method in real-world applications.

- While the study demonstrates significant improvements in counting accuracy and computational efficiency compared to previous models, it lacks a comprehensive analysis of the model's performance across different pig breeds or sizes, which may influence the counting accuracy and generalizability of the proposed method in diverse farming scenarios."," - The study utilized pig counting datasets that included various scenarios, specifically focusing on oblique, overhead, and all pig counting datasets to evaluate the performance of the improved YOLOv7 model.
- Experimental results indicated that the improved model was tested on videos with total pig counts of 144, 201, 285, and 295, demonstrating its effectiveness in dynamic counting across different scenes."," - The research highlights the challenges of accurately counting pigs in complex environments, where stress reactions and obstructions hinder traditional counting methods that rely on overhead views or static images. This sets the stage for the need for a dynamic counting method that can adapt to real-time conditions.

- The study introduces an improved YOLOv7 model combined with DeepSORT, which optimizes computational efficiency and enhances accuracy in pig counting. The model's performance is validated through experimental results, showing significant improvements in mean Average Precision (mAP) and reduced computational costs compared to previous models, indicating its superiority in dynamic counting scenarios."," - The improved YOLOv7 model, when combined with DeepSORT, achieved an average accuracy of 96.58% in dynamic counting experiments across various video datasets, with errors of -3, -3, -4, and -26 for total pig counts of 144, 201, 285, and 295, respectively. This indicates the model's effectiveness in real-time pig counting in complex environments.

- The enhancements made to the YOLOv7 model resulted in a mean Average Precision (mAP) increase of 3.24, 0.05, and 1.00 percentage points for oblique, overhead, and all pig counting datasets, respectively, while also reducing the computational cost by 3.6 GFLOPS, demonstrating improved performance over previous models like YOLOv5, YOLOv4, YOLOv3, Faster RCNN, and SSD."," - The research presents a dynamic pig counting method that integrates an improved YOLOv7 model with DeepSORT, addressing the challenges of accurately counting pigs in complex environments where they may obstruct each other and exhibit stress reactions. The model optimizes computational efficiency while enhancing accuracy through modifications in the network structure and the introduction of a coordinate attention mechanism.

- Experimental results indicate that the improved YOLOv7 model achieves a mean Average Precision (mAP) increase across various counting datasets and demonstrates superior performance compared to earlier YOLO versions and other detection models. In dynamic counting tests, the model maintains an average accuracy of 96.58% with a frame rate of 22 FPS, showcasing its effectiveness for real-time pig counting in diverse scenarios."," - The research highlights the challenge of accurately counting pigs in complex pigsty environments due to pigs' stress reactions and frequent obstructions, which complicates the counting process compared to studies that utilize overhead views or static images.

- While the improved YOLOv7 model demonstrates enhanced performance in dynamic counting, the paper does not explicitly mention any limitations regarding the model's performance in extremely crowded scenarios or its adaptability to different lighting conditions, which could affect its accuracy in real-world applications."," - The research aims to develop a video-based dynamic counting method for pigs that addresses the challenges of accurate counting in complex pigsty environments, where pigs exhibit stress reactions and frequent obstructions, contrasting with traditional methods that rely on overhead views or static images.

- The study focuses on improving the YOLOv7 network structure by optimizing convolution operations and introducing the coordinate attention mechanism to enhance position perception and semantic information extraction, ultimately achieving higher accuracy and reduced computational costs in real-time pig counting.",,yolo,"- YOLOv7 network structure
- DeepSORT
- ELAN-W with PConv
- Coordinate Attention (CA) mechanism
- REPConv"
Proceedings Article,An Improved Pig Counting Algorithm Based on YOLOv5 and DeepSORT Model,10.3390/s23146309,"Pig counting is an important task in pig sales and breeding supervision. Currently, manual counting is low-efficiency and high-cost and presents challenges in terms of statistical analysis. In response to the difficulties faced in pig part feature detection, the loss of tracking due to rapid movement, and the large counting deviation in pig video tracking and counting research, this paper proposes an improved pig counting algorithm (Mobile Pig Counting Algorithm with YOLOv5xpig and DeepSORTPig (MPC-YD)) based on YOLOv5 + DeepSORT model. The algorithm improves the detection rate of pig body parts by adding two different sizes of SPP networks and using SoftPool instead of MaxPool operations in YOLOv5x. In addition, the algorithm includes a pig reidentification network, a pig-tracking method based on spatial state correction, and a pig counting method based on frame number judgment on the DeepSORT algorithm to improve pig tracking accuracy. Experimental analysis shows that the MPC-YD algorithm achieves an average precision of 99.24% in pig object detection and an accuracy of 85.32% in multitarget pig tracking. In the aisle environment of the slaughterhouse, the MPC-YD algorithm achieves a correlation coefficient (R2) of 98.14% in pig counting from video, and it achieves stable pig counting in a breeding environment. The algorithm has a wide range of application prospects.",2023.0,"Yigui Huang, Deqin Xiao, Junbin Liu","The paper presents an improved pig counting algorithm (MPC-YD) that enhances livestock detection, counting, and classification using the YOLOv5 and DeepSORT models. It addresses challenges in detecting pig body parts and tracking accuracy, achieving an average precision of 99.24% in pig object detection and 85.32% in multitarget tracking. The algorithm's effectiveness is demonstrated in various environments, including slaughterhouses and breeding settings, showcasing its potential for accurate livestock counting and classification."," - The paper addresses the inefficiencies and high costs associated with manual counting of pigs, which poses challenges for statistical analysis in pig sales and breeding supervision. 
- It highlights specific difficulties in pig part feature detection, loss of tracking due to rapid movement, and significant counting deviations in video tracking and counting research, necessitating the development of a more effective counting algorithm."," - The paper proposes an improved pig counting algorithm (MPC-YD) that utilizes the YOLOv5 model enhanced with two different sizes of SPP networks and replaces MaxPool operations with SoftPool to improve the detection rate of pig body parts.

- The algorithm incorporates a pig reidentification network, a spatial state correction-based tracking method, and a counting method based on frame number judgment within the DeepSORT algorithm to enhance the accuracy of pig tracking and counting."," - The paper addresses challenges in pig part feature detection and tracking loss due to rapid movement, indicating a gap in existing methodologies that struggle with these issues in pig video tracking and counting research.
- There is a noted large counting deviation in current pig counting methods, suggesting a gap in accuracy and reliability that the proposed MPC-YD algorithm aims to fill by improving detection rates and tracking accuracy.",,," - The MPC-YD algorithm achieves an average precision of 99.24% in pig object detection and an accuracy of 85.32% in multitarget pig tracking, demonstrating its effectiveness in accurately identifying and tracking pigs in various environments.
- In the aisle environment of the slaughterhouse, the MPC-YD algorithm achieves a correlation coefficient (R2) of 98.14% in pig counting from video, indicating its reliability and stability in counting pigs in a breeding environment."," - The paper presents an improved pig counting algorithm, named Mobile Pig Counting Algorithm with YOLOv5xpig and DeepSORTPig (MPC-YD), which addresses challenges in pig part feature detection, tracking loss due to rapid movement, and counting deviations in video tracking. The algorithm enhances detection rates by incorporating SPP networks and SoftPool operations in YOLOv5x, along with a pig reidentification network and a refined tracking method.

- Experimental results demonstrate that the MPC-YD algorithm achieves an impressive average precision of 99.24% in pig object detection and 85.32% accuracy in multitarget tracking. In a slaughterhouse aisle environment, it shows a correlation coefficient of 98.14% for pig counting from video, indicating its effectiveness and potential for stable counting in breeding environments."," - The paper addresses challenges in pig part feature detection, particularly the loss of tracking due to rapid movement, which can lead to inaccuracies in counting and tracking pigs in video footage.
- There is a noted large counting deviation in existing pig video tracking and counting research, indicating that previous methods may not provide reliable results in various environments, such as slaughterhouses and breeding facilities."," - The research aims to develop an improved pig counting algorithm (MPC-YD) that enhances the detection rate of pig body parts by incorporating two different sizes of SPP networks and replacing MaxPool operations with SoftPool in the YOLOv5x model, addressing challenges in pig part feature detection.

- The study focuses on improving pig tracking accuracy through the implementation of a pig reidentification network, a spatial state correction-based tracking method, and a frame number judgment-based counting method within the DeepSORT algorithm, ultimately achieving high precision in pig object detection and multitarget tracking.",,yolo,"- YOLOv5
- SPP networks
- SoftPool
- Pig reidentification network
- Spatial state correction-based tracking method
- DeepSORT algorithm"
Journal Article,Sheep Counting Method Based on Multiscale Module Deep Neural Network,10.1109/access.2022.3221542,"Due to the uneven distribution and large scale change of sheep in the pasture, it is not conducive to the counting and statistics of sheep in animal husbandry. The traditional target counting algorithm has low counting accuracy in the field of animal husbandry, and there are fewer sheep data sets for research. To solve these problems, the data set of sheep density estimation was established, and a method of grassland sheep number estimation based on multi-scale residual visual information fusion Network (MRVIFNet) was proposed. This method extracts multi-scale features of sheep targets by using multiple parallel hole convolutions with different hole rates, and designs a depth neural network that is more suitable for live counting of sheep, so as to reduce the grid effect caused by hole convolution and better adapt to multi-scale changes of sheep. In the sheep density data set, the method obtained the lowest mean absolute error (MAE) and root mean square error (RMSE). In addition, a convolutional neural network model based on view branch sharing is also studied. Compared with the five popular methods, this method can achieve better performance. It is applied to solve the problem of pedestrian scale change and chaotic distribution in complex scenes; The performance of this method is better than that of comparison method, and the application results in actual scenarios verify the effectiveness of this method. ",2022.0,,"The paper presents a method for sheep counting and density estimation using a multi-scale residual visual information fusion Network (MRVIFNet). This approach addresses challenges in livestock detection by extracting multi-scale features through parallel hole convolutions, enhancing counting accuracy in unevenly distributed sheep populations. The method outperforms traditional algorithms, achieving the lowest mean absolute error (MAE) and root mean square error (RMSE) in sheep density data sets, thus effectively addressing counting and classification in livestock management."," - The paper addresses the challenges in counting and estimating sheep numbers in pastures due to their uneven distribution and large scale changes, which complicate accurate counting and statistics in animal husbandry.
- It highlights the limitations of traditional target counting algorithms, which exhibit low counting accuracy in the field of animal husbandry, and notes the scarcity of sheep data sets available for research purposes."," - The paper proposes a method for sheep number estimation based on a multi-scale residual visual information fusion Network (MRVIFNet), which utilizes multiple parallel hole convolutions with different hole rates to extract multi-scale features of sheep targets. This approach aims to reduce the grid effect caused by hole convolution and better adapt to the multi-scale changes of sheep in the pasture.

- Additionally, the study explores a convolutional neural network model based on view branch sharing, which is designed to address the challenges of pedestrian scale change and chaotic distribution in complex scenes. This model demonstrates better performance compared to five popular methods in the context of sheep counting."," - The paper highlights the challenge of low counting accuracy in traditional target counting algorithms within the field of animal husbandry, indicating a gap in existing methodologies that can effectively handle the uneven distribution and large scale changes of sheep in pastures.

- There is a noted scarcity of sheep data sets for research, which presents a gap in the availability of comprehensive data necessary for developing and validating more accurate sheep counting methods."," - A data set of sheep density estimation was established to address the challenges of counting and statistics of sheep in animal husbandry due to uneven distribution and large scale changes.
- The study utilized a sheep density data set to evaluate the performance of the proposed method, which achieved the lowest mean absolute error (MAE) and root mean square error (RMSE) in sheep counting."," - The paper addresses the challenges in counting sheep in pastures due to their uneven distribution and large scale changes, highlighting the limitations of traditional target counting algorithms which exhibit low accuracy in animal husbandry contexts. It emphasizes the scarcity of sheep data sets available for research, which complicates the development of effective counting methods.

- To overcome these issues, the authors established a sheep density estimation data set and proposed a novel method using a multi-scale residual visual information fusion Network (MRVIFNet). This method leverages multiple parallel hole convolutions with varying hole rates to extract multi-scale features of sheep, aiming to reduce grid effects and improve adaptability to the diverse scales of sheep in the field."," - The proposed method, based on the multi-scale residual visual information fusion Network (MRVIFNet), achieved the lowest mean absolute error (MAE) and root mean square error (RMSE) in the sheep density data set, indicating high counting accuracy for sheep in pastures.
- The convolutional neural network model based on view branch sharing demonstrated better performance compared to five popular methods, effectively addressing the challenges of pedestrian scale change and chaotic distribution in complex scenes, with application results in actual scenarios verifying its effectiveness."," - The paper addresses the challenges of counting sheep in pastures due to their uneven distribution and large scale changes, proposing a method for sheep number estimation using a multi-scale residual visual information fusion Network (MRVIFNet) that effectively extracts multi-scale features through parallel hole convolutions, leading to improved counting accuracy.
  
- The proposed method outperforms traditional counting algorithms, achieving the lowest mean absolute error (MAE) and root mean square error (RMSE) in sheep density data sets, and demonstrates better performance compared to five popular methods in complex scenes, confirming its effectiveness in real-world applications."," - The traditional target counting algorithm has low counting accuracy in the field of animal husbandry, which poses challenges for effective sheep counting and statistics in pastures with uneven distribution and large scale changes of sheep.
- There are fewer sheep data sets available for research, which limits the development and testing of more accurate counting methods in the context of animal husbandry."," - The research aims to establish a data set for sheep density estimation to address the challenges of uneven distribution and large scale changes of sheep in pastures, which hinder accurate counting and statistics in animal husbandry.

- The study proposes a method for estimating sheep numbers using a multi-scale residual visual information fusion Network (MRVIFNet) that extracts multi-scale features of sheep targets, thereby improving counting accuracy and reducing errors in sheep density estimation compared to traditional algorithms."," - Future research could focus on expanding the sheep data sets for better training and validation of counting algorithms, as the current availability of sheep data sets is limited, which affects the accuracy and reliability of counting methods in animal husbandry.

- Another area for future exploration could involve enhancing the multi-scale residual visual information fusion Network (MRVIFNet) to further improve its adaptability to various environmental conditions and sheep distributions, potentially incorporating additional features or advanced techniques to address challenges in complex scenes.",mrvifnet,"Method Used: Multi-scale Residual Visual Information Fusion Network (MRVIFNet), Convolutional Neural Network (CNN)"
Proceedings Article,A Comparison of Different Learning Algorithms for Wildlife Detection and Classification in Animal Conservation Applications,10.1109/ICAIS56108.2023.10073833,"In order to track animal movement patterns, habitat use, population demographics, human-wildlife conflict, vehicle-animal collisions, snare and poaching occurrences, and epidemics, it is essential to monitor wildlife. Over time, accidents between wildlife and vehicles have increased in frequency on both rural and hilly roads and highways. Road deaths are sometimes caused by wildlife crossing the road at inopportune moments. The identification and categorization of animals from picture and video sequences is a popular area of study. Current methods for wildlife monitoring depend on image processing. This study provides a reliable method for detecting wildlife and divides it into two categories: animal-human conflict and animal-vehicle collision. Different learning approaches are employed to classify the animals with the use of datasets and a live motion sensor. Applications for wildlife have employed machine learning and deep learning extensively. This article discusses a variety of learning techniques and offers the authors' answers. There may be a chance to identify and categories wildlife when it enters a living area, an agricultural region, or a roadway. Various authors provide various classification and identification strategies based on Camera trap and Dataset.",2023.0,"M. Mangaleswaran, M. Azhagiri","The paper primarily focuses on wildlife detection and classification, particularly in the context of animal-human conflict and animal-vehicle collisions. While it discusses various learning algorithms for identifying and categorizing animals using image processing techniques, it does not specifically address livestock detection, counting, or classification. The methodologies explored are tailored towards monitoring wildlife rather than livestock management, indicating a gap in the application of these techniques for agricultural animals."," - The paper addresses the increasing frequency of accidents between wildlife and vehicles, particularly on rural and hilly roads and highways, which often results in road deaths due to wildlife crossing at inopportune moments. 

- It emphasizes the necessity of monitoring wildlife to track various factors such as animal movement patterns, habitat use, population demographics, and incidents of human-wildlife conflict, which are critical for effective animal conservation efforts."," - The study employs various learning approaches, including machine learning and deep learning techniques, to classify animals based on datasets and live motion sensor data. These methods are crucial for detecting wildlife and categorizing incidents related to animal-human conflict and animal-vehicle collisions.

- The identification and categorization of animals are primarily based on image processing techniques, utilizing camera trap images and video sequences to monitor wildlife effectively and track their movement patterns and interactions with human environments."," - The study highlights the need for improved methods in detecting and classifying wildlife, particularly in the context of human-wildlife conflict and animal-vehicle collisions, suggesting that current image processing techniques may not be sufficient for accurate monitoring and identification in various environments.

- There is an indication that while machine learning and deep learning have been extensively employed in wildlife applications, there may be a lack of comprehensive evaluation of different learning algorithms and their effectiveness in real-time wildlife detection and classification, pointing to a potential area for further research and development."," - The study utilizes datasets that are specifically designed for wildlife monitoring, which include images and video sequences captured from camera traps. These datasets are essential for training the learning algorithms to accurately detect and classify wildlife.
  
- The research emphasizes the use of a live motion sensor in conjunction with the datasets, allowing for real-time monitoring and classification of animals as they enter various environments such as living areas, agricultural regions, or roadways."," - The study highlights the increasing frequency of wildlife-vehicle collisions and the necessity for effective wildlife monitoring to track various factors such as animal movement patterns, habitat use, and human-wildlife conflict. It emphasizes the importance of identifying and categorizing animals from images and videos to mitigate these issues.

- The paper discusses the application of different learning algorithms, including machine learning and deep learning, for wildlife detection and classification. It categorizes the detection methods into two main areas: animal-human conflict and animal-vehicle collision, showcasing various strategies based on camera traps and datasets used for wildlife monitoring."," - The study provides a reliable method for detecting wildlife, categorizing it into two main areas: animal-human conflict and animal-vehicle collision, which highlights the importance of monitoring wildlife interactions with human activities and infrastructure.
- Various learning techniques are discussed, showcasing the extensive use of machine learning and deep learning in wildlife monitoring applications, particularly in classifying animals using datasets and live motion sensors."," - The study emphasizes the importance of monitoring wildlife to track various factors such as animal movement patterns, habitat use, and incidents of human-wildlife conflict, particularly focusing on the increasing frequency of vehicle-animal collisions on roads. It highlights the need for effective wildlife detection and classification methods to mitigate these issues.

- The research explores different learning algorithms, including machine learning and deep learning techniques, for the identification and categorization of animals from images and video sequences. It categorizes wildlife detection into two main areas: animal-human conflict and animal-vehicle collision, and discusses various strategies based on camera traps and datasets for effective wildlife monitoring.",," - The research aims to develop a reliable method for detecting wildlife and categorizing incidents into two main categories: animal-human conflict and animal-vehicle collision, thereby enhancing wildlife monitoring efforts.
- The study explores various learning techniques, including machine learning and deep learning, to classify animals using datasets and live motion sensors, with the goal of improving identification and categorization of wildlife in different environments such as living areas, agricultural regions, and roadways."," - Future research could focus on improving the accuracy and efficiency of wildlife detection and classification algorithms, particularly in distinguishing between animal-human conflicts and animal-vehicle collisions, utilizing advanced machine learning and deep learning techniques on diverse datasets and live motion sensor data.

- Another area for future exploration may involve developing more robust methods for monitoring wildlife in various environments, such as urban areas, agricultural regions, and roadways, to enhance the identification and categorization of wildlife as they enter these spaces.","deep learning, machine learning","Method Used: Machine Learning, Deep Learning, Image Processing Techniques."
Proceedings Article,A Comparison of Different Learning Algorithms for Wildlife Detection and Classification in Animal Conservation Applications,10.1109/icais56108.2023.10073833,"In order to track animal movement patterns, habitat use, population demographics, human-wildlife conflict, vehicle-animal collisions, snare and poaching occurrences, and epidemics, it is essential to monitor wildlife. Over time, accidents between wildlife and vehicles have increased in frequency on both rural and hilly roads and highways. Road deaths are sometimes caused by wildlife crossing the road at inopportune moments. The identification and categorization of animals from picture and video sequences is a popular area of study. Current methods for wildlife monitoring depend on image processing. This study provides a reliable method for detecting wildlife and divides it into two categories: animal-human conflict and animal-vehicle collision. Different learning approaches are employed to classify the animals with the use of datasets and a live motion sensor. Applications for wildlife have employed machine learning and deep learning extensively. This article discusses a variety of learning techniques and offers the authors' answers. There may be a chance to identify and categories wildlife when it enters a living area, an agricultural region, or a roadway. Various authors provide various classification and identification strategies based on Camera trap and Dataset. ",2023.0,,"The paper primarily focuses on wildlife detection and classification, particularly in the context of animal-human conflict and animal-vehicle collisions. While it discusses various learning algorithms for identifying and categorizing animals using image processing techniques, it does not specifically address livestock detection, counting, or classification. The methodologies explored are tailored towards monitoring wildlife movements and interactions rather than agricultural livestock management. Thus, the findings may not be directly applicable to livestock-related applications."," - The paper addresses the increasing frequency of accidents between wildlife and vehicles, particularly on rural and hilly roads and highways, which often results in road deaths due to wildlife crossing at inopportune moments. 

- It emphasizes the necessity of monitoring wildlife to track various factors such as animal movement patterns, habitat use, population demographics, and incidents of human-wildlife conflict, which are critical for effective animal conservation efforts."," - The study employs various learning approaches, including machine learning and deep learning techniques, to classify animals based on datasets and live motion sensor data. These methods are crucial for detecting wildlife and categorizing incidents related to animal-human conflict and animal-vehicle collisions.

- The identification and categorization of animals are primarily based on image processing methods, utilizing camera trap images and video sequences to monitor wildlife effectively and track their movement patterns and interactions with human environments."," - The study highlights the need for improved methods in detecting and classifying wildlife, particularly in the context of human-wildlife conflict and vehicle-animal collisions, suggesting that current image processing techniques may not be sufficient for accurate monitoring and identification in various environments.

- There is an indication that while machine learning and deep learning have been extensively employed in wildlife applications, there may be unexplored or underutilized learning approaches that could enhance the effectiveness of wildlife detection and classification, particularly in dynamic settings such as agricultural regions and roadways."," - The study utilizes datasets that are specifically designed for wildlife monitoring, which include images and video sequences for the identification and categorization of animals.
- The research emphasizes the use of camera traps as a source of data, which are employed to capture wildlife in various environments, aiding in the classification and identification strategies discussed by different authors."," - The study highlights the increasing frequency of wildlife-vehicle collisions and the necessity for effective wildlife monitoring to track various factors such as animal movement patterns, habitat use, and human-wildlife conflict. It emphasizes the importance of identifying and categorizing animals from images and videos to mitigate these issues.

- The paper discusses the application of different learning algorithms, including machine learning and deep learning, for wildlife detection and classification. It categorizes the detection methods into two main areas: animal-human conflict and animal-vehicle collision, showcasing various strategies based on camera traps and datasets for effective wildlife monitoring."," - The study provides a reliable method for detecting wildlife, categorizing it into two main areas: animal-human conflict and animal-vehicle collision, which highlights the importance of monitoring wildlife to prevent accidents and conflicts.
- Various learning techniques are discussed, showcasing the extensive use of machine learning and deep learning in wildlife monitoring applications, particularly in classifying animals using datasets and live motion sensors."," - The study emphasizes the importance of monitoring wildlife to track various factors such as animal movement patterns, habitat use, and incidents of human-wildlife conflict, particularly focusing on the increasing frequency of vehicle-animal collisions on roads. It highlights the need for effective wildlife detection and classification methods to mitigate these issues.

- The research explores different learning algorithms, including machine learning and deep learning techniques, for the identification and categorization of animals from images and video sequences. It categorizes wildlife monitoring into two main areas: animal-human conflict and animal-vehicle collision, and discusses various strategies based on camera traps and datasets for effective wildlife classification."," - The study highlights the increasing frequency of wildlife-vehicle collisions, indicating a need for improved monitoring methods, but does not specify the limitations of current image processing techniques used for wildlife detection and classification.
  
- While various learning approaches are employed for classifying animals, the paper does not address potential challenges or limitations associated with the datasets and live motion sensors used in the monitoring process."," - The research aims to develop a reliable method for detecting wildlife and categorizing incidents into two main categories: animal-human conflict and animal-vehicle collision, addressing the increasing frequency of wildlife-related accidents on roads.

- The study explores various learning algorithms, including machine learning and deep learning techniques, to classify animals using datasets and live motion sensors, enhancing the identification and monitoring of wildlife in different environments such as living areas, agricultural regions, and roadways."," - Future research could focus on improving the accuracy and efficiency of wildlife detection and classification algorithms, particularly in distinguishing between animal-human conflicts and animal-vehicle collisions, to enhance monitoring efforts in various environments such as living areas, agricultural regions, and roadways.

- There is potential for exploring new machine learning and deep learning techniques that can be applied to diverse datasets and live motion sensor data, which may lead to more effective wildlife monitoring solutions and better understanding of animal movement patterns and behaviors.","deep learning, machine learning","- Machine learning techniques  
- Deep learning techniques  
- Image processing methods  "
Proceedings Article,Deep Learning Methods for Animal Counting in Camera Trap Images,10.1109/ICTAI56018.2022.00143,"Camera traps are widely used to monitor the biodiversity and population density of animal species. Camera trap images are usually taken in bursts, and the animal counting problem for a sequence of camera trap images is also an important part of evaluating animal population density. In this paper, two new animal counting methods based on Microsoft MegaDetector V 4 have been proposed. FilterDetector uses different filters with bounding box ensemble algorithms to achieve more accurate bounding box detection. DLEDetector is an ensemble method that uses two base deep learning models to correct and enhance the detection result of MegaDetector. Our experimental results in iWildCam 2022 competition test dataset show that both methods outperformed the best method in iWildCam 2021 and the baseline method based on MegaDetector V 4 in iWildCam 2022 competition by 9.09% and 6.44%, respectively, and ranked first and third in the competition.",2022.0,"Yizhen Wang, Yang Zhang, Yuan-Yao Feng, Y. Shang","The paper focuses on animal counting methods using camera trap images, specifically for wildlife monitoring rather than livestock detection. It introduces two methods, FilterDetector and DLEDetector, which enhance bounding box detection and improve results from Microsoft MegaDetector V 4. While the techniques may be applicable to various animal species, including livestock, the research primarily addresses biodiversity and population density evaluation in wildlife contexts, not specifically livestock counting and classification."," - The paper addresses the animal counting problem in camera trap images, which is crucial for evaluating animal population density and biodiversity monitoring. Camera traps capture images in bursts, making it essential to accurately count animals across a sequence of images.

- Two new methods for animal counting are proposed: FilterDetector, which utilizes various filters and bounding box ensemble algorithms for improved detection accuracy, and DLEDetector, an ensemble method that enhances detection results by combining two base deep learning models with Microsoft MegaDetector V 4."," - **FilterDetector**: This method utilizes various filters combined with bounding box ensemble algorithms to enhance the accuracy of bounding box detection in camera trap images.

- **DLEDetector**: This is an ensemble method that employs two base deep learning models to improve and refine the detection results produced by Microsoft MegaDetector V 4.",," - The study utilized the iWildCam 2022 competition test dataset to evaluate the performance of the proposed animal counting methods.
- The experimental results indicated that the new methods, FilterDetector and DLEDetector, outperformed the baseline method based on MegaDetector V 4 in the iWildCam 2022 competition."," - The paper discusses the significance of camera traps in monitoring biodiversity and animal population density, highlighting the importance of accurately counting animals in sequences of camera trap images for evaluating population density.
- It introduces two new animal counting methods, FilterDetector and DLEDetector, which improve upon the existing Microsoft MegaDetector V 4 by utilizing advanced filtering techniques and ensemble deep learning models to enhance bounding box detection accuracy."," - The proposed methods, FilterDetector and DLEDetector, achieved significant improvements in animal counting accuracy, outperforming the best method from the iWildCam 2021 competition by 9.09% and the baseline method based on MegaDetector V 4 by 6.44% in the iWildCam 2022 competition test dataset.
- In the iWildCam 2022 competition, FilterDetector ranked first, while DLEDetector secured the third position, demonstrating the effectiveness of the new deep learning methods for animal counting in camera trap images."," - The paper presents two new animal counting methods, FilterDetector and DLEDetector, which are based on Microsoft MegaDetector V 4, aimed at improving the accuracy of bounding box detection in camera trap images used for monitoring animal populations.
- Experimental results from the iWildCam 2022 competition demonstrate that both methods significantly outperformed previous methods, with FilterDetector achieving a 9.09% improvement over the best method from iWildCam 2021 and DLEDetector achieving a 6.44% improvement, ranking first and third in the competition, respectively.",," - The paper aims to develop two new animal counting methods, FilterDetector and DLEDetector, based on Microsoft MegaDetector V 4, to improve the accuracy of bounding box detection in camera trap images for monitoring animal populations.
- The research seeks to enhance the performance of animal counting methods by demonstrating that both proposed methods outperform previous benchmarks, achieving a 9.09% and 6.44% improvement over the best method from iWildCam 2021 and the baseline method in the iWildCam 2022 competition, respectively.",,deep learning,"- **FilterDetector**: Bounding box ensemble algorithms.
- **DLEDetector**: Ensemble method with deep learning models."
Journal Article,Automation of cattle livestock,10.1109/ickecs61492.2024.10616665,"An innovative paper called Automation of Cattle Livestock aims to revolutionize the management and care of cattle. The health of cattle and the livelihoods of dependent people are seriously threatened by disease outbreaks, and a lack of veterinary care in a country where cattle are essential to rural economies. In order to improve illness diagnosis, individual cow tracking and food management, this research offers an integrated approach to the automation of cattle livestock management. First, using image processing techniques, a Convolutional Neural Network (CNN)-based system is built for the early diagnosis of lumpy illness in cattle populations. The work makes use of a 700-image collection from Lumpy Skin Image dataset. This approach makes it possible to quickly identify and isolate those that are ill, which reduces the amount of time the disease spreads through out the herd. Second, an RFID technology is used for a productive tracking and identification system is suggested that uses each cow’s unique ID for tracking purpose. This makes it easier to identify and handle every animal in the herd. Furthermore, the system indicates resource usage and nutritional intake by monitoring and controlling feeding item quantities in real-time for cattle and livestock.",2024.0,"C Rangaswamy, K Monisha, H S Rajini, B A Rakshitha","The paper discusses an innovative approach to livestock management through the use of a Convolutional Neural Network (CNN) for early diagnosis of diseases like lumpy skin disease in cattle. While it primarily focuses on disease identification and tracking using RFID technology, the image processing techniques employed can also be adapted for livestock detection, counting, and classification. This integrated system enhances the management of cattle by enabling quick identification of health issues and efficient tracking of individual animals."," - The health of cattle and the livelihoods of people dependent on them are threatened by disease outbreaks and a lack of veterinary care, particularly in rural economies where cattle are essential.
- The paper addresses the need for improved illness diagnosis, individual cow tracking, and food management to enhance the management and care of cattle livestock."," - The paper employs image processing techniques to develop a Convolutional Neural Network (CNN)-based system for the early diagnosis of lumpy illness in cattle populations, utilizing a dataset of 700 images from the Lumpy Skin Image dataset to quickly identify and isolate sick animals, thereby reducing disease spread within the herd.

- An RFID technology is implemented for a productive tracking and identification system, which assigns a unique ID to each cow for effective tracking, facilitating the identification and management of every animal in the herd, while also monitoring and controlling real-time resource usage and nutritional intake.",," - The study utilizes a collection of 700 images from the Lumpy Skin Image dataset to build a Convolutional Neural Network (CNN)-based system for the early diagnosis of lumpy illness in cattle populations.
- This dataset is crucial for enabling the quick identification and isolation of sick cattle, thereby reducing the spread of disease throughout the herd."," - The paper discusses the critical need for improved cattle health management due to disease outbreaks and inadequate veterinary care, which threaten both cattle health and the livelihoods of rural communities that depend on them. 
- It presents an integrated approach to cattle livestock management that includes a CNN-based system for early diagnosis of lumpy skin disease using a dataset of 700 images, and an RFID technology for effective tracking and identification of individual cows, enhancing resource management and nutritional monitoring."," - The paper presents a Convolutional Neural Network (CNN)-based system that utilizes image processing techniques for the early diagnosis of lumpy skin disease in cattle, enabling quick identification and isolation of infected animals, which helps to reduce the spread of the disease within the herd.

- An RFID technology-based tracking and identification system is proposed, allowing for the unique identification of each cow, facilitating better management of the herd, and enabling real-time monitoring and control of resource usage and nutritional intake for improved cattle care."," - The paper ""Automation of Cattle Livestock"" presents an integrated approach to enhance the management and care of cattle, addressing the challenges posed by disease outbreaks and inadequate veterinary care that threaten both cattle health and rural economies. It focuses on improving illness diagnosis, individual cow tracking, and food management.

- The research utilizes a Convolutional Neural Network (CNN) for early diagnosis of lumpy skin disease in cattle, employing a dataset of 700 images to facilitate quick identification and isolation of affected animals. Additionally, it proposes an RFID-based tracking system for efficient identification and management of each cow, while also monitoring real-time resource usage and nutritional intake.",," - The research aims to improve illness diagnosis in cattle by developing a Convolutional Neural Network (CNN)-based system that utilizes image processing techniques for the early detection of lumpy skin disease, enabling quick identification and isolation of affected animals to prevent disease spread within the herd.

- Another objective is to implement an RFID technology-based tracking and identification system that assigns a unique ID to each cow, facilitating efficient management of the herd by allowing for real-time monitoring of resource usage and nutritional intake through controlled feeding item quantities."," - Future research could explore the integration of advanced machine learning algorithms beyond Convolutional Neural Networks (CNNs) for more accurate and efficient diagnosis of various cattle diseases, potentially expanding the dataset to include a wider range of illnesses affecting cattle populations.

- Another area for future research could involve enhancing the RFID tracking system by incorporating IoT (Internet of Things) technologies to enable real-time data analytics and predictive modeling for better resource management and nutritional optimization in cattle livestock management.","cnn, rfid",**Method Used:** Convolutional Neural Network (CNN) for image processing and RFID technology for tracking and identification.
Journal Article,Hitching Artificial Intelligence and IoT and for Livestock Management Competence,10.4018/979-8-3693-3061-6.ch020,"Agriculture has always been a human-centered industry and technological advancements have made it possible to increase production, sustainability, and efficiency. An important area of agriculture, livestock management, has profited from the combination of AI and IoT. Farmers are able to optimize feeding, track activity, keep an eye on the health of their cattle, and anticipate possible problems before they become serious because of these technologies. The most recent developments, difficulties, and potential applications of AI and IoT integration in cattle management are covered in this chapter. This chapter scrutinizes the potential of AI and IoT technology as well as its potential for future development in the field of livestock management. Its goal is to give a thorough review of this field's present technological condition with an emphasis on how it might be applied to develop livestock management systems that are more productive, sustainable and efficient. ",2024.0,"Bhupinder Singh, Christian Kaunert","The integration of AI and IoT in livestock management enhances detection, counting, and classification of cattle. These technologies enable farmers to optimize feeding and monitor health by utilizing sensors and data analytics. AI algorithms can analyze data from IoT devices to accurately identify and classify livestock, track their movements, and assess their well-being. This capability allows for proactive management, improving productivity and sustainability in livestock operations while anticipating potential health issues before they escalate."," - The chapter discusses the challenges faced in integrating AI and IoT technologies into livestock management, highlighting the need for advancements to optimize feeding, track cattle activity, monitor health, and predict potential issues before they escalate.

- It emphasizes the importance of developing more productive, sustainable, and efficient livestock management systems through the application of these technologies, while also addressing the current technological state and future development potential in the field."," - The chapter discusses the integration of Artificial Intelligence (AI) and the Internet of Things (IoT) in livestock management, focusing on how these technologies can optimize feeding, track animal activity, monitor health, and predict potential issues before they escalate.

- It provides a comprehensive review of the current technological state in livestock management, highlighting recent developments, challenges, and future applications of AI and IoT to enhance productivity, sustainability, and efficiency in the industry."," - The chapter discusses the current technological state of AI and IoT in livestock management but does not explicitly identify specific research gaps or areas that require further investigation, which could be beneficial for future advancements in the field.

- While the potential applications of AI and IoT in cattle management are covered, the chapter may lack a detailed analysis of the challenges and limitations faced in the integration of these technologies, which could highlight areas needing more research and development.",," - The chapter provides a comprehensive overview of the integration of AI and IoT in livestock management, highlighting how these technologies enable farmers to optimize feeding, monitor cattle activity, and assess health, ultimately leading to improved production, sustainability, and efficiency in agriculture.

- It discusses the latest advancements, challenges, and potential applications of AI and IoT in cattle management, aiming to present the current technological landscape and its implications for developing more effective livestock management systems."," - The integration of AI and IoT in livestock management has enabled farmers to optimize feeding practices, monitor cattle activity, and maintain health oversight, leading to improved production, sustainability, and efficiency in the industry.
- The chapter provides a comprehensive review of the current technological state of AI and IoT in cattle management, highlighting potential future developments and applications that could enhance the productivity and sustainability of livestock management systems."," - The chapter discusses the integration of Artificial Intelligence (AI) and the Internet of Things (IoT) in livestock management, highlighting how these technologies enhance production, sustainability, and efficiency in agriculture. It emphasizes the ability of farmers to optimize feeding, monitor cattle health, track activity, and foresee potential issues before they escalate.

- It provides a comprehensive review of the current technological landscape in livestock management, focusing on the latest advancements, challenges, and future applications of AI and IoT, with the aim of developing more productive, sustainable, and efficient livestock management systems.",," - The chapter aims to provide a comprehensive review of the current technological state of AI and IoT integration in livestock management, focusing on how these technologies can enhance productivity, sustainability, and efficiency in the industry.
- It scrutinizes the potential applications and future development of AI and IoT technologies in cattle management, highlighting their ability to optimize feeding, track activity, monitor health, and anticipate potential issues before they escalate."," - Future research could focus on enhancing the integration of AI and IoT technologies in livestock management to further optimize feeding practices, improve health monitoring, and increase overall efficiency in cattle management systems. This includes developing more sophisticated algorithms for data analysis and predictive modeling to anticipate health issues before they escalate.

- Another area for future research is the exploration of sustainable practices within livestock management through the use of AI and IoT. This could involve investigating how these technologies can contribute to reducing the environmental impact of livestock farming while maintaining productivity and profitability.",,Method Used: Integration of Artificial Intelligence (AI) and Internet of Things (IoT) in livestock management.
Journal Article,Object counting from aerial remote sensing images: application to wildlife and marine mammals,10.48550/arXiv.2306.10439,"Anthropogenic activities pose threats to wildlife and marine fauna, prompting the need for efficient animal counting methods. This research study utilizes deep learning techniques to automate counting tasks. Inspired by previous studies on crowd and animal counting, a UNet model with various backbones is implemented, which uses Gaussian density maps for training, bypassing the need of training a detector. The new model is applied to the task of counting dolphins and elephants in aerial images. Quantitative evaluation shows promising results, with the EfficientNet-B5 backbone achieving the best performance for African elephants and the ResNet18 backbone for dolphins. The model accurately locates animals despite complex image background conditions. By leveraging artificial intelligence, this research contributes to wildlife conservation efforts and enhances coexistence between humans and wildlife through efficient object counting without detection from aerial remote sensing.",2023.0,"Tanya Singh, Hugo Gangloff, Minh-Tan Pham","The paper focuses on counting wildlife and marine mammals, specifically dolphins and elephants, using deep learning techniques and Gaussian density maps, rather than livestock detection. It employs a UNet model to automate counting tasks without requiring detection of individual animals. While it does not address livestock detection, the methodology could potentially be adapted for similar applications in livestock counting and classification, leveraging the regression-based approach demonstrated in the study."," - The paper addresses the challenges posed by anthropogenic activities that threaten wildlife and marine fauna, highlighting the need for efficient animal counting methods to support wildlife conservation efforts. The research focuses on automating the counting process using deep learning techniques, specifically through a UNet model that utilizes Gaussian density maps, thereby eliminating the necessity for traditional detection methods.

- The objective of the study is to develop a regression-based approach for counting animals in aerial imagery without the need for detection, which is often impractical. This method aims to accurately count dolphins and elephants in complex image backgrounds, contributing to enhanced coexistence between humans and wildlife by providing a faster and more efficient means of monitoring animal populations."," - The paper utilizes deep learning techniques, specifically a UNet model with various backbones, for automating animal counting tasks in aerial remote sensing images.
- Gaussian density maps are used for training the model, eliminating the need for training a detector. This regression-based method avoids predicting object coordinates and directly focuses on the counting task, making it less costly in terms of annotations and faster compared to detection-based counting methods."," - One potential research gap identified in the paper is the opportunity to extend the model to count different species of animals, such as those in the Semmacape dataset. This would allow for class-wise counting, which could enhance the understanding of biodiversity and species distribution in various habitats.

- Another gap is the possibility of improving the model through self-supervised learning techniques. By integrating more powerful loss functions, such as contrastive losses, and performing model pre-training with large amounts of unlabeled data, the accuracy and efficiency of the counting method could be significantly enhanced."," - The first dataset used in the study is the Aerial Elephant Dataset (AED), which consists of 2101 aerial images with dot annotations for a total of 15,511 African bush elephants in their natural habitat. This dataset is designed to promote research on animal detection in practical conditions, featuring complex backgrounds.

- The second dataset is the Semmacape Dataset (SD), which contains 165 box-annotated aerial images collected in the Gironde estuary and Pertuis sea Marine Nature Park, France, during spring 2020. This dataset presents challenges due to complex backgrounds, including sun glare and waves, and features marine animals at varying distances from the sea surface, complicating their recognition."," - The research study builds upon previous studies focused on crowd and animal counting, utilizing deep learning techniques to automate the counting process. It specifically implements a UNet model with various backbones, employing Gaussian density maps for training, which allows for counting without the need for a traditional object detection approach.

- The study highlights the effectiveness of the model in counting animals in complex aerial imagery, demonstrating that the EfficientNet-B5 backbone achieved superior performance for counting African elephants, while the ResNet18 backbone was more effective for counting dolphins. This indicates a significant advancement in wildlife conservation efforts through improved counting methodologies."," - The UNet model with EfficientNet-B5 backbone achieved better RMSE (Root Mean Square Error) and MAE (Mean Absolute Error) values of 0.89 and 0.49, respectively, for the African Elephant dataset, showcasing improved performance compared to previous approaches.
- The model outperformed the count-ception approach, demonstrating the effectiveness of utilizing deep learning techniques for automating animal counting tasks in aerial remote sensing images."," - The research focuses on developing an automated method for counting wildlife, specifically dolphins and elephants, from aerial remote sensing images using deep learning techniques. A UNet model is employed, utilizing Gaussian density maps for training, which allows for efficient counting without the need for object detection.

- The study demonstrates promising results, with the EfficientNet-B5 backbone performing best for counting African elephants and the ResNet18 backbone excelling in counting dolphins. The model effectively locates animals in complex backgrounds, contributing to wildlife conservation efforts and promoting coexistence between humans and wildlife."," - The study acknowledges that counting without detection is important because detecting every object instance is not always feasible or necessary, indicating a limitation in the ability to identify individual animals in complex backgrounds where detection may fail.

- The research suggests potential improvements, such as extending the model to count different species of animals and integrating self-supervised learning techniques, which implies that the current model may have limitations in its adaptability and performance across various animal species and datasets."," - The primary objective of this research is to develop a UNet-based model that automates the counting of wildlife, specifically dolphins and elephants, from aerial remote sensing images without the need for detection. This approach utilizes Gaussian density maps to facilitate counting, which is particularly important in scenarios where detecting every individual instance is not feasible.

- Another goal of the study is to enhance wildlife conservation efforts by providing an efficient and accurate method for counting animals in complex backgrounds, thereby improving the coexistence between humans and wildlife. The research aims to demonstrate the potential of deep learning techniques in processing aerial imagery for effective animal population assessments."," - Future research could focus on extending the current model to count different species of animals, such as those in the Semmacape dataset, which would allow for class-wise counting and provide more detailed insights into wildlife populations.

- Another potential area for improvement is the application of self-supervised learning techniques to enhance the model's performance. This could involve integrating more powerful loss functions, like contrastive losses, and utilizing model pre-training when a large amount of unlabeled data is available.",deep learning,Method used: Deep Learning (UNet model with various backbones)
Journal Article,"Advancing Livestock Technology: Intelligent Systemization for Enhanced Productivity, Welfare, and Sustainability",10.3390/agriengineering6020084,"The livestock industry is undergoing significant transformation with the integration of intelligent technologies aimed at enhancing productivity, welfare, and sustainability. This review explores the latest advancements in intelligent systemization (IS), including real-time monitoring, machine learning (ML), and the Internet of Things (IoT), and their impacts on livestock farming. The aim of this study is to provide a comprehensive overview of how these technologies can address industry challenges by improving animal health, optimizing resource use, and promoting sustainable practices. The methods involve an extensive review of the current literature and case studies on intelligent monitoring, data analytics, automation in feeding and climate control, and renewable energy integration. The results indicate that IS enhances livestock well-being through real-time health monitoring and early disease detection, optimizes feeding efficiency, and reduces operational costs through automation. Furthermore, these technologies contribute to environmental sustainability by minimizing waste and reducing the ecological footprint of livestock farming. This study highlights the transformative potential of intelligent technologies in creating a more efficient, humane, and sustainable livestock industry. ",2024.0,"Petru Alexandru Vlaicu, Mihail Alexandru Gras, Arabela Elena Untea, Nicoleta Aurelia Lefter, Mircea Cătălin Rotar","The paper discusses advancements in intelligent systemization (IS) that include real-time monitoring and machine learning (ML) for livestock detection, counting, and classification. These technologies enable accurate tracking of animal health and behavior, facilitating early disease detection and optimizing resource use. By employing data analytics and automation, IS enhances operational efficiency and contributes to improved animal welfare, ultimately transforming livestock management practices and promoting sustainability within the industry."," - The livestock industry faces significant challenges related to productivity, animal welfare, and sustainability, necessitating the integration of intelligent technologies to address these issues effectively.
- The study aims to explore how advancements in intelligent systemization, such as real-time monitoring, machine learning, and the Internet of Things, can improve animal health, optimize resource use, and promote sustainable practices in livestock farming."," - The methods involve an extensive review of the current literature and case studies on intelligent monitoring, data analytics, automation in feeding and climate control, and renewable energy integration.
- The study focuses on the application of intelligent technologies such as real-time monitoring, machine learning, and the Internet of Things to address challenges in the livestock industry."," - The paper does not explicitly mention any identified research gaps within the livestock technology field, focusing instead on the advancements and impacts of intelligent systemization.
- While the study provides a comprehensive overview of how intelligent technologies can address industry challenges and improve various aspects of livestock farming, it does not delve into specific areas where further research is needed to enhance the implementation and effectiveness of these technologies.",," - The literature review encompasses an extensive examination of current advancements in intelligent systemization (IS) technologies, including real-time monitoring, machine learning (ML), and the Internet of Things (IoT), and their applications in addressing challenges within the livestock industry.
- It includes case studies on intelligent monitoring, data analytics, automation in feeding and climate control, and the integration of renewable energy, highlighting how these technologies improve animal health, optimize resource use, and promote sustainable practices in livestock farming."," - Intelligent systemization (IS) enhances livestock well-being through real-time health monitoring and early disease detection, which leads to improved animal health and welfare.
- The integration of intelligent technologies optimizes feeding efficiency and reduces operational costs through automation, while also contributing to environmental sustainability by minimizing waste and reducing the ecological footprint of livestock farming."," - The paper reviews the integration of intelligent technologies in the livestock industry, focusing on advancements such as real-time monitoring, machine learning, and the Internet of Things, which aim to enhance productivity, animal welfare, and sustainability in farming practices. 

- It highlights the benefits of intelligent systemization, including improved animal health through early disease detection, optimized resource use, reduced operational costs via automation, and contributions to environmental sustainability by minimizing waste and lowering the ecological footprint of livestock farming.",," - The primary objective of the study is to provide a comprehensive overview of how intelligent technologies, such as real-time monitoring, machine learning, and the Internet of Things, can address challenges in the livestock industry by improving animal health and optimizing resource use.

- Another key objective is to explore the impact of intelligent systemization on promoting sustainable practices within livestock farming, including enhancing livestock well-being, reducing operational costs through automation, and minimizing waste to lower the ecological footprint of the industry."," - Future research could focus on the development and integration of more advanced machine learning algorithms that enhance real-time monitoring and data analytics in livestock farming, aiming to improve early disease detection and overall animal health management.

- Investigating the long-term impacts of intelligent systemization on resource optimization and environmental sustainability in livestock operations could provide valuable insights into best practices and strategies for minimizing waste and reducing the ecological footprint of the industry.",machine learning,"- Literature Review
- Case Studies
- Intelligent Monitoring
- Data Analytics
- Automation
- Machine Learning
- Internet of Things (IoT)
- Renewable Energy Integration"
Journal Article,From crowd to herd counting: How to precisely detect and count African mammals using aerial imagery and deep learning?,10.1016/j.isprsjprs.2023.01.025,"Rapid growth of human populations in sub-Saharan Africa has led to a simultaneous increase in the number of livestock, often leading to conflicts of use with wildlife in protected areas. To minimize these conflicts, and to meet both communities’ and conservation goals, it is therefore essential to monitor livestock density and their land use. This is usually done by conducting aerial surveys during which aerial images are taken for later counting. Although this approach appears to reduce counting bias, the manual processing of images is time-consuming. The use of dense convolutional neural networks (CNNs) has emerged as a very promising avenue for processing such datasets. However, typical CNN architectures have detection limits for dense herds and close-by animals. To tackle this problem, this study introduces a new point-based CNN architecture, HerdNet, inspired by crowd counting. It was optimized on challenging oblique aerial images containing herds of camels (Camelus dromedarius), donkeys (Equus asinus), sheep (Ovis aries) and goats (Capra hircus), acquired over heterogeneous arid landscapes of the Ennedi reserve (Chad). This approach was compared to an anchor-based architecture, Faster-RCNN, and a density-based, adapted version of DLA-34 that is typically used in crowd counting. HerdNet achieved a global F1 score of 73.6 % on 24 megapixels images, with a root mean square error of 9.8 animals and at a processing speed of 3.6 s, outperforming the two baselines in terms of localization, counting and speed. It showed better proximity-invariant precision while maintaining equivalent recall to that of Faster-RCNN, thus demonstrating that it is the most suitable approach for detecting and counting large mammals at close range. The only limitation of HerdNet was the slightly weaker identification of species, with an average confusion rate approximately 4 % higher than that of Faster-RCNN. This study provides a new CNN architecture that could be used to develop an automatic livestock counting tool in aerial imagery. The reduced image analysis time could motivate more frequent flights, thus allowing a much finer monitoring of livestock and their land use. ",2023.0,"Alexandre Delplanque, Samuel Foucher, Jérôme Théau, Elsa Bussière, Cédric Vermeulen, Philippe Lejeune","The study introduces HerdNet, a point-based CNN architecture optimized for detecting and counting livestock in aerial imagery, specifically camels, donkeys, sheep, and goats. It achieved a global F1 score of 73.6% with a root mean square error of 9.8 animals, outperforming Faster-RCNN and an adapted DLA-34 in localization, counting, and speed. However, HerdNet had a slightly higher species identification confusion rate, approximately 4% more than Faster-RCNN, indicating a trade-off between counting accuracy and species classification."," - The rapid growth of human populations in sub-Saharan Africa has led to an increase in livestock numbers, resulting in conflicts of land use between livestock and wildlife in protected areas. This necessitates effective monitoring of livestock density and land use to balance community needs and conservation goals.

- Traditional methods of monitoring livestock through aerial surveys involve time-consuming manual processing of images, which can introduce counting bias. The study addresses the need for a more efficient and accurate method of counting livestock using advanced deep learning techniques."," - The paper introduces a new point-based CNN architecture called HerdNet, inspired by crowd counting, to detect and count large mammals at close range in aerial images.
- The study compares HerdNet with two other architectures, Faster-RCNN and a density-based adapted version of DLA-34, in terms of localization, counting accuracy, and processing speed, with HerdNet outperforming the baselines in terms of precision and speed while maintaining equivalent recall."," - The study indicates a limitation in the identification of species, with HerdNet showing an average confusion rate approximately 4% higher than that of the Faster-RCNN architecture. This suggests a need for further improvement in species classification accuracy within the proposed CNN framework.

- While HerdNet outperformed existing architectures in terms of localization, counting, and processing speed, the research does not address the potential challenges of applying this method to different environments or species beyond those tested (camels, donkeys, sheep, and goats in arid landscapes), indicating a gap in the generalizability of the approach."," - The study utilized challenging oblique aerial images containing herds of camels (Camelus dromedarius), donkeys (Equus asinus), sheep (Ovis aries), and goats (Capra hircus).
- These images were acquired over heterogeneous arid landscapes of the Ennedi reserve in Chad."," - The study highlights the challenges of monitoring livestock density and land use in sub-Saharan Africa due to the rapid growth of human populations and livestock, which often leads to conflicts with wildlife in protected areas. Traditional aerial surveys for counting livestock are time-consuming due to the manual processing of images, necessitating a more efficient method.

- The research introduces HerdNet, a new point-based CNN architecture optimized for counting dense herds in aerial imagery, which outperforms existing methods like Faster-RCNN and a density-based version of DLA-34 in terms of localization, counting accuracy, and processing speed, while also addressing the limitations of typical CNN architectures in detecting close-by animals."," - HerdNet, a new point-based CNN architecture inspired by crowd counting, achieved a global F1 score of 73.6% on 24 megapixels images, with a root mean square error of 9.8 animals and a processing speed of 3.6 s, outperforming the anchor-based Faster-RCNN and density-based adapted DLA-34 architectures in terms of localization, counting, and speed.
- While HerdNet showed better proximity-invariant precision and equivalent recall to Faster-RCNN for detecting and counting large mammals at close range, it had a slightly weaker identification of species, with an average confusion rate approximately 4% higher than that of Faster-RCNN."," - The study addresses the need for monitoring livestock density in sub-Saharan Africa to minimize conflicts between livestock and wildlife, introducing a new point-based CNN architecture called HerdNet, which is optimized for counting animals in aerial images. HerdNet outperformed traditional methods in terms of localization, counting accuracy, and processing speed, achieving a global F1 score of 73.6% with a root mean square error of 9.8 animals.

- While HerdNet demonstrated superior performance in counting and speed, it had a slightly higher species identification confusion rate compared to the Faster-RCNN architecture. The findings suggest that HerdNet could facilitate the development of an automatic livestock counting tool, enabling more frequent aerial surveys for better monitoring of livestock and land use."," - The only limitation of the HerdNet architecture was its slightly weaker identification of species, with an average confusion rate approximately 4% higher than that of the Faster-RCNN architecture. This indicates that while HerdNet excels in counting and localization, it may struggle more with accurately distinguishing between different species of livestock.

- Despite its advantages in processing speed and proximity-invariant precision, the study does not mention any specific limitations related to the overall performance of HerdNet in terms of counting accuracy or image processing capabilities beyond the species identification issue."," - The primary objective of the research is to develop a new point-based convolutional neural network architecture, HerdNet, to improve the detection and counting of dense herds of livestock in aerial imagery, specifically addressing the limitations of typical CNN architectures in counting close-by animals.

- The study aims to provide an efficient and accurate method for monitoring livestock density and land use in sub-Saharan Africa, thereby minimizing conflicts between livestock and wildlife, and facilitating more frequent aerial surveys through reduced image analysis time."," - Future research could focus on improving the species identification capabilities of the HerdNet architecture, as it currently has a slightly higher confusion rate (approximately 4%) compared to Faster-RCNN. Enhancing species recognition could lead to more accurate assessments of wildlife populations and better inform conservation strategies.

- Another area for future research could involve the application of the HerdNet architecture to different environments and species beyond those tested in the study, such as varying landscapes or other types of livestock and wildlife. This could help validate the robustness and adaptability of the model in diverse ecological contexts and further refine automatic livestock counting tools.",cnn,Method: Point-based CNN architecture (HerdNet) for crowd counting.
Journal Article,Trajectory Agnostic Livestock Counting Through UAV Imaging,10.1109/mass62177.2024.00109,"Individual object identification is a common problem in visual tracking. This work aims to resolve the detectable instance disappearance problem by estimating probabilities of its placement in the image. This problem can occur both through occlusion and camera movement. Potential solutions can be used in crowd monitoring, visual tracking, traffic monitoring, and agriculture. We present an evaluation of the proposed method based on cattle counting using an Unmanned Aerial Vehicle (UAV) application which is useful for monitoring farms and eliminates one of the many stress factors on farmers. We are able to not only fuse results from multiple frames but also significantly reduce the number of double-counted individuals in the field.",2024.0,"Maksym Lishchynskyi, Irene Cheng, Ioanis Nikolaidis","The research paper focuses on livestock counting, specifically cattle, using UAV imaging to address the challenges of individual object identification and detectable instance disappearance. It proposes a method that estimates the probabilities of cattle placement in images, effectively reducing double-counting and improving accuracy in monitoring farms. While the paper emphasizes counting, it does not explicitly cover classification of livestock, but the techniques could potentially be adapted for classification tasks in future applications."," - The paper addresses the issue of individual object identification in visual tracking, specifically focusing on the problem of detectable instance disappearance, which can occur due to occlusion or camera movement.
- It highlights the need for effective solutions in various applications, including crowd monitoring, visual tracking, traffic monitoring, and agriculture, with a particular emphasis on improving cattle counting through UAV imaging to aid in farm monitoring and reduce stress factors for farmers."," - The paper presents a method for resolving the detectable instance disappearance problem by estimating probabilities of an object's placement in the image, which addresses issues caused by occlusion and camera movement.
- The proposed method involves fusing results from multiple frames to enhance cattle counting accuracy and significantly reduce the occurrence of double-counted individuals in the field."," - The paper addresses the issue of detectable instance disappearance due to occlusion and camera movement, but it does not explore other potential factors that may affect individual object identification in livestock counting, such as varying environmental conditions or different types of livestock behavior that could complicate tracking.

- While the proposed method shows effectiveness in reducing double-counted individuals and fusing results from multiple frames, the evaluation does not provide insights into the scalability of the method for larger herds or its performance in diverse agricultural settings beyond cattle counting.",," - The paper addresses the common problem of individual object identification in visual tracking, specifically focusing on the issue of detectable instance disappearance due to factors like occlusion and camera movement. This highlights the need for improved methods in various applications such as crowd monitoring, visual tracking, traffic monitoring, and agriculture.

- The proposed method is evaluated through its application in cattle counting using Unmanned Aerial Vehicles (UAVs), which aids in farm monitoring and reduces stress factors for farmers. The approach not only integrates results from multiple frames but also minimizes the occurrence of double-counted individuals in the field."," - The proposed method effectively addresses the detectable instance disappearance problem in cattle counting by estimating the probabilities of individual placements in the image, which helps in overcoming issues caused by occlusion and camera movement.
- The evaluation of the method demonstrated a significant reduction in the number of double-counted individuals in the field, enhancing the accuracy of livestock monitoring through UAV imaging."," - The paper addresses the challenge of individual object identification in visual tracking, specifically focusing on the issue of detectable instance disappearance due to occlusion and camera movement. It proposes a method that estimates the probabilities of an object's placement in an image, which can be applied in various fields such as crowd monitoring, traffic monitoring, and agriculture.

- The evaluation of the proposed method is demonstrated through cattle counting using Unmanned Aerial Vehicle (UAV) imaging, which aids in farm monitoring and alleviates stress factors for farmers. The approach effectively combines results from multiple frames and significantly minimizes the occurrence of double-counted individuals in the field."," - The paper addresses the issue of detectable instance disappearance, which can occur due to occlusion and camera movement, indicating that these factors can limit the effectiveness of visual tracking in livestock counting.
- While the proposed method aims to reduce double-counting of individuals in the field, it does not explicitly mention any limitations regarding the accuracy of counting in highly dense or overlapping cattle populations, which could still pose challenges."," - The research aims to resolve the detectable instance disappearance problem in visual tracking, which can occur due to occlusion and camera movement, by estimating probabilities of object placement in images.
- The study evaluates a method for cattle counting using UAV imaging, focusing on improving farm monitoring by reducing double-counted individuals and fusing results from multiple frames."," - Future research could explore the application of the proposed method in other domains such as crowd monitoring, visual tracking, and traffic monitoring, to assess its effectiveness and adaptability in various scenarios beyond livestock counting.
- Investigating advanced algorithms for further reducing the occurrence of double-counted individuals and improving the accuracy of object identification in more complex environments, which could enhance the reliability of UAV imaging in agricultural monitoring.",,"Method: Object placement probability estimation, multi-frame fusion."
Journal Article,Semi-Supervised Machine Learning for Livestock Threat Classification Using GPS Data,10.1109/access.2023.3258621,"South African livestock farmers face major challenges in the form of livestock theft and predation. In response to these concerns, farmers started using a collar that monitors the acceleration of an animal and, when specific parameters are met, triggers an alarm which transmits GPS data to the user’s mobile application. Typically, a collar is placed on one animal per flock or herd. In this work, we aim to classify the GPS trajectories captured by these devices into four categories: theft, predation, own-handling and other. We lay particular emphasis on distinguishing theft alarms since these have direct implications for the safety and financial sustainability of farmers. To date, just over one million of these alarms have been recorded. Unfortunately, these trajectories are not labelled with the four categories. Therefore, we start by collecting labelled data sets that can be used for training classification models. We then investigate supervised and semi-supervised approaches for classifying the trajectories. Our semi-supervised approach shows the best results with performance comparable to human performance. The approach consists of three parts. First, an autoencoder and classifier are jointly trained to produce fixed-dimensional embeddings from GPS trajectories. Second, these embeddings are clustered to produce cluster labels. And lastly, the cluster labels are added to human-engineered features and used to train a final classifier. Our semi-supervised approach achieves an overall classification accuracy of 69%, with an <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">F</i> <sub xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sub> score of 56% for theft events (4% lower than human performance) and an <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">F</i> <sub xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sub> score of 90% for own-handling events (slightly outperforming a human). This model can be deployed to aid farmers in terms of safety and security by providing them with critical information in emergency situations. ",2023.0,,"The paper focuses on classifying GPS trajectories of livestock into categories such as theft, predation, own-handling, and other events, rather than directly addressing livestock detection counting. It employs a semi-supervised machine learning approach that combines autoencoders, clustering, and classification to achieve a classification accuracy of 69%. While it emphasizes the classification of events related to livestock safety and security, it does not specifically cover counting livestock."," - South African livestock farmers are facing significant challenges due to livestock theft and predation, which threaten their safety and financial sustainability. To address these issues, farmers have begun using collars that monitor animal acceleration and trigger alarms that transmit GPS data when specific parameters are met.

- The paper focuses on classifying the GPS trajectories captured by these collars into four categories: theft, predation, own-handling, and other. A particular emphasis is placed on accurately distinguishing theft alarms, as they have direct implications for the safety and financial well-being of the farmers. However, the challenge lies in the fact that the recorded GPS trajectories are not labeled with these categories, necessitating the development of classification models using both labeled and unlabeled data."," - The paper employs a semi-supervised approach that consists of three main parts: first, an autoencoder and classifier are jointly trained to create fixed-dimensional embeddings from GPS trajectories; second, these embeddings are clustered to generate cluster labels; and third, the cluster labels are combined with human-engineered features to train a final classifier.

- The classification models are trained using both supervised and semi-supervised methods, with the semi-supervised approach demonstrating the best performance, achieving an overall classification accuracy of 69% and an F1 score of 56% for theft events, which is only 4% lower than human performance."," - The paper highlights the challenge of classifying GPS trajectories into specific categories (theft, predation, own-handling, and other) due to the lack of labeled data for the majority of the recorded alarms, indicating a gap in the availability of comprehensive labeled datasets for training classification models effectively.

- While the semi-supervised approach shows promising results, achieving an overall classification accuracy of 69% and an F1 score of 56% for theft events (4% lower than human performance), there remains a need for further improvement in the classification accuracy, particularly for theft events, to enhance the model's reliability and effectiveness in real-world applications."," - The study utilizes a collection of labelled data sets that are used for training classification models to categorize GPS trajectories into four categories: theft, predation, own-handling, and other.
- Over one million alarms have been recorded from the collars that monitor livestock, which provide the unlabelled GPS trajectories that the semi-supervised machine learning approach aims to classify.",," - The semi-supervised approach developed in the study achieved an overall classification accuracy of 69%, with an F1 score of 56% for theft events, which is 4% lower than human performance. This indicates that while the model is effective, there is still room for improvement in accurately identifying theft incidents.

- For own-handling events, the model achieved an F1 score of 90%, slightly outperforming human classification. This suggests that the model is particularly strong in recognizing when farmers are handling their livestock, which can be crucial for ensuring safety and security in livestock management."," - The paper addresses the challenges faced by South African livestock farmers due to livestock theft and predation, introducing a collar that monitors animal acceleration and transmits GPS data when specific parameters trigger an alarm. The study focuses on classifying the GPS trajectories into four categories: theft, predation, own-handling, and other, with a particular emphasis on accurately identifying theft events.

- A semi-supervised machine learning approach is developed, which combines autoencoders and classifiers to create fixed-dimensional embeddings from GPS data. This method achieves an overall classification accuracy of 69%, with a notable F1 score of 56% for theft events, which is only 4% lower than human performance, and a 90% F1 score for own-handling events, slightly outperforming human classification."," - The GPS trajectories captured by the collars are not labelled with the four categories (theft, predation, own-handling, and other), which poses a challenge for training classification models effectively. This lack of labelled data necessitates the use of semi-supervised approaches to infer classifications from unlabelled data.

- The semi-supervised approach achieves an overall classification accuracy of 69% and an F1 score of 56% for theft events, which is 4% lower than human performance. This indicates that while the model performs well, it still has limitations in accurately classifying theft events compared to human classifiers."," - The primary objective of the research is to classify GPS trajectories captured by livestock monitoring collars into four distinct categories: theft, predation, own-handling, and other, with a particular focus on accurately identifying theft alarms due to their significant implications for the safety and financial sustainability of farmers.

- The research aims to develop and evaluate both supervised and semi-supervised machine learning approaches for classifying these trajectories, ultimately achieving a semi-supervised model that demonstrates performance comparable to human classification, particularly in identifying theft and own-handling events.",,,"Semi-supervised learning, autoencoder, classifier, clustering, feature engineering."
Journal Article,PDC-YOLO: A Network for Pig Detection under Complex Conditions for Counting Purposes,10.3390/agriculture14101807,"Pigs play vital roles in the food supply, economic development, agricultural recycling, bioenergy, and social culture. Pork serves as a primary meat source and holds extensive applications in various dietary cultures, making pigs indispensable to human dietary structures. Manual pig counting, a crucial aspect of pig farming, suffers from high costs and time-consuming processes. In this paper, we propose the PDC-YOLO network to address these challenges, dedicated to detecting pigs in complex farming environments for counting purposes. Built upon YOLOv7, our model incorporates the SPD-Conv structure into the YOLOv7 backbone to enhance detection under varying lighting conditions and for small-scale pigs. Additionally, we replace the neck of YOLOv7 with AFPN to efficiently fuse features of different scales. Furthermore, the model utilizes rotated bounding boxes for improved accuracy. Achieving a mAP of 91.97%, precision of 95.11%, and recall of 89.94% on our collected pig dataset, our model outperforms others. Regarding technical performance, PDC-YOLO exhibits an error rate of 0.002 and surpasses manual counting significantly in speed. ",2024.0,"Peitong He, Sijian Zhao, Pan Pan, Guomin Zhou, Jianhua Zhang","The PDC-YOLO network is designed for livestock detection, specifically pig counting and classification in complex farming environments. It enhances detection capabilities using the SPD-Conv structure for varying lighting conditions and small-scale pigs, and employs rotated bounding boxes for improved accuracy. The model achieves a mean Average Precision (mAP) of 91.97%, precision of 95.11%, and recall of 89.94%, significantly outperforming manual counting in speed and accuracy, making it a valuable tool for pig farming operations."," - Manual pig counting is a crucial aspect of pig farming that is hindered by high costs and time-consuming processes, making it inefficient for farmers.
- The paper addresses the challenge of detecting pigs in complex farming environments, particularly under varying lighting conditions and for small-scale pigs, to improve the accuracy and speed of counting."," - The PDC-YOLO network is built upon the YOLOv7 architecture and incorporates the SPD-Conv structure into the YOLOv7 backbone, which enhances detection capabilities under varying lighting conditions and improves the detection of small-scale pigs.

- The model replaces the neck of YOLOv7 with an Adaptive Feature Pyramid Network (AFPN) to efficiently fuse features of different scales, and it utilizes rotated bounding boxes to achieve improved accuracy in pig detection."," - The paper does not address the potential limitations of the PDC-YOLO model in extremely challenging environmental conditions, such as heavy rain or snow, which could affect detection accuracy and reliability in real-world pig farming scenarios.

- There is no discussion on the scalability of the PDC-YOLO network for larger pig populations or different species, which may require further adaptation of the model to maintain high performance in diverse agricultural settings."," - The study utilizes a collected pig dataset specifically designed for evaluating the performance of the PDC-YOLO network in detecting pigs under complex farming environments.
- The model achieves a mean Average Precision (mAP) of 91.97%, precision of 95.11%, and recall of 89.94% on this dataset, indicating its effectiveness in pig detection and counting.",," - The PDC-YOLO model achieved a mean Average Precision (mAP) of 91.97%, a precision of 95.11%, and a recall of 89.94% on the collected pig dataset, indicating its high effectiveness in detecting pigs for counting purposes.
- The model demonstrated a low error rate of 0.002 and significantly outperformed manual counting in terms of speed, showcasing its efficiency in complex farming environments."," - The paper introduces the PDC-YOLO network, designed to enhance pig detection in complex farming environments for counting purposes, addressing the challenges of high costs and time-consuming manual counting methods. The model is built on YOLOv7 and incorporates advanced features such as the SPD-Conv structure and AFPN for improved detection under varying conditions and efficient feature fusion.

- PDC-YOLO achieves impressive technical performance metrics, including a mean Average Precision (mAP) of 91.97%, precision of 95.11%, and recall of 89.94% on a custom pig dataset, significantly outperforming manual counting in terms of speed and exhibiting a low error rate of 0.002."," - The paper does not explicitly mention any limitations of the PDC-YOLO network, focusing instead on its advantages and performance metrics such as a mAP of 91.97%, precision of 95.11%, and recall of 89.94% on the collected pig dataset.

- There is no discussion regarding potential challenges or shortcomings in the implementation or application of the PDC-YOLO model in real-world scenarios, such as environmental factors or variations in pig behavior that could affect detection accuracy."," - The primary objective of the research is to develop the PDC-YOLO network, which is designed to detect pigs in complex farming environments, thereby facilitating accurate counting of pigs and addressing the challenges associated with manual counting, which is costly and time-consuming.

- The model aims to enhance detection performance under varying lighting conditions and for small-scale pigs by incorporating the SPD-Conv structure into the YOLOv7 backbone and replacing the neck of YOLOv7 with AFPN for efficient feature fusion across different scales, ultimately achieving high accuracy metrics such as a mAP of 91.97%.",,yolo,"- YOLOv7 architecture
- SPD-Conv structure
- Adaptive Feature Pyramid Network (AFPN)
- Rotated bounding boxes"
Proceedings Article,Wildlife Monitoring and Surveillance,10.1109/ICONAT53423.2022.9725874,"Animal detection and classifications using computer vision systems have been practically unusable in uncontrolled contexts for years, due to concerns about the accuracy of the algorithms used. As a result, object detection, recognition, and classification, among other things, are receiving a lot of attention. Visual monitoring of animals in their natural habitat is currently one of the most popular methods in the field of computer vision (CV) systems. However, real-time animal detection and classification methods are still unavailable. Deep Learning improvements in Computer Vision have been built and developed through time, primarily over one specific method - a Convolutional Neural Network(CNN). This project is proposed using CNN to detect and classify animals in digital images. The feature of the animal in the input image is extracted to aid decision making, which is then plugged into the classification part for model analysis. According to the experimental results, the proposed algorithm has a positive effect on overall animal classification performance. An accuracy of around 64% was achieved when the image size was 50 × 50..",2022.0,"S. V. Viraktamath, J. R, Vidya A, Abhay S Bhat, Sathvik Nayak","The paper focuses on animal detection and classification using Convolutional Neural Networks (CNN) in digital images, which can be applied to livestock detection and counting. While it does not specifically address livestock, the proposed algorithm demonstrates an overall animal classification performance with an accuracy of around 64% for images sized 50 × 50. This suggests that similar methods could be adapted for effective livestock monitoring in uncontrolled environments, enhancing detection and classification capabilities."," - The paper discusses the challenges of using computer vision systems for animal detection and classification in uncontrolled contexts, primarily due to concerns about the accuracy of the algorithms employed. This has rendered such systems practically unusable in real-world scenarios.

- It highlights that, despite the popularity of visual monitoring of animals in their natural habitats, real-time animal detection and classification methods are still lacking, necessitating improvements in the algorithms used for these tasks."," - The paper proposes the use of Convolutional Neural Networks (CNN) for detecting and classifying animals in digital images, focusing on extracting features from the input images to aid in decision making for classification.
- The experimental results indicate that the proposed CNN algorithm has a positive impact on animal classification performance, achieving an accuracy of approximately 64% with images sized at 50 × 50 pixels."," - The paper highlights that real-time animal detection and classification methods are still unavailable, indicating a significant gap in the application of computer vision systems for wildlife monitoring in uncontrolled environments. This suggests a need for further research to develop algorithms that can operate effectively in real-time scenarios.

- Although the proposed algorithm achieved an accuracy of around 64% with a specific image size of 50 × 50, this level of accuracy may not be sufficient for practical applications in wildlife monitoring. There is a need for further improvements in the accuracy and robustness of the classification performance to enhance the effectiveness of animal detection in diverse and challenging natural habitats.",," - The paper discusses the historical challenges faced in animal detection and classification using computer vision systems, particularly in uncontrolled contexts, where concerns about the accuracy of algorithms have rendered them practically unusable for years. 

- It highlights the advancements in deep learning, specifically through the development of Convolutional Neural Networks (CNN), which have been utilized to improve the performance of animal detection and classification in digital images, achieving an accuracy of around 64% with a specific image size of 50 × 50."," - The proposed algorithm for animal detection and classification using Convolutional Neural Networks (CNN) demonstrated a positive effect on overall animal classification performance.
- An accuracy of approximately 64% was achieved when processing images sized at 50 × 50 pixels."," - The paper discusses the challenges of using computer vision systems for animal detection and classification in uncontrolled environments, highlighting the historical concerns regarding the accuracy of these algorithms. It emphasizes the growing interest in object detection, recognition, and classification, particularly in the context of visual monitoring of wildlife.

- The proposed solution involves utilizing Convolutional Neural Networks (CNN) to enhance the detection and classification of animals in digital images. The study reports an experimental accuracy of approximately 64% when processing images sized at 50 × 50 pixels, indicating a positive impact on overall animal classification performance."," - The paper highlights that animal detection and classification using computer vision systems have been practically unusable in uncontrolled contexts for years due to concerns about the accuracy of the algorithms employed. This indicates a significant limitation in the reliability of these systems in real-world applications.

- Despite advancements in deep learning and the development of Convolutional Neural Networks (CNN), real-time animal detection and classification methods are still unavailable, suggesting a limitation in the practical implementation of these technologies for immediate wildlife monitoring."," - The primary objective of the research is to utilize Convolutional Neural Networks (CNN) for the detection and classification of animals in digital images, addressing the limitations of previous algorithms in uncontrolled contexts and enhancing accuracy in wildlife monitoring.

- The project aims to extract features from input images of animals to improve decision-making processes in classification, ultimately achieving a higher overall animal classification performance, as evidenced by an experimental accuracy of around 64% with a specific image size of 50 × 50."," - Future research could focus on improving the accuracy of animal detection and classification algorithms beyond the current achievement of around 64%, particularly in uncontrolled environments where real-time monitoring is essential. This may involve exploring advanced techniques or hybrid models that combine CNN with other machine learning approaches.

- Another area for future research could be the development of real-time animal detection and classification methods, as current systems are not capable of operating in real-time. This would enhance the effectiveness of visual monitoring in wildlife studies and conservation efforts, allowing for immediate data analysis and response.",cnn,Method Used: Convolutional Neural Networks (CNN)
Proceedings Article,People/Animal Counting – Integrated Sensor Based and Wifi/Machine Learning Based System,10.1109/eeae53789.2022.9831396,"Especially with the COVID-19 pandemic, which is affecting the whole world today, accurate determination of the number of people entering a closed area has become very important in terms of measures to be taken against the spread of the disease. This project uses WiFi Signals and IR sensors to determine the number of people in a predefined area. To obtain the required raw data the system utilizes two main principles: the effect of humans on the WiFi signal strength and the entrance-exit control based on distance and LDR sensors. It is a low cost solution with quite good sensitivity and low error level. The simple principles which it is based on allows its application also in other areas like for example livestock farming, where the number of cattle entering a closed area can be counted.",2022.0,Radosveta Sokullu,"The research paper discusses a system that utilizes WiFi signals and IR sensors for counting individuals in a predefined area, which can also be applied to livestock farming. The system counts the number of cattle entering a closed area by leveraging the effect of humans on WiFi signal strength and entrance-exit control using distance and LDR sensors. This low-cost solution offers good sensitivity and low error levels, making it suitable for livestock detection and counting."," - The paper addresses the challenge of accurately determining the number of people entering a closed area, which has become crucial due to the COVID-19 pandemic and the need for measures to prevent the spread of the disease.
- It highlights the use of WiFi signals and IR sensors to count individuals, leveraging the impact of humans on WiFi signal strength and implementing entrance-exit control through distance and LDR sensors to achieve a low-cost solution with good sensitivity and low error levels."," - The system utilizes WiFi signals to determine the number of people in a predefined area by analyzing the effect of humans on the WiFi signal strength, which helps in accurately counting individuals entering or exiting the area.
  
- It employs entrance-exit control based on distance and LDR (Light Dependent Resistor) sensors, allowing for effective monitoring of the number of people or animals, such as cattle, in a closed space.",," - The system utilizes WiFi signals to determine the number of people in a predefined area by analyzing the effect of humans on the WiFi signal strength.
- It also employs IR sensors along with distance and LDR sensors for entrance-exit control to accurately count the number of individuals entering and exiting the area.",," - The project successfully demonstrates a low-cost solution for accurately determining the number of people entering a closed area, which is particularly important for managing health measures during the COVID-19 pandemic. The system utilizes WiFi signals and IR sensors to achieve this goal with good sensitivity and a low error level.

- The principles used in the system, which include the effect of humans on WiFi signal strength and entrance-exit control based on distance and LDR sensors, allow for potential applications beyond human counting, such as in livestock farming for counting the number of cattle entering a closed area."," - The project focuses on accurately counting the number of people entering a closed area, which has become crucial during the COVID-19 pandemic for controlling the spread of the disease. It employs WiFi signals and IR sensors to gather data on human presence and movement.
  
- The system operates on two main principles: the impact of humans on WiFi signal strength and the use of distance and LDR sensors for entrance-exit control. It is designed to be a low-cost solution with high sensitivity and low error rates, making it applicable in various fields, including livestock farming for counting cattle.",," - The primary objective of the research is to accurately determine the number of people entering a closed area, which has become crucial for implementing measures against the spread of COVID-19. This is achieved through the use of WiFi signals and IR sensors to monitor and count individuals effectively.

- Another objective is to develop a low-cost solution that demonstrates good sensitivity and low error levels in counting, which can also be applied in other fields such as livestock farming, where it can be used to count the number of cattle entering a closed area."," - Future research could explore the application of the integrated sensor-based and WiFi/machine learning system in various environments beyond human counting, such as in livestock farming, to enhance the accuracy and efficiency of counting cattle entering and exiting closed areas.

- Investigating the potential for improving the sensitivity and reducing the error level of the system could lead to advancements in its technology, making it applicable in more complex scenarios, such as crowded public spaces or large-scale events, where precise counting is crucial for health and safety measures.",ldr,"- Method Used: WiFi signal analysis, distance measurement, LDR sensor monitoring"
Journal Article,Machine Learning Based Approaches for Livestock Symptoms and Diseases Prediction and Classification,10.1109/ic3se62002.2024.10593244,"Farm animals farmed for financial gain are referred to as livestock. The majority of livestock animals are found in isolated locations with little access to medical care. Rapid and precise disease diagnosis is generally a challenging task. To prevent the disease from spreading among the cattle, it is essential to identify the disease's consequence and take appropriate precautions. Therefore, a system that can assist in forecasting cattle diseases based on symptoms and recommend preventive actions in relation to the projected disease is required. In this work, we analyze a dataset of livestock animal health issues using automated monitoring systems using eight machine learning methods. The variables that the machine learning algorithms examine are the age, symptoms, variations in temperature, disease type. Using a dataset, we have implemented machine learning algorithms for the purpose of early diagnosis and prediction of disease in livestock animals. Machine learning techniques like logistic regression, XGBoost, Catboost, light gradient boost, Random Forests and Support Vector Machines were integrated with feature selection algorithms to predict diseases. After analyzing the data for each classifier, the Catboost and Random Forest classifiers had the greatest and most reliable accuracy of 83.7% and 83.5% respectively.",2024.0,"Priya Bhardwaj, Sacheen Kumar, G. Prabu Kanna, Mithila Achintha","The paper focuses on predicting and classifying diseases in livestock rather than detection, counting, or general classification of livestock. It utilizes machine learning algorithms to analyze health issues based on symptoms, age, temperature variations, and disease type. The study implements methods like logistic regression, XGBoost, Catboost, and Random Forests, achieving high accuracy in disease prediction, specifically 83.7% with Catboost and 83.5% with Random Forests, but does not address livestock counting or detection directly."," - The paper addresses the challenge of rapid and precise disease diagnosis in livestock, which is difficult due to the isolated locations of farm animals and their limited access to medical care. This makes it essential to identify diseases quickly to prevent their spread among cattle.

- To tackle this issue, the paper proposes a system that forecasts cattle diseases based on symptoms and recommends preventive actions, utilizing machine learning algorithms to analyze various factors such as age, symptoms, temperature variations, and disease type for early diagnosis and prediction."," - The paper utilizes eight machine learning methods for analyzing a dataset of livestock animal health issues, including logistic regression, XGBoost, Catboost, light gradient boost, Random Forests, and Support Vector Machines, integrated with feature selection algorithms to enhance disease prediction accuracy.

- Among the classifiers analyzed, the Catboost and Random Forest classifiers demonstrated the highest and most reliable accuracy rates of 83.7% and 83.5%, respectively, indicating their effectiveness in early diagnosis and prediction of diseases in livestock animals."," - The paper does not address the integration of real-time data collection methods for monitoring livestock health, which could enhance the accuracy and timeliness of disease prediction and classification. Implementing IoT devices or wearable technology could provide continuous health monitoring and improve the dataset used for machine learning algorithms.

- There is a lack of exploration into the scalability of the proposed machine learning models across different livestock species and varying environmental conditions. Future research could investigate how these models perform in diverse agricultural settings and with different types of livestock to ensure broader applicability and effectiveness."," - The study analyzes a dataset of livestock animal health issues, which includes variables such as age, symptoms, variations in temperature, and disease type.
- The dataset is utilized to implement various machine learning algorithms for the early diagnosis and prediction of diseases in livestock animals."," - The paper discusses the challenges of rapid and precise disease diagnosis in livestock, emphasizing the need for a system that can forecast cattle diseases based on symptoms and recommend preventive actions to mitigate disease spread among farm animals.
- It evaluates a dataset of livestock health issues using eight machine learning methods, focusing on variables such as age, symptoms, temperature variations, and disease type, ultimately finding that the Catboost and Random Forest classifiers achieved the highest accuracy rates of 83.7% and 83.5%, respectively."," - The study implemented various machine learning algorithms, including logistic regression, XGBoost, Catboost, light gradient boost, Random Forests, and Support Vector Machines, to analyze a dataset of livestock animal health issues for early diagnosis and prediction of diseases based on symptoms and other variables such as age and temperature variations.

- Among the classifiers evaluated, the Catboost and Random Forest classifiers achieved the highest and most reliable accuracy rates of 83.7% and 83.5%, respectively, indicating their effectiveness in predicting livestock diseases."," - The paper discusses the development of a machine learning-based system aimed at predicting and classifying diseases in livestock by analyzing various factors such as age, symptoms, temperature variations, and disease type. This system is crucial for early diagnosis and prevention of disease spread among farm animals, which often have limited access to medical care.

- Eight different machine learning algorithms, including logistic regression, XGBoost, Catboost, light gradient boost, Random Forests, and Support Vector Machines, were employed to analyze a dataset of livestock health issues. Among these, the Catboost and Random Forest classifiers achieved the highest accuracy rates of 83.7% and 83.5%, respectively, demonstrating their effectiveness in predicting livestock diseases."," - The paper highlights the challenge of rapid and precise disease diagnosis in livestock, particularly due to the isolated locations of many farm animals, which often have limited access to medical care. This situation complicates the timely identification and management of diseases among cattle.

- While the study implements various machine learning algorithms for disease prediction, it does not specify any limitations regarding the dataset used, such as its size, diversity, or potential biases, which could affect the generalizability and reliability of the predictive models."," - The primary objective of the research is to develop a system that can forecast cattle diseases based on observed symptoms, enabling early diagnosis and timely preventive actions to mitigate the spread of diseases among livestock.

- The study aims to analyze a dataset of livestock animal health issues using various machine learning methods, specifically focusing on factors such as age, symptoms, temperature variations, and disease type, to enhance the accuracy of disease prediction and classification."," - Future research could focus on enhancing the accuracy and reliability of machine learning algorithms for livestock disease prediction by exploring additional algorithms beyond those already tested, such as deep learning techniques, and incorporating more diverse datasets that include a wider range of symptoms and environmental factors.

- Another area for future research could involve the development of real-time monitoring systems that integrate machine learning predictions with IoT devices, allowing for immediate data collection and analysis to facilitate timely interventions and preventive measures in livestock health management.",machine learning,"- Method Used: Machine Learning  
  - Specific Techniques: 
    - Logistic Regression
    - XGBoost
    - Catboost
    - Light Gradient Boost
    - Random Forests
    - Support Vector Machines
    - Feature Selection Algorithms"
Journal Article,Livestock detection in African rangelands: Potential of high-resolution remote sensing data,10.1016/j.rsase.2024.101139,"Livestock production is vital in eradicating poverty, malnutrition, and in attainment of the Sustainable Development Goals (SDG) in developing regions such as Africa. The livestock sector of Africa contributes 10%–44% of the gross domestic product and more than 70% of the greenhouse gas emissions of the continent. With the anticipated increase in demand for livestock products, the need to mitigate climate change, and lack of accurate livestock census data, innovative remote sensing technologies and methods for livestock census become crucial for the livestock sector. In this paper, we present a review of current technological advancements in remote sensing and detection algorithms in livestock censuses, identifying weaknesses in sensors and detection methods, and highlighting issues that currently limit adoption of these technologies in African countries. We observed that the last four years (2019–2022) accounted for 69% of all livestock detection studies. This surge was driven by development of Unmanned Aerial Vehicles, which offer high resolution images and flexibility for detection. In addition, the use of automated detection methods are fast, efficient and accurate. However, the surrounding background of different livestock species, herd size and spatial resolution of the datasets affects detection accuracy. We suggest the need for publicly accessible aerial labelled livestock databases covering the various livestock breeds in Africa to develop customized detection models for the heterogeneous landscapes in the rangelands. Efficient detection methods are vital for monitoring livestock population trends and environmental impacts of grazing practises. ",2024.0,"Ian A. Ocholla, Petri Pellikka, Faith N. Karanja, Ilja Elias Vuorinne, Victor Odipo, Janne Heiskanen","Livestock detection counting and classification are enhanced through high-resolution remote sensing technologies, particularly Unmanned Aerial Vehicles (UAVs), which provide detailed images for accurate identification. Automated detection methods improve efficiency and precision in counting livestock populations. However, factors such as the surrounding background, herd size, and spatial resolution of datasets can impact detection accuracy. The paper emphasizes the need for publicly accessible aerial labeled livestock databases to develop tailored detection models suitable for Africa's diverse rangeland landscapes."," - The paper discusses the critical need for innovative remote sensing technologies and methods for livestock census in Africa due to the anticipated increase in demand for livestock products, the necessity to mitigate climate change, and the lack of accurate livestock census data. This highlights the importance of developing effective monitoring systems for the livestock sector.

- It identifies weaknesses in current sensors and detection methods, as well as issues that limit the adoption of these technologies in African countries, such as the influence of background environments, herd size, and spatial resolution on detection accuracy, which complicates effective livestock monitoring and management."," - The paper reviews current technological advancements in remote sensing and detection algorithms specifically for livestock censuses, highlighting the development of Unmanned Aerial Vehicles (UAVs) that provide high-resolution images and flexibility for effective detection of livestock.

- It discusses the use of automated detection methods that are characterized as fast, efficient, and accurate, while also addressing the challenges posed by factors such as the surrounding background of different livestock species, herd size, and the spatial resolution of the datasets, which can affect detection accuracy."," - The paper identifies weaknesses in current sensors and detection methods used for livestock censuses, indicating a need for improved technologies that can enhance detection accuracy in diverse African rangeland environments. The limitations of existing methods hinder the effective adoption of remote sensing technologies in livestock monitoring.

- There is a lack of publicly accessible aerial labelled livestock databases that cover various livestock breeds in Africa. This gap restricts the development of customized detection models tailored to the heterogeneous landscapes of the rangelands, which is essential for accurate livestock population monitoring and understanding the environmental impacts of grazing practices."," - The study emphasizes the need for publicly accessible aerial labelled livestock databases that cover various livestock breeds in Africa. This is crucial for developing customized detection models tailored to the heterogeneous landscapes found in African rangelands.

- The paper highlights that the accuracy of livestock detection is influenced by factors such as the surrounding background of different livestock species, herd size, and the spatial resolution of the datasets used in detection methods."," - The paper presents a review of current technological advancements in remote sensing and detection algorithms specifically for livestock censuses, identifying weaknesses in existing sensors and detection methods that limit their adoption in African countries. It highlights the importance of innovative remote sensing technologies in addressing the challenges of accurate livestock census data amidst increasing demand for livestock products.

- The review indicates that the last four years (2019–2022) have seen a significant surge in livestock detection studies, accounting for 69% of the total research in this area. This increase is attributed to the development of Unmanned Aerial Vehicles (UAVs), which provide high-resolution images and flexibility for livestock detection, as well as the implementation of automated detection methods that enhance speed, efficiency, and accuracy in monitoring livestock populations."," - The paper reviews current technological advancements in remote sensing and detection algorithms for livestock censuses, highlighting the significant increase in livestock detection studies over the last four years (2019–2022), which accounted for 69% of all studies, primarily driven by the development of Unmanned Aerial Vehicles that provide high-resolution images and flexibility for detection.

- It identifies weaknesses in existing sensors and detection methods, noting that factors such as the surrounding background of different livestock species, herd size, and spatial resolution of datasets can affect detection accuracy, and suggests the creation of publicly accessible aerial labelled livestock databases to develop customized detection models for the diverse landscapes in African rangelands."," - The paper discusses the importance of livestock production in Africa for poverty eradication and achieving Sustainable Development Goals, while highlighting the sector's significant contribution to the continent's GDP and greenhouse gas emissions. It emphasizes the need for innovative remote sensing technologies to improve livestock census accuracy amidst increasing demand for livestock products and climate change mitigation efforts.

- It reviews recent advancements in remote sensing and detection algorithms for livestock censuses, noting a surge in studies from 2019 to 2022 due to the development of Unmanned Aerial Vehicles. The paper identifies challenges such as background interference, herd size variability, and spatial resolution that affect detection accuracy, and calls for publicly accessible aerial labelled livestock databases to enhance detection methods tailored to Africa's diverse rangeland landscapes."," - The paper identifies weaknesses in sensors and detection methods that currently limit the adoption of remote sensing technologies for livestock census in African countries. These limitations can affect the accuracy and reliability of livestock detection.

- Factors such as the surrounding background of different livestock species, herd size, and the spatial resolution of the datasets are noted to impact detection accuracy, making it challenging to implement effective monitoring of livestock populations."," - The paper aims to review current technological advancements in remote sensing and detection algorithms specifically for livestock censuses, identifying the weaknesses in existing sensors and detection methods that limit their adoption in African countries.

- It highlights the importance of developing publicly accessible aerial labelled livestock databases that encompass various livestock breeds in Africa, which would facilitate the creation of customized detection models tailored to the diverse landscapes of African rangelands."," - There is a need for the development of publicly accessible aerial labelled livestock databases that cover various livestock breeds in Africa. This would facilitate the creation of customized detection models tailored to the heterogeneous landscapes found in African rangelands.

- Future research should focus on improving detection accuracy by addressing the limitations posed by the surrounding background of different livestock species, herd size, and the spatial resolution of datasets. Enhancing automated detection methods to overcome these challenges is crucial for effective monitoring of livestock population trends and the environmental impacts of grazing practices.",,"- Remote Sensing
- Unmanned Aerial Vehicles (UAVs)
- Automated Detection Methods"
